{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "import os.path\n",
    "import sys\n",
    "\n",
    "import keras.metrics\n",
    "from keras import callbacks, models, metrics\n",
    "from datahandler.constants import all_features, data_version, acc_features, tensorboard_dir, location_labels, mag_features\n",
    "from datahandler.data_preprocessing import get_train_test_data, load_data_v3\n",
    "from models.log_writer import LogWriter\n",
    "from model.lstm import make_lstm_model_v1\n",
    "from model.transformer import make_transformer_model_v1, make_transformer_model_v2\n",
    "from model.cnn import make_cnn_model_v1, make_cnn_model_v2\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import print_line_divider\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from datahandler.data_preprocessing_from_jupyter import load_train_test_data_raw_normalized,load_train_test_data_added_features_normalized, load_train_test_data_added_features_pca\n",
    "from audio.audio import play_training_is_complete\n",
    "from sklearn.metrics import classification_report\n",
    "import time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************\n",
      "Preparing data...\n",
      "Loading from file: /Users/duc.letran/Desktop/FINAL PROJECT/context_transformer/data/v4/mix/mm5_datacollection.csv (1/25)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [21]\u001B[0m, in \u001B[0;36m<cell line: 10>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPreparing data...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# x_train, y_train, x_test, y_test = get_train_test_data(supported_features, window_time_in_seconds, window_size)\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# x_train, y_train, x_test, y_test = load_data_v3(\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m#     features = supported_features,\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m#     window_time_in_seconds = window_time_in_seconds,\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m#     window_size = window_size\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# )\u001B[39;00m\n\u001B[0;32m---> 10\u001B[0m x_train, y_train, x_test, y_test \u001B[38;5;241m=\u001B[39m \u001B[43mload_train_test_data_raw_normalized\u001B[49m\u001B[43m(\u001B[49m\u001B[43mselected_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mall_features\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTrain data shape: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(x_train\u001B[38;5;241m.\u001B[39mshape) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m | Train label shape: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(y_train\u001B[38;5;241m.\u001B[39mshape))\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTest data shape: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(x_test\u001B[38;5;241m.\u001B[39mshape) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m | Test label shape: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(y_test\u001B[38;5;241m.\u001B[39mshape))\n",
      "File \u001B[0;32m~/Desktop/FINAL PROJECT/context_transformer/datahandler/data_preprocessing_from_jupyter.py:209\u001B[0m, in \u001B[0;36mload_train_test_data_raw_normalized\u001B[0;34m(added_feature, selected_features)\u001B[0m\n\u001B[1;32m    207\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    208\u001B[0m     df_type \u001B[38;5;241m=\u001B[39m DF_TYPE_RAW\n\u001B[0;32m--> 209\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mload_df_from_files\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdf_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mselected_features\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    210\u001B[0m window_index_start \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    211\u001B[0m window_index_increasing_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(WINDOW_SIZE \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m)\n",
      "File \u001B[0;32m~/Desktop/FINAL PROJECT/context_transformer/datahandler/data_preprocessing_from_jupyter.py:62\u001B[0m, in \u001B[0;36mload_df_from_files\u001B[0;34m(filepath, df_type, selected_features)\u001B[0m\n\u001B[1;32m     60\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_df_from_files\u001B[39m(filepath, df_type, selected_features\u001B[38;5;241m=\u001B[39mall_features):\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;66;03m# Step 1: Load from data\u001B[39;00m\n\u001B[0;32m---> 62\u001B[0m     df \u001B[38;5;241m=\u001B[39m \u001B[43mload_data_from_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     63\u001B[0m     df \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mdrop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabelActivity\u001B[39m\u001B[38;5;124m\"\u001B[39m, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     64\u001B[0m     df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabelPhone\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabelPhone\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: location_labels\u001B[38;5;241m.\u001B[39mindex(x))\n",
      "File \u001B[0;32m~/Desktop/FINAL PROJECT/context_transformer/datahandler/data_loader.py:39\u001B[0m, in \u001B[0;36mload_data_from_file\u001B[0;34m(filepath, show_info)\u001B[0m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_data_from_file\u001B[39m(filepath, show_info\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m     38\u001B[0m     data \u001B[38;5;241m=\u001B[39m pandas\u001B[38;5;241m.\u001B[39mread_csv(filepath)\n\u001B[0;32m---> 39\u001B[0m     data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdate\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mpandas\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_datetime\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdate\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;132;43;01m%d\u001B[39;49;00m\u001B[38;5;124;43m \u001B[39;49m\u001B[38;5;124;43m%\u001B[39;49m\u001B[38;5;124;43mb \u001B[39;49m\u001B[38;5;124;43m%\u001B[39;49m\u001B[38;5;124;43mY \u001B[39;49m\u001B[38;5;124;43m%\u001B[39;49m\u001B[38;5;124;43mH:\u001B[39;49m\u001B[38;5;124;43m%\u001B[39;49m\u001B[38;5;124;43mM:\u001B[39;49m\u001B[38;5;124;43m%\u001B[39;49m\u001B[38;5;124;43mS:\u001B[39;49m\u001B[38;5;132;43;01m%f\u001B[39;49;00m\u001B[38;5;124;43m \u001B[39;49m\u001B[38;5;124;43m%\u001B[39;49m\u001B[38;5;124;43mz\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     40\u001B[0m     data \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mset_index(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdate\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     41\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m show_info:\n",
      "File \u001B[0;32m~/Desktop/FINAL PROJECT/context_transformer/venv/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1051\u001B[0m, in \u001B[0;36mto_datetime\u001B[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001B[0m\n\u001B[1;32m   1049\u001B[0m         result \u001B[38;5;241m=\u001B[39m arg\u001B[38;5;241m.\u001B[39mmap(cache_array)\n\u001B[1;32m   1050\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1051\u001B[0m         values \u001B[38;5;241m=\u001B[39m \u001B[43mconvert_listlike\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_values\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1052\u001B[0m         result \u001B[38;5;241m=\u001B[39m arg\u001B[38;5;241m.\u001B[39m_constructor(values, index\u001B[38;5;241m=\u001B[39marg\u001B[38;5;241m.\u001B[39mindex, name\u001B[38;5;241m=\u001B[39marg\u001B[38;5;241m.\u001B[39mname)\n\u001B[1;32m   1053\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arg, (ABCDataFrame, abc\u001B[38;5;241m.\u001B[39mMutableMapping)):\n",
      "File \u001B[0;32m~/Desktop/FINAL PROJECT/context_transformer/venv/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:394\u001B[0m, in \u001B[0;36m_convert_listlike_datetimes\u001B[0;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001B[0m\n\u001B[1;32m    391\u001B[0m         \u001B[38;5;28mformat\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    393\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mformat\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 394\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43m_to_datetime_with_format\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    395\u001B[0m \u001B[43m        \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morig_arg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtz\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexact\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minfer_datetime_format\u001B[49m\n\u001B[1;32m    396\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    397\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m res \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    398\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
      "File \u001B[0;32m~/Desktop/FINAL PROJECT/context_transformer/venv/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:501\u001B[0m, in \u001B[0;36m_to_datetime_with_format\u001B[0;34m(arg, orig_arg, name, tz, fmt, exact, errors, infer_datetime_format)\u001B[0m\n\u001B[1;32m    498\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m _box_as_indexlike(result, utc\u001B[38;5;241m=\u001B[39mutc, name\u001B[38;5;241m=\u001B[39mname)\n\u001B[1;32m    500\u001B[0m     \u001B[38;5;66;03m# fallback\u001B[39;00m\n\u001B[0;32m--> 501\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43m_array_strptime_with_fallback\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtz\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfmt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexact\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minfer_datetime_format\u001B[49m\n\u001B[1;32m    503\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    504\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n\u001B[1;32m    506\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m    507\u001B[0m     \u001B[38;5;66;03m# Fallback to try to convert datetime objects if timezone-aware\u001B[39;00m\n\u001B[1;32m    508\u001B[0m     \u001B[38;5;66;03m#  datetime objects are found without passing `utc=True`\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/FINAL PROJECT/context_transformer/venv/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:439\u001B[0m, in \u001B[0;36m_array_strptime_with_fallback\u001B[0;34m(arg, name, tz, fmt, exact, errors, infer_datetime_format)\u001B[0m\n\u001B[1;32m    437\u001B[0m     result, timezones \u001B[38;5;241m=\u001B[39m array_strptime(arg, fmt, exact\u001B[38;5;241m=\u001B[39mexact, errors\u001B[38;5;241m=\u001B[39merrors)\n\u001B[1;32m    438\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mZ\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m fmt \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mz\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m fmt:\n\u001B[0;32m--> 439\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_return_parsed_timezone_results\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimezones\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtz\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    440\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m OutOfBoundsDatetime:\n\u001B[1;32m    441\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m errors \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m~/Desktop/FINAL PROJECT/context_transformer/venv/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:280\u001B[0m, in \u001B[0;36m_return_parsed_timezone_results\u001B[0;34m(result, timezones, tz, name)\u001B[0m\n\u001B[1;32m    260\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_return_parsed_timezone_results\u001B[39m(result: np\u001B[38;5;241m.\u001B[39mndarray, timezones, tz, name) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Index:\n\u001B[1;32m    261\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    262\u001B[0m \u001B[38;5;124;03m    Return results from array_strptime if a %z or %Z directive was passed.\u001B[39;00m\n\u001B[1;32m    263\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    277\u001B[0m \u001B[38;5;124;03m    tz_result : Index-like of parsed dates with timezone\u001B[39;00m\n\u001B[1;32m    278\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m    279\u001B[0m     tz_results \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(\n\u001B[0;32m--> 280\u001B[0m         [Timestamp(res)\u001B[38;5;241m.\u001B[39mtz_localize(zone) \u001B[38;5;28;01mfor\u001B[39;00m res, zone \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(result, timezones)]\n\u001B[1;32m    281\u001B[0m     )\n\u001B[1;32m    282\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m tz \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    283\u001B[0m         \u001B[38;5;66;03m# Convert to the same tz\u001B[39;00m\n\u001B[1;32m    284\u001B[0m         tz_results \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([tz_result\u001B[38;5;241m.\u001B[39mtz_convert(tz) \u001B[38;5;28;01mfor\u001B[39;00m tz_result \u001B[38;5;129;01min\u001B[39;00m tz_results])\n",
      "File \u001B[0;32m~/Desktop/FINAL PROJECT/context_transformer/venv/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:280\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    260\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_return_parsed_timezone_results\u001B[39m(result: np\u001B[38;5;241m.\u001B[39mndarray, timezones, tz, name) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Index:\n\u001B[1;32m    261\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    262\u001B[0m \u001B[38;5;124;03m    Return results from array_strptime if a %z or %Z directive was passed.\u001B[39;00m\n\u001B[1;32m    263\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    277\u001B[0m \u001B[38;5;124;03m    tz_result : Index-like of parsed dates with timezone\u001B[39;00m\n\u001B[1;32m    278\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m    279\u001B[0m     tz_results \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(\n\u001B[0;32m--> 280\u001B[0m         [\u001B[43mTimestamp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mres\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mtz_localize(zone) \u001B[38;5;28;01mfor\u001B[39;00m res, zone \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(result, timezones)]\n\u001B[1;32m    281\u001B[0m     )\n\u001B[1;32m    282\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m tz \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    283\u001B[0m         \u001B[38;5;66;03m# Convert to the same tz\u001B[39;00m\n\u001B[1;32m    284\u001B[0m         tz_results \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([tz_result\u001B[38;5;241m.\u001B[39mtz_convert(tz) \u001B[38;5;28;01mfor\u001B[39;00m tz_result \u001B[38;5;129;01min\u001B[39;00m tz_results])\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# DATA Loader\n",
    "print_line_divider()\n",
    "print(\"Preparing data...\")\n",
    "# x_train, y_train, x_test, y_test = get_train_test_data(supported_features, window_time_in_seconds, window_size)\n",
    "# x_train, y_train, x_test, y_test = load_data_v3(\n",
    "#     features = supported_features,\n",
    "#     window_time_in_seconds = window_time_in_seconds,\n",
    "#     window_size = window_size\n",
    "# )\n",
    "x_train, y_train, x_test, y_test = load_train_test_data_raw_normalized(selected_features=all_features)\n",
    "print(\"Train data shape: \" + str(x_train.shape) + \" | Train label shape: \" + str(y_train.shape))\n",
    "print(\"Test data shape: \" + str(x_test.shape) + \" | Test label shape: \" + str(y_test.shape))\n",
    "print_line_divider()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "# LOGGING CONFIGURATION\n",
    "enabled_log = True\n",
    "enabled_tensor_board = True\n",
    "log_writer = LogWriter(enabled_log)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING THE TRAINING PROCESS\n"
     ]
    }
   ],
   "source": [
    "# TRAINING CONFIGURATION\n",
    "print(\"STARTING THE TRAINING PROCESS\")\n",
    "SAVED_BEST_MODEL = \"model/best_model.h5\"\n",
    "window_time_in_seconds = 2\n",
    "window_size = 40\n",
    "epochs = 1000\n",
    "batch_size = 32\n",
    "validation_split = 15 / 85\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.01,\n",
    "    name=\"Adam\",\n",
    ")\n",
    "loss_function = \"sparse_categorical_crossentropy\"\n",
    "supported_features = all_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "log_writer.write(\"Configuration\", line_divider=True)\n",
    "log_writer.write(\n",
    "    f\"\"\"Window size: {window_size}\n",
    "Window time in second: {window_time_in_seconds}\n",
    "Maximum number of epochs: {epochs}\n",
    "Batch size: {batch_size}\n",
    "Validation split: {validation_split}\n",
    "Optimizer: {optimizer}\n",
    "Loss function: {loss_function}\"\"\"\n",
    ")\n",
    "log_writer.write(\"Data\", line_divider=True)\n",
    "log_writer.write(\"Data loaded from version \" + data_version)\n",
    "log_writer.write(\n",
    "    f\"\"\"Data training shape: ${x_train.shape}\n",
    "Data testing shape: ${x_test.shape}\"\"\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************\n",
      "Distribution for set Training set\n",
      "\n",
      "holdinginhand count is 1269\n",
      "insidethepantpocket count is 1272\n",
      "calling count is 1284\n",
      "beingusedinhand count is 1296\n",
      "insidethebag count is 1297\n",
      "****************************************************\n",
      "Distribution for set Testing set\n",
      "\n",
      "holdinginhand count is 231\n",
      "insidethepantpocket count is 231\n",
      "calling count is 217\n",
      "beingusedinhand count is 205\n",
      "insidethebag count is 203\n"
     ]
    }
   ],
   "source": [
    "def check_distribution(labels_list, set_name):\n",
    "    label_count_dict = {}\n",
    "    for label_ind in labels_list:\n",
    "        if label_ind in label_count_dict.keys():\n",
    "            label_count_dict[label_ind] += 1\n",
    "        else:\n",
    "            label_count_dict[label_ind] = 1\n",
    "\n",
    "    print_line_divider()\n",
    "    print(\"Distribution for set \" + set_name + \"\\n\")\n",
    "    for key in label_count_dict:\n",
    "        key = int(key)\n",
    "        print(location_labels[key] + \" count is \" + str(label_count_dict[key]))\n",
    "\n",
    "\n",
    "check_distribution(y_train, \"Training set\")\n",
    "check_distribution(y_test, \"Testing set\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (40, 9)\n"
     ]
    }
   ],
   "source": [
    "if len(x_train.shape) == 2:\n",
    "    input_shape = (x_train.shape[1], 1)\n",
    "else:\n",
    "    input_shape = x_train.shape[1:]\n",
    "print(\"Input shape: \" + str(input_shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_13 (InputLayer)          [(None, 40, 9)]      0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_50 (LayerN  (None, 40, 9)       18          ['input_13[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_25 (Multi  (None, 40, 9)       9993        ['layer_normalization_50[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_74 (Dropout)           (None, 40, 9)        0           ['multi_head_attention_25[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_50 (TFOpL  (None, 40, 9)       0           ['dropout_74[0][0]',             \n",
      " ambda)                                                           'input_13[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_51 (LayerN  (None, 40, 9)       18          ['tf.__operators__.add_50[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_53 (Conv1D)             (None, 40, 4)        40          ['layer_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_75 (Dropout)           (None, 40, 4)        0           ['conv1d_53[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_54 (Conv1D)             (None, 40, 9)        45          ['dropout_75[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_51 (TFOpL  (None, 40, 9)       0           ['conv1d_54[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_50[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_52 (LayerN  (None, 40, 9)       18          ['tf.__operators__.add_51[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_26 (Multi  (None, 40, 9)       9993        ['layer_normalization_52[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_76 (Dropout)           (None, 40, 9)        0           ['multi_head_attention_26[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_52 (TFOpL  (None, 40, 9)       0           ['dropout_76[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_51[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_53 (LayerN  (None, 40, 9)       18          ['tf.__operators__.add_52[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_55 (Conv1D)             (None, 40, 4)        40          ['layer_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_77 (Dropout)           (None, 40, 4)        0           ['conv1d_55[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_56 (Conv1D)             (None, 40, 9)        45          ['dropout_77[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_53 (TFOpL  (None, 40, 9)       0           ['conv1d_56[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_52[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_54 (LayerN  (None, 40, 9)       18          ['tf.__operators__.add_53[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_27 (Multi  (None, 40, 9)       9993        ['layer_normalization_54[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_78 (Dropout)           (None, 40, 9)        0           ['multi_head_attention_27[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_54 (TFOpL  (None, 40, 9)       0           ['dropout_78[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_53[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_55 (LayerN  (None, 40, 9)       18          ['tf.__operators__.add_54[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_57 (Conv1D)             (None, 40, 4)        40          ['layer_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_79 (Dropout)           (None, 40, 4)        0           ['conv1d_57[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_58 (Conv1D)             (None, 40, 9)        45          ['dropout_79[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_55 (TFOpL  (None, 40, 9)       0           ['conv1d_58[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_54[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_12 (G  (None, 40)          0           ['tf.__operators__.add_55[0][0]']\n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 128)          5248        ['global_average_pooling1d_12[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_80 (Dropout)           (None, 128)          0           ['dense_25[0][0]']               \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 5)            645         ['dropout_80[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 36,235\n",
      "Trainable params: 36,235\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "****************************************************\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# SETTING UP THE MODEL\n",
    "# model_name, model = make_cnn_model_v1(input_shape=input_shape)\n",
    "# model_name, model = make_lstm_model_v1(input_shape=input_shape)\n",
    "model_name, model = make_transformer_model_v1(\n",
    "    input_shape=input_shape,\n",
    "    head_size=64,\n",
    "    num_heads=4,\n",
    "    ff_dim=4,\n",
    "    num_transformer_blocks=3,\n",
    "    mlp_units=[128],\n",
    "    mlp_dropout=0.4,\n",
    "    dropout=0.25,\n",
    ")\n",
    "# model_name, model = make_transformer_model_v2(input_shape=input_shape)\n",
    "print(\"Model Summary:\")\n",
    "stringlist = []\n",
    "model.summary(print_fn=lambda x: stringlist.append(x))\n",
    "short_model_summary = \"\\n\".join(stringlist)\n",
    "print(short_model_summary)\n",
    "print(print_line_divider())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "# LOGGING THE MODEL\n",
    "log_writer.write(\"Model\", line_divider=True)\n",
    "log_writer.write(\"Model name: \" + model_name)\n",
    "log_writer.write(short_model_summary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "# MODELS CALLBACK AND SETUP\n",
    "callback_list = [\n",
    "    callbacks.ModelCheckpoint(SAVED_BEST_MODEL, save_best_only=True, monitor=\"val_loss\"),\n",
    "    callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=50, min_lr=0.0001),\n",
    "    callbacks.EarlyStopping(monitor=\"val_loss\", patience=200, verbose=1)\n",
    "]\n",
    "if enabled_tensor_board:\n",
    "    callback_list.append(callbacks.TensorBoard(log_dir=tensorboard_dir, histogram_freq=1))\n",
    "if log_writer.enabled:\n",
    "    callback_list.append(\n",
    "        callbacks.ModelCheckpoint(log_writer.base_folder + \"/model.h5\", save_best_only=True, monitor=\"val_loss\")\n",
    "    )\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss_function,\n",
    "    metrics=[\"sparse_categorical_accuracy\"],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************\n",
      "Starting to train...\n",
      "Epoch 1/1000\n",
      "166/166 [==============================] - 23s 123ms/step - loss: 1.1262 - sparse_categorical_accuracy: 0.4978 - val_loss: 0.7877 - val_sparse_categorical_accuracy: 0.6055 - lr: 0.0100\n",
      "Epoch 2/1000\n",
      "166/166 [==============================] - 21s 126ms/step - loss: 0.7201 - sparse_categorical_accuracy: 0.7141 - val_loss: 0.4917 - val_sparse_categorical_accuracy: 0.7882 - lr: 0.0100\n",
      "Epoch 3/1000\n",
      "166/166 [==============================] - 22s 131ms/step - loss: 0.5763 - sparse_categorical_accuracy: 0.7939 - val_loss: 0.6660 - val_sparse_categorical_accuracy: 0.7679 - lr: 0.0100\n",
      "Epoch 4/1000\n",
      "166/166 [==============================] - 20s 119ms/step - loss: 0.4929 - sparse_categorical_accuracy: 0.8231 - val_loss: 0.8863 - val_sparse_categorical_accuracy: 0.7149 - lr: 0.0100\n",
      "Epoch 5/1000\n",
      "166/166 [==============================] - 19s 112ms/step - loss: 0.4916 - sparse_categorical_accuracy: 0.8231 - val_loss: 0.6334 - val_sparse_categorical_accuracy: 0.7891 - lr: 0.0100\n",
      "Epoch 6/1000\n",
      "166/166 [==============================] - 19s 117ms/step - loss: 0.4398 - sparse_categorical_accuracy: 0.8448 - val_loss: 0.9863 - val_sparse_categorical_accuracy: 0.7026 - lr: 0.0100\n",
      "Epoch 7/1000\n",
      "166/166 [==============================] - 21s 125ms/step - loss: 0.4316 - sparse_categorical_accuracy: 0.8524 - val_loss: 0.9441 - val_sparse_categorical_accuracy: 0.7873 - lr: 0.0100\n",
      "Epoch 8/1000\n",
      "166/166 [==============================] - 19s 117ms/step - loss: 0.4467 - sparse_categorical_accuracy: 0.8431 - val_loss: 1.1971 - val_sparse_categorical_accuracy: 0.6567 - lr: 0.0100\n",
      "Epoch 9/1000\n",
      "166/166 [==============================] - 18s 110ms/step - loss: 0.3686 - sparse_categorical_accuracy: 0.8691 - val_loss: 1.6395 - val_sparse_categorical_accuracy: 0.7335 - lr: 0.0100\n",
      "Epoch 10/1000\n",
      "166/166 [==============================] - 21s 126ms/step - loss: 0.3736 - sparse_categorical_accuracy: 0.8728 - val_loss: 2.0270 - val_sparse_categorical_accuracy: 0.7034 - lr: 0.0100\n",
      "Epoch 11/1000\n",
      "166/166 [==============================] - 22s 135ms/step - loss: 0.4506 - sparse_categorical_accuracy: 0.8454 - val_loss: 2.2904 - val_sparse_categorical_accuracy: 0.7326 - lr: 0.0100\n",
      "Epoch 12/1000\n",
      "166/166 [==============================] - 19s 117ms/step - loss: 0.4328 - sparse_categorical_accuracy: 0.8498 - val_loss: 1.5134 - val_sparse_categorical_accuracy: 0.6911 - lr: 0.0100\n",
      "Epoch 13/1000\n",
      "166/166 [==============================] - 16s 97ms/step - loss: 0.4311 - sparse_categorical_accuracy: 0.8526 - val_loss: 0.6163 - val_sparse_categorical_accuracy: 0.7926 - lr: 0.0100\n",
      "Epoch 14/1000\n",
      "166/166 [==============================] - 16s 98ms/step - loss: 0.4126 - sparse_categorical_accuracy: 0.8609 - val_loss: 0.7523 - val_sparse_categorical_accuracy: 0.7758 - lr: 0.0100\n",
      "Epoch 15/1000\n",
      "166/166 [==============================] - 18s 106ms/step - loss: 0.3961 - sparse_categorical_accuracy: 0.8687 - val_loss: 1.0244 - val_sparse_categorical_accuracy: 0.7935 - lr: 0.0100\n",
      "Epoch 16/1000\n",
      "166/166 [==============================] - 21s 126ms/step - loss: 0.3534 - sparse_categorical_accuracy: 0.8802 - val_loss: 0.8927 - val_sparse_categorical_accuracy: 0.7732 - lr: 0.0100\n",
      "Epoch 17/1000\n",
      "166/166 [==============================] - 21s 128ms/step - loss: 0.3624 - sparse_categorical_accuracy: 0.8766 - val_loss: 0.6208 - val_sparse_categorical_accuracy: 0.7555 - lr: 0.0100\n",
      "Epoch 18/1000\n",
      "166/166 [==============================] - 22s 132ms/step - loss: 0.4203 - sparse_categorical_accuracy: 0.8604 - val_loss: 1.1070 - val_sparse_categorical_accuracy: 0.7149 - lr: 0.0100\n",
      "Epoch 19/1000\n",
      "166/166 [==============================] - 24s 146ms/step - loss: 0.6496 - sparse_categorical_accuracy: 0.8019 - val_loss: 1.1033 - val_sparse_categorical_accuracy: 0.8270 - lr: 0.0100\n",
      "Epoch 20/1000\n",
      "166/166 [==============================] - 24s 144ms/step - loss: 0.4183 - sparse_categorical_accuracy: 0.8647 - val_loss: 1.1766 - val_sparse_categorical_accuracy: 0.7811 - lr: 0.0100\n",
      "Epoch 21/1000\n",
      "166/166 [==============================] - 23s 141ms/step - loss: 0.6742 - sparse_categorical_accuracy: 0.7871 - val_loss: 0.6896 - val_sparse_categorical_accuracy: 0.8288 - lr: 0.0100\n",
      "Epoch 22/1000\n",
      "166/166 [==============================] - 18s 111ms/step - loss: 0.4010 - sparse_categorical_accuracy: 0.8653 - val_loss: 2.0551 - val_sparse_categorical_accuracy: 0.7882 - lr: 0.0100\n",
      "Epoch 23/1000\n",
      "166/166 [==============================] - 17s 100ms/step - loss: 0.3985 - sparse_categorical_accuracy: 0.8700 - val_loss: 0.5350 - val_sparse_categorical_accuracy: 0.8332 - lr: 0.0100\n",
      "Epoch 24/1000\n",
      "166/166 [==============================] - 18s 112ms/step - loss: 0.4012 - sparse_categorical_accuracy: 0.8702 - val_loss: 0.9339 - val_sparse_categorical_accuracy: 0.8605 - lr: 0.0100\n",
      "Epoch 25/1000\n",
      "166/166 [==============================] - 19s 114ms/step - loss: 0.3250 - sparse_categorical_accuracy: 0.8997 - val_loss: 0.7402 - val_sparse_categorical_accuracy: 0.8314 - lr: 0.0100\n",
      "Epoch 26/1000\n",
      "166/166 [==============================] - 19s 114ms/step - loss: 0.4604 - sparse_categorical_accuracy: 0.8562 - val_loss: 1.3757 - val_sparse_categorical_accuracy: 0.8067 - lr: 0.0100\n",
      "Epoch 27/1000\n",
      "166/166 [==============================] - 18s 110ms/step - loss: 0.3450 - sparse_categorical_accuracy: 0.8889 - val_loss: 1.4805 - val_sparse_categorical_accuracy: 0.4731 - lr: 0.0100\n",
      "Epoch 28/1000\n",
      "166/166 [==============================] - 19s 116ms/step - loss: 1.2954 - sparse_categorical_accuracy: 0.6057 - val_loss: 2.0283 - val_sparse_categorical_accuracy: 0.1606 - lr: 0.0100\n",
      "Epoch 29/1000\n",
      "166/166 [==============================] - 20s 118ms/step - loss: 1.6042 - sparse_categorical_accuracy: 0.2579 - val_loss: 1.6568 - val_sparse_categorical_accuracy: 0.1121 - lr: 0.0100\n",
      "Epoch 30/1000\n",
      "166/166 [==============================] - 20s 120ms/step - loss: 1.5452 - sparse_categorical_accuracy: 0.2772 - val_loss: 1.3831 - val_sparse_categorical_accuracy: 0.2816 - lr: 0.0100\n",
      "Epoch 31/1000\n",
      "166/166 [==============================] - 17s 105ms/step - loss: 1.4270 - sparse_categorical_accuracy: 0.3569 - val_loss: 1.3546 - val_sparse_categorical_accuracy: 0.2533 - lr: 0.0100\n",
      "Epoch 32/1000\n",
      "166/166 [==============================] - 18s 110ms/step - loss: 1.3137 - sparse_categorical_accuracy: 0.4231 - val_loss: 1.3210 - val_sparse_categorical_accuracy: 0.2833 - lr: 0.0100\n",
      "Epoch 33/1000\n",
      "166/166 [==============================] - 19s 113ms/step - loss: 1.2596 - sparse_categorical_accuracy: 0.4496 - val_loss: 1.3738 - val_sparse_categorical_accuracy: 0.2763 - lr: 0.0100\n",
      "Epoch 34/1000\n",
      "166/166 [==============================] - 18s 110ms/step - loss: 1.2340 - sparse_categorical_accuracy: 0.4660 - val_loss: 1.3075 - val_sparse_categorical_accuracy: 0.2436 - lr: 0.0100\n",
      "Epoch 35/1000\n",
      "166/166 [==============================] - 16s 97ms/step - loss: 1.2428 - sparse_categorical_accuracy: 0.4571 - val_loss: 1.0462 - val_sparse_categorical_accuracy: 0.6567 - lr: 0.0100\n",
      "Epoch 36/1000\n",
      "166/166 [==============================] - 15s 89ms/step - loss: 1.1324 - sparse_categorical_accuracy: 0.5576 - val_loss: 1.4116 - val_sparse_categorical_accuracy: 0.2560 - lr: 0.0100\n",
      "Epoch 37/1000\n",
      "166/166 [==============================] - 16s 95ms/step - loss: 1.2984 - sparse_categorical_accuracy: 0.4373 - val_loss: 1.4360 - val_sparse_categorical_accuracy: 0.2595 - lr: 0.0100\n",
      "Epoch 38/1000\n",
      "166/166 [==============================] - 15s 91ms/step - loss: 1.2067 - sparse_categorical_accuracy: 0.4715 - val_loss: 1.3242 - val_sparse_categorical_accuracy: 0.2577 - lr: 0.0100\n",
      "Epoch 39/1000\n",
      "166/166 [==============================] - 17s 105ms/step - loss: 1.2872 - sparse_categorical_accuracy: 0.4465 - val_loss: 1.3767 - val_sparse_categorical_accuracy: 0.2692 - lr: 0.0100\n",
      "Epoch 40/1000\n",
      "166/166 [==============================] - 18s 106ms/step - loss: 1.2395 - sparse_categorical_accuracy: 0.4556 - val_loss: 1.6946 - val_sparse_categorical_accuracy: 0.2639 - lr: 0.0100\n",
      "Epoch 41/1000\n",
      "166/166 [==============================] - 19s 112ms/step - loss: 1.2148 - sparse_categorical_accuracy: 0.4670 - val_loss: 1.2860 - val_sparse_categorical_accuracy: 0.2763 - lr: 0.0100\n",
      "Epoch 42/1000\n",
      "166/166 [==============================] - 17s 105ms/step - loss: 1.3923 - sparse_categorical_accuracy: 0.3905 - val_loss: 1.5542 - val_sparse_categorical_accuracy: 0.2065 - lr: 0.0100\n",
      "Epoch 43/1000\n",
      "166/166 [==============================] - 17s 105ms/step - loss: 1.5263 - sparse_categorical_accuracy: 0.2823 - val_loss: 1.4921 - val_sparse_categorical_accuracy: 0.1959 - lr: 0.0100\n",
      "Epoch 44/1000\n",
      "166/166 [==============================] - 15s 89ms/step - loss: 1.5181 - sparse_categorical_accuracy: 0.2833 - val_loss: 1.7035 - val_sparse_categorical_accuracy: 0.2630 - lr: 0.0100\n",
      "Epoch 45/1000\n",
      "166/166 [==============================] - 16s 94ms/step - loss: 1.4626 - sparse_categorical_accuracy: 0.3084 - val_loss: 1.3385 - val_sparse_categorical_accuracy: 0.2692 - lr: 0.0100\n",
      "Epoch 46/1000\n",
      "166/166 [==============================] - 15s 89ms/step - loss: 1.3756 - sparse_categorical_accuracy: 0.3868 - val_loss: 2.3094 - val_sparse_categorical_accuracy: 0.2754 - lr: 0.0100\n",
      "Epoch 47/1000\n",
      "166/166 [==============================] - 14s 86ms/step - loss: 1.4107 - sparse_categorical_accuracy: 0.3423 - val_loss: 1.3885 - val_sparse_categorical_accuracy: 0.2568 - lr: 0.0100\n",
      "Epoch 48/1000\n",
      "166/166 [==============================] - 16s 95ms/step - loss: 1.3233 - sparse_categorical_accuracy: 0.4235 - val_loss: 1.2954 - val_sparse_categorical_accuracy: 0.2613 - lr: 0.0100\n",
      "Epoch 49/1000\n",
      "166/166 [==============================] - 17s 104ms/step - loss: 1.3203 - sparse_categorical_accuracy: 0.4185 - val_loss: 3.0853 - val_sparse_categorical_accuracy: 0.2771 - lr: 0.0100\n",
      "Epoch 50/1000\n",
      "166/166 [==============================] - 21s 125ms/step - loss: 1.3334 - sparse_categorical_accuracy: 0.4161 - val_loss: 1.3694 - val_sparse_categorical_accuracy: 0.2657 - lr: 0.0100\n",
      "Epoch 51/1000\n",
      "166/166 [==============================] - 20s 119ms/step - loss: 1.2512 - sparse_categorical_accuracy: 0.4488 - val_loss: 1.8621 - val_sparse_categorical_accuracy: 0.2727 - lr: 0.0100\n",
      "Epoch 52/1000\n",
      "166/166 [==============================] - 21s 124ms/step - loss: 1.2530 - sparse_categorical_accuracy: 0.4515 - val_loss: 1.2861 - val_sparse_categorical_accuracy: 0.2551 - lr: 0.0100\n",
      "Epoch 53/1000\n",
      "166/166 [==============================] - 22s 131ms/step - loss: 1.3284 - sparse_categorical_accuracy: 0.4412 - val_loss: 1.3042 - val_sparse_categorical_accuracy: 0.2648 - lr: 0.0050\n",
      "Epoch 54/1000\n",
      "166/166 [==============================] - 23s 136ms/step - loss: 1.2306 - sparse_categorical_accuracy: 0.4675 - val_loss: 1.9838 - val_sparse_categorical_accuracy: 0.2692 - lr: 0.0050\n",
      "Epoch 55/1000\n",
      "166/166 [==============================] - 21s 129ms/step - loss: 1.2192 - sparse_categorical_accuracy: 0.4617 - val_loss: 2.2917 - val_sparse_categorical_accuracy: 0.2736 - lr: 0.0050\n",
      "Epoch 56/1000\n",
      "166/166 [==============================] - 22s 135ms/step - loss: 1.1815 - sparse_categorical_accuracy: 0.4734 - val_loss: 1.4319 - val_sparse_categorical_accuracy: 0.2763 - lr: 0.0050\n",
      "Epoch 57/1000\n",
      "166/166 [==============================] - 21s 125ms/step - loss: 1.2045 - sparse_categorical_accuracy: 0.4704 - val_loss: 1.8426 - val_sparse_categorical_accuracy: 0.2771 - lr: 0.0050\n",
      "Epoch 58/1000\n",
      "166/166 [==============================] - 22s 131ms/step - loss: 1.1749 - sparse_categorical_accuracy: 0.4783 - val_loss: 2.9244 - val_sparse_categorical_accuracy: 0.2683 - lr: 0.0050\n",
      "Epoch 59/1000\n",
      "166/166 [==============================] - 26s 157ms/step - loss: 1.1776 - sparse_categorical_accuracy: 0.4751 - val_loss: 1.3742 - val_sparse_categorical_accuracy: 0.2710 - lr: 0.0050\n",
      "Epoch 60/1000\n",
      "166/166 [==============================] - 26s 155ms/step - loss: 1.1433 - sparse_categorical_accuracy: 0.4876 - val_loss: 1.8820 - val_sparse_categorical_accuracy: 0.2771 - lr: 0.0050\n",
      "Epoch 61/1000\n",
      "166/166 [==============================] - 24s 145ms/step - loss: 1.1565 - sparse_categorical_accuracy: 0.4867 - val_loss: 1.2609 - val_sparse_categorical_accuracy: 0.2595 - lr: 0.0050\n",
      "Epoch 62/1000\n",
      "166/166 [==============================] - 23s 136ms/step - loss: 1.2149 - sparse_categorical_accuracy: 0.4778 - val_loss: 2.2593 - val_sparse_categorical_accuracy: 0.2692 - lr: 0.0050\n",
      "Epoch 63/1000\n",
      "166/166 [==============================] - 20s 123ms/step - loss: 1.2792 - sparse_categorical_accuracy: 0.4640 - val_loss: 1.5758 - val_sparse_categorical_accuracy: 0.2763 - lr: 0.0050\n",
      "Epoch 64/1000\n",
      "166/166 [==============================] - 21s 128ms/step - loss: 1.2662 - sparse_categorical_accuracy: 0.4530 - val_loss: 1.3026 - val_sparse_categorical_accuracy: 0.2683 - lr: 0.0050\n",
      "Epoch 65/1000\n",
      "166/166 [==============================] - 18s 111ms/step - loss: 1.2295 - sparse_categorical_accuracy: 0.4668 - val_loss: 1.2709 - val_sparse_categorical_accuracy: 0.2630 - lr: 0.0050\n",
      "Epoch 66/1000\n",
      "166/166 [==============================] - 16s 96ms/step - loss: 1.2619 - sparse_categorical_accuracy: 0.4556 - val_loss: 1.6628 - val_sparse_categorical_accuracy: 0.2639 - lr: 0.0050\n",
      "Epoch 67/1000\n",
      "166/166 [==============================] - 20s 120ms/step - loss: 1.2351 - sparse_categorical_accuracy: 0.4498 - val_loss: 1.4726 - val_sparse_categorical_accuracy: 0.2639 - lr: 0.0050\n",
      "Epoch 68/1000\n",
      "166/166 [==============================] - 20s 123ms/step - loss: 1.1983 - sparse_categorical_accuracy: 0.4749 - val_loss: 2.7208 - val_sparse_categorical_accuracy: 0.2736 - lr: 0.0050\n",
      "Epoch 69/1000\n",
      "166/166 [==============================] - 22s 130ms/step - loss: 1.2343 - sparse_categorical_accuracy: 0.4562 - val_loss: 1.5217 - val_sparse_categorical_accuracy: 0.2665 - lr: 0.0050\n",
      "Epoch 70/1000\n",
      "166/166 [==============================] - 21s 127ms/step - loss: 1.1846 - sparse_categorical_accuracy: 0.4746 - val_loss: 1.3801 - val_sparse_categorical_accuracy: 0.2392 - lr: 0.0050\n",
      "Epoch 71/1000\n",
      "166/166 [==============================] - 20s 118ms/step - loss: 1.2082 - sparse_categorical_accuracy: 0.4658 - val_loss: 2.0371 - val_sparse_categorical_accuracy: 0.2710 - lr: 0.0050\n",
      "Epoch 72/1000\n",
      "166/166 [==============================] - 21s 128ms/step - loss: 1.1677 - sparse_categorical_accuracy: 0.4791 - val_loss: 1.5192 - val_sparse_categorical_accuracy: 0.2701 - lr: 0.0050\n",
      "Epoch 73/1000\n",
      "166/166 [==============================] - 23s 140ms/step - loss: 1.1683 - sparse_categorical_accuracy: 0.4817 - val_loss: 1.5521 - val_sparse_categorical_accuracy: 0.2692 - lr: 0.0050\n",
      "Epoch 74/1000\n",
      "166/166 [==============================] - 23s 138ms/step - loss: 1.1443 - sparse_categorical_accuracy: 0.4874 - val_loss: 2.1004 - val_sparse_categorical_accuracy: 0.2674 - lr: 0.0050\n",
      "Epoch 75/1000\n",
      "166/166 [==============================] - 24s 147ms/step - loss: 1.2161 - sparse_categorical_accuracy: 0.4609 - val_loss: 1.4265 - val_sparse_categorical_accuracy: 0.2736 - lr: 0.0050\n",
      "Epoch 76/1000\n",
      "166/166 [==============================] - 21s 124ms/step - loss: 1.2028 - sparse_categorical_accuracy: 0.4749 - val_loss: 1.4361 - val_sparse_categorical_accuracy: 0.2727 - lr: 0.0050\n",
      "Epoch 77/1000\n",
      "109/166 [==================>...........] - ETA: 5s - loss: 1.1739 - sparse_categorical_accuracy: 0.4794"
     ]
    }
   ],
   "source": [
    "# TRAINING\n",
    "print_line_divider()\n",
    "print(\"Starting to train...\")\n",
    "\n",
    "start_time = time.time()\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=callback_list,\n",
    "    validation_split=validation_split,\n",
    "    verbose=1,\n",
    "    shuffle=True\n",
    ")\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(\"Total training time in seconds: \" + str(training_time))\n",
    "print(\"Highest validation accuracy: \", max(history.history['val_sparse_categorical_accuracy']))\n",
    "log_writer.write(\"Result\", line_divider=True)\n",
    "log_writer.write(\"Training time: \" + str(end_time - start_time) + \" seconds.\")\n",
    "log_writer.write(\"Highest validation accuracy: \" + str(max(history.history['val_sparse_categorical_accuracy'])))\n",
    "play_training_is_complete()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if log_writer.enabled:\n",
    "    model.save(log_writer.base_folder + \"/model_last.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# PLOTTING\n",
    "metric = \"sparse_categorical_accuracy\"\n",
    "plt.figure()\n",
    "plt.plot(history.history[metric])\n",
    "plt.plot(history.history[\"val_\" + metric])\n",
    "plt.title(\"model \" + model_name + \" :\" + metric)\n",
    "plt.ylabel(metric, fontsize=\"large\")\n",
    "plt.xlabel(\"epoch\", fontsize=\"large\")\n",
    "plt.legend([\"train\", \"val\"], loc=\"best\")\n",
    "if log_writer.enabled:\n",
    "    plt.savefig(os.path.join(log_writer.base_folder, \"Validation progress.png\"))\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# EVALUATION\n",
    "model = models.load_model(SAVED_BEST_MODEL)\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print_line_divider()\n",
    "print(\"Test accuracy\", test_acc)\n",
    "print(\"Test loss\", test_loss)\n",
    "\n",
    "# Accuracy based on different labels\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "metrics_report = classification_report(y_test, y_pred)\n",
    "print(\"Metrics report: \")\n",
    "print(metrics_report)\n",
    "\n",
    "con_mat = tf.math.confusion_matrix(labels=y_test, predictions=y_pred).numpy()\n",
    "con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=4)\n",
    "con_mat_df = pd.DataFrame(con_mat_norm, index=location_labels, columns=location_labels)\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(con_mat_df, annot=True, cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "if log_writer.enabled:\n",
    "    plt.savefig(os.path.join(log_writer.base_folder, \"Accuracy.png\"))\n",
    "plt.show()\n",
    "plt.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "log_writer.write(\"Test evaluation\", line_divider=True)\n",
    "log_writer.write(\"Test accuracy: \" + str(test_acc))\n",
    "log_writer.write(\"Test loss: \" + str(test_loss))\n",
    "log_writer.write(\"Metric report: \")\n",
    "log_writer.write(metrics_report)\n",
    "log_writer.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}