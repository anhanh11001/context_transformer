{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Step Detection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from datahandler.data_loader import load_data_from_file, load_date_from_steptracking_file\n",
    "from datahandler.constants import v4_walking, v4_mix\n",
    "import os\n",
    "from utils import print_line_divider\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import random, seed\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "seed(100)\n",
    "location_labels = ['holdinginhand', 'insidethebag', 'insidethepantpocket']"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Load file names"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['ds5', 'mm3', 'pp1', 'tt3', 'ds4', 'pp5', 'ds3', 'mm5', 'mm4', 'tt1', 'pp3', 'tt5'])\n"
     ]
    }
   ],
   "source": [
    "# Loading file names\n",
    "data_folder = v4_mix\n",
    "\n",
    "\n",
    "def get_all_files_from_folder(folder):\n",
    "    file_names = []\n",
    "    for datafile in os.listdir(folder):\n",
    "        if datafile.startswith(\".\"):\n",
    "            continue\n",
    "\n",
    "        path = os.path.join(folder, datafile)\n",
    "        if os.path.isfile(path):\n",
    "            file_names.append(datafile)\n",
    "    return file_names\n",
    "\n",
    "\n",
    "data_dict = {}\n",
    "for filename in get_all_files_from_folder(data_folder):\n",
    "    code = filename[:3]\n",
    "    data_dict[code] = os.path.join(data_folder, filename)\n",
    "\n",
    "step_dict = {}\n",
    "for filename in get_all_files_from_folder(data_folder + \"/step_fixed\"):\n",
    "    code = filename[:3]\n",
    "    if code in data_dict.keys():\n",
    "        step_dict[code] = os.path.join(data_folder, \"step\", filename)\n",
    "\n",
    "print(step_dict.keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# Configuration\n",
    "WINDOW_SIZE = 40\n",
    "WINDOW_LENGTH_IN_SECONDS = 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Load data from one file pair"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building model & configuration"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def load_data_from_code(code):\n",
    "    # Step 1\n",
    "    df = load_data_from_file(data_dict[code])\n",
    "    df = df.drop(\"labelActivity\", axis=1)\n",
    "    df['labelPhone'] = df['labelPhone'].apply(lambda x: location_labels.index(x))\n",
    "    # Step 2\n",
    "    step_dates = load_date_from_steptracking_file(step_dict[code])\n",
    "    # Step 3\n",
    "    fixed_size_data = []\n",
    "    fixed_size_indexes = []\n",
    "    current_timestamp = df.index[0].to_pydatetime()\n",
    "    last_timestamp_raw = df.index[df.shape[0] - 1].to_pydatetime()\n",
    "    current_timestamp_raw_index = 0\n",
    "    one_window_length_in_millis = WINDOW_LENGTH_IN_SECONDS * 1000 / WINDOW_SIZE\n",
    "    while True:\n",
    "        current_timestamp = current_timestamp + timedelta(milliseconds=one_window_length_in_millis)\n",
    "        if current_timestamp > last_timestamp_raw:\n",
    "            break\n",
    "\n",
    "        while current_timestamp_raw_index < df.shape[0] - 1:\n",
    "            next_timestamp_raw = df.index[current_timestamp_raw_index + 1].to_pydatetime()\n",
    "            if next_timestamp_raw < current_timestamp:\n",
    "                current_timestamp_raw_index += 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        fixed_size_data.append(df.iloc[current_timestamp_raw_index])\n",
    "        fixed_size_indexes.append(current_timestamp)\n",
    "    fixed_size_df = pd.DataFrame(\n",
    "        data=fixed_size_data,\n",
    "        index=fixed_size_indexes,\n",
    "        columns=df.columns\n",
    "    )\n",
    "\n",
    "    # Step 4\n",
    "    def update_date_microsecond(date, first_rem, second_rem):\n",
    "        current_microsecond = date.microsecond\n",
    "        new_microsecond_one = (int(current_microsecond / 100000) * 100 + first_rem) * 1000\n",
    "        new_microsecond_two = (int(current_microsecond / 100000) * 100 + second_rem) * 1000\n",
    "        diff_one = abs(current_microsecond - new_microsecond_one)\n",
    "        diff_two = abs(current_microsecond - new_microsecond_one)\n",
    "        if diff_one > diff_two:\n",
    "            new_microsecond = new_microsecond_two\n",
    "        else:\n",
    "            new_microsecond = new_microsecond_one\n",
    "        return date.replace(microsecond=new_microsecond)\n",
    "\n",
    "    index_first_date = fixed_size_df.index[0]\n",
    "    milli = index_first_date.microsecond / 1000\n",
    "    first_remainder = int(milli % 100)\n",
    "    second_remainder = int((milli + 50) % 100)\n",
    "\n",
    "    updated_step_dates = set()\n",
    "    for date in step_dates:\n",
    "        updated_step_dates.add(update_date_microsecond(date, first_remainder, second_remainder))\n",
    "\n",
    "    is_step_series = []\n",
    "    count = 0\n",
    "    for m in fixed_size_df.index:\n",
    "        is_step = m.to_pydatetime() in updated_step_dates\n",
    "        if is_step:\n",
    "            count += 1\n",
    "        is_step_series.append(is_step)\n",
    "\n",
    "    fixed_size_df['isStep'] = is_step_series\n",
    "\n",
    "    # Step 5\n",
    "    def normalize(df):\n",
    "        feature_count = df.shape[1] - 2\n",
    "        values = df.iloc[:, 0:feature_count]\n",
    "        phone_labels = df.loc[:, \"labelPhone\"].set_axis(range(df.shape[0]))\n",
    "        is_step = df.loc[:, \"isStep\"].set_axis(range(df.shape[0]))\n",
    "        normalizer = MinMaxScaler()\n",
    "        normalized_values = normalizer.fit_transform(values)\n",
    "        normalized_df = pd.DataFrame(\n",
    "            data=normalized_values,\n",
    "            columns=values.columns\n",
    "        )\n",
    "        normalized_df[\"labelPhone\"] = phone_labels\n",
    "        normalized_df[\"isStep\"] = is_step\n",
    "        return normalized_df\n",
    "\n",
    "    normalized_df = normalize(fixed_size_df)\n",
    "\n",
    "    # Step 6\n",
    "    def count_number_of_steps(list):\n",
    "        step_count = 0\n",
    "        for item in list:\n",
    "            if item:\n",
    "                step_count += 1\n",
    "        return step_count\n",
    "\n",
    "    def convert_df_to_final_train_data(df):\n",
    "\n",
    "        train_x, test_x = [], []\n",
    "        train_y_context, test_y_context = [], []\n",
    "        train_y_step, test_y_step = [], []\n",
    "\n",
    "        window_index_start = 0\n",
    "        window_index_increasing_size = int(WINDOW_SIZE / 8)  # 2\n",
    "        no_features = df.shape[1] - 2\n",
    "        values = df.iloc[:, 0:no_features]\n",
    "        context_labels = df.loc[:, \"labelPhone\"]\n",
    "        step_found = df.loc[:, \"isStep\"]\n",
    "\n",
    "        while window_index_start + WINDOW_SIZE < df.shape[0]:\n",
    "            train_data = values[window_index_start:(window_index_start + WINDOW_SIZE)]\n",
    "            context_label = context_labels[window_index_start]\n",
    "            step_count = count_number_of_steps(step_found[window_index_start:(window_index_start + WINDOW_SIZE)])\n",
    "\n",
    "            if random() < 0.15:\n",
    "                test_x.append(train_data)\n",
    "                test_y_context.append(context_label)\n",
    "                test_y_step.append(step_count)\n",
    "            else:\n",
    "                train_x.append(train_data)\n",
    "                train_y_context.append(context_label)\n",
    "                train_y_step.append(step_count)\n",
    "\n",
    "            window_index_start += window_index_increasing_size\n",
    "\n",
    "        return train_x, train_y_step, train_y_context, test_x, test_y_step, test_y_context\n",
    "\n",
    "    return convert_df_to_final_train_data(normalized_df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling data from code tt1\n",
      "Handling data from code pp1\n",
      "Handling data from code ds4\n",
      "Handling data from code tt5\n",
      "Handling data from code pp5\n",
      "Handling data from code ds3\n",
      "Handling data from code tt3\n",
      "Handling data from code pp3\n",
      "Handling data from code ds5\n",
      "****************************************************\n",
      "(9167, 40, 9) (9167,) (9167,)\n",
      "(1626, 40, 9) (1626,) (1626,)\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y_step, train_y_context = [], [], []\n",
    "test_x, test_y_step, test_y_context = [], [], []\n",
    "\n",
    "# mm, tt, pp, ds, os\n",
    "inside_pant_pocket = [\"tt1\", \"pp1\", \"ds4\"]  # 75%\n",
    "inside_the_bag = [\"tt5\", \"pp5\", \"ds3\"]\n",
    "swinging_in_hand = [\"tt3\", \"pp3\", \"ds5\"]\n",
    "all_data = inside_pant_pocket + inside_the_bag + swinging_in_hand\n",
    "for code in all_data:\n",
    "    print(\"Handling data from code \" + code)\n",
    "    a, c, d, e, g, h = load_data_from_code(code)\n",
    "\n",
    "    train_x = train_x + a\n",
    "    train_y_step = train_y_step + c\n",
    "    train_y_context = train_y_context + d\n",
    "    test_x = test_x + e\n",
    "    test_y_step = test_y_step + g\n",
    "    test_y_context = test_y_context + h\n",
    "\n",
    "train_x = np.array(train_x)\n",
    "train_y_step = np.array(train_y_step)\n",
    "train_y_context = np.array(train_y_context)\n",
    "test_x = np.array(test_x)\n",
    "test_y_step = np.array(test_y_step)\n",
    "test_y_context = np.array(test_y_context)\n",
    "\n",
    "print_line_divider()\n",
    "print(train_x.shape, train_y_step.shape, train_y_context.shape)\n",
    "print(test_x.shape, test_y_step.shape, test_y_context.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training and testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Simple binary classifier using CNN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 40, 9)]           0         \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 40, 64)            1792      \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 40, 64)           256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_6 (ReLU)              (None, 40, 64)            0         \n",
      "                                                                 \n",
      " conv1d_10 (Conv1D)          (None, 40, 64)            12352     \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 40, 64)           256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_7 (ReLU)              (None, 40, 64)            0         \n",
      "                                                                 \n",
      " global_average_pooling1d_2   (None, 64)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,105\n",
      "Trainable params: 22,849\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers, models, Sequential\n",
    "from models.log_writer import LogWriter\n",
    "\n",
    "log_writer = LogWriter(enabled=True)\n",
    "\n",
    "\n",
    "def build_shallow_cnn(input_shape):\n",
    "    model_2d = Sequential()\n",
    "    model_2d.add(\n",
    "        layers.Conv1D(\n",
    "            filters=12,\n",
    "            kernel_size=3,\n",
    "            strides=1,\n",
    "            padding=\"same\",\n",
    "            activation='relu',\n",
    "            input_shape=input_shape)\n",
    "    )\n",
    "    model_2d.add(layers.Dropout(0.1))\n",
    "    model_2d.add(layers.MaxPooling1D(pool_size=2, strides=2, padding=\"valid\"))\n",
    "    model_2d.add(layers.Flatten())\n",
    "    model_2d.add(layers.Dense(50, activation='relu'))\n",
    "    model_2d.add(layers.Dropout(0.4))\n",
    "    model_2d.add(layers.Dense(1, activation='relu'))\n",
    "    return model_2d\n",
    "\n",
    "\n",
    "def build_cnn_step_model(input_shape):\n",
    "    input_layer = layers.Input(input_shape)\n",
    "    conv1 = layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(input_layer)\n",
    "    conv1 = layers.BatchNormalization()(conv1)\n",
    "    conv1 = layers.ReLU()(conv1)\n",
    "    conv2 = layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(conv1)\n",
    "    conv2 = layers.BatchNormalization()(conv2)\n",
    "    conv2 = layers.ReLU()(conv2)\n",
    "    conv3 = layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(conv2)\n",
    "    conv3 = layers.BatchNormalization()(conv2)\n",
    "    conv3 = layers.ReLU()(conv1)\n",
    "    gap = layers.GlobalAveragePooling1D()(conv2)\n",
    "    dense = layers.Dense(128, activation='relu')(gap)\n",
    "    output_layer = layers.Dense(1, activation=\"relu\")(dense)\n",
    "\n",
    "    return models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "\n",
    "model = build_cnn_step_model((40, 9))\n",
    "# model = build_shallow_cnn((40,9))\n",
    "model.summary()\n",
    "stringlist = []\n",
    "model.summary(print_fn=lambda x: stringlist.append(x))\n",
    "short_model_summary = \"\\n\".join(stringlist)\n",
    "log_writer.write(\"Model Configuration\", line_divider=True)\n",
    "log_writer.write(short_model_summary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "236/236 [==============================] - 3s 10ms/step - loss: 0.8571 - val_loss: 1.9659 - lr: 0.0050\n",
      "Epoch 2/300\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.6733 - val_loss: 1.1174 - lr: 0.0050\n",
      "Epoch 3/300\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.6150 - val_loss: 1.4433 - lr: 0.0050\n",
      "Epoch 4/300\n",
      "236/236 [==============================] - 2s 7ms/step - loss: 0.6078 - val_loss: 1.3773 - lr: 0.0050\n",
      "Epoch 5/300\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.5777 - val_loss: 0.9599 - lr: 0.0050\n",
      "Epoch 6/300\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.5521 - val_loss: 1.2816 - lr: 0.0050\n",
      "Epoch 7/300\n",
      "236/236 [==============================] - 2s 9ms/step - loss: 0.5422 - val_loss: 1.9329 - lr: 0.0050\n",
      "Epoch 8/300\n",
      "236/236 [==============================] - 2s 9ms/step - loss: 0.5223 - val_loss: 1.5161 - lr: 0.0050\n",
      "Epoch 9/300\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.5230 - val_loss: 1.5408 - lr: 0.0050\n",
      "Epoch 10/300\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.5006 - val_loss: 2.9419 - lr: 0.0050\n",
      "Epoch 11/300\n",
      "236/236 [==============================] - 2s 8ms/step - loss: 0.4752 - val_loss: 1.5561 - lr: 0.0050\n",
      "Epoch 12/300\n",
      "236/236 [==============================] - 2s 9ms/step - loss: 0.4647 - val_loss: 1.3097 - lr: 0.0050\n",
      "Epoch 13/300\n",
      "236/236 [==============================] - 2s 9ms/step - loss: 0.4446 - val_loss: 1.7436 - lr: 0.0050\n",
      "Epoch 14/300\n",
      "236/236 [==============================] - 2s 9ms/step - loss: 0.4375 - val_loss: 1.4968 - lr: 0.0050\n",
      "Epoch 15/300\n",
      "236/236 [==============================] - 2s 9ms/step - loss: 0.4296 - val_loss: 1.3041 - lr: 0.0050\n",
      "Epoch 16/300\n",
      "236/236 [==============================] - 2s 10ms/step - loss: 0.4171 - val_loss: 2.1872 - lr: 0.0050\n",
      "Epoch 17/300\n",
      "236/236 [==============================] - 2s 10ms/step - loss: 0.4201 - val_loss: 2.2863 - lr: 0.0050\n",
      "Epoch 18/300\n",
      "236/236 [==============================] - 2s 10ms/step - loss: 0.4060 - val_loss: 1.6422 - lr: 0.0050\n",
      "Epoch 19/300\n",
      "236/236 [==============================] - 2s 10ms/step - loss: 0.3853 - val_loss: 1.2848 - lr: 0.0050\n",
      "Epoch 20/300\n",
      "236/236 [==============================] - 2s 10ms/step - loss: 0.3760 - val_loss: 1.4775 - lr: 0.0050\n",
      "Epoch 21/300\n",
      "236/236 [==============================] - 2s 10ms/step - loss: 0.3551 - val_loss: 3.3904 - lr: 0.0050\n",
      "Epoch 22/300\n",
      "236/236 [==============================] - 2s 11ms/step - loss: 0.3647 - val_loss: 2.2120 - lr: 0.0050\n",
      "Epoch 23/300\n",
      "236/236 [==============================] - 2s 10ms/step - loss: 0.3532 - val_loss: 1.8510 - lr: 0.0050\n",
      "Epoch 24/300\n",
      "236/236 [==============================] - 2s 10ms/step - loss: 0.3255 - val_loss: 1.6736 - lr: 0.0050\n",
      "Epoch 25/300\n",
      "236/236 [==============================] - 2s 10ms/step - loss: 0.3290 - val_loss: 1.8082 - lr: 0.0050\n",
      "Epoch 26/300\n",
      "236/236 [==============================] - 2s 10ms/step - loss: 0.3108 - val_loss: 1.4324 - lr: 0.0050\n",
      "Epoch 27/300\n",
      "236/236 [==============================] - 2s 10ms/step - loss: 0.3208 - val_loss: 1.9396 - lr: 0.0050\n",
      "Epoch 28/300\n",
      "236/236 [==============================] - 2s 10ms/step - loss: 0.3032 - val_loss: 2.6075 - lr: 0.0050\n",
      "Epoch 29/300\n",
      "236/236 [==============================] - 2s 10ms/step - loss: 0.3136 - val_loss: 2.1629 - lr: 0.0050\n",
      "Epoch 30/300\n",
      "236/236 [==============================] - 2s 10ms/step - loss: 0.3114 - val_loss: 2.2208 - lr: 0.0050\n",
      "Epoch 31/300\n",
      "236/236 [==============================] - 3s 11ms/step - loss: 0.3038 - val_loss: 1.2518 - lr: 0.0050\n",
      "Epoch 32/300\n",
      "236/236 [==============================] - 3s 11ms/step - loss: 0.2747 - val_loss: 1.7938 - lr: 0.0050\n",
      "Epoch 33/300\n",
      "236/236 [==============================] - 3s 11ms/step - loss: 0.2942 - val_loss: 2.5930 - lr: 0.0050\n",
      "Epoch 34/300\n",
      "236/236 [==============================] - 3s 11ms/step - loss: 0.2645 - val_loss: 2.1615 - lr: 0.0050\n",
      "Epoch 35/300\n",
      "236/236 [==============================] - 3s 11ms/step - loss: 0.2816 - val_loss: 2.0494 - lr: 0.0050\n",
      "Epoch 36/300\n",
      "236/236 [==============================] - 3s 11ms/step - loss: 0.2433 - val_loss: 2.1504 - lr: 0.0025\n",
      "Epoch 37/300\n",
      "236/236 [==============================] - 3s 11ms/step - loss: 0.2210 - val_loss: 1.9795 - lr: 0.0025\n",
      "Epoch 38/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.2221 - val_loss: 2.1614 - lr: 0.0025\n",
      "Epoch 39/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.2265 - val_loss: 2.1275 - lr: 0.0025\n",
      "Epoch 40/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.2202 - val_loss: 1.9398 - lr: 0.0025\n",
      "Epoch 41/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.2226 - val_loss: 1.8265 - lr: 0.0025\n",
      "Epoch 42/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.2156 - val_loss: 1.7771 - lr: 0.0025\n",
      "Epoch 43/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.2158 - val_loss: 2.0040 - lr: 0.0025\n",
      "Epoch 44/300\n",
      "236/236 [==============================] - 3s 11ms/step - loss: 0.2151 - val_loss: 2.1059 - lr: 0.0025\n",
      "Epoch 45/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.2084 - val_loss: 1.9637 - lr: 0.0025\n",
      "Epoch 46/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.2119 - val_loss: 2.0978 - lr: 0.0025\n",
      "Epoch 47/300\n",
      "236/236 [==============================] - 3s 11ms/step - loss: 0.2054 - val_loss: 1.9759 - lr: 0.0025\n",
      "Epoch 48/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.2049 - val_loss: 2.0709 - lr: 0.0025\n",
      "Epoch 49/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.2140 - val_loss: 2.0705 - lr: 0.0025\n",
      "Epoch 50/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1964 - val_loss: 2.1352 - lr: 0.0025\n",
      "Epoch 51/300\n",
      "236/236 [==============================] - 3s 13ms/step - loss: 0.2022 - val_loss: 1.6935 - lr: 0.0025\n",
      "Epoch 52/300\n",
      "236/236 [==============================] - 3s 13ms/step - loss: 0.1983 - val_loss: 1.9819 - lr: 0.0025\n",
      "Epoch 53/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.2001 - val_loss: 2.2010 - lr: 0.0025\n",
      "Epoch 54/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.2028 - val_loss: 2.1214 - lr: 0.0025\n",
      "Epoch 55/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1973 - val_loss: 2.2078 - lr: 0.0025\n",
      "Epoch 56/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.2093 - val_loss: 1.9884 - lr: 0.0025\n",
      "Epoch 57/300\n",
      "236/236 [==============================] - 3s 13ms/step - loss: 0.1953 - val_loss: 1.7610 - lr: 0.0025\n",
      "Epoch 58/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1861 - val_loss: 1.6631 - lr: 0.0025\n",
      "Epoch 59/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1987 - val_loss: 1.8717 - lr: 0.0025\n",
      "Epoch 60/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1963 - val_loss: 2.2981 - lr: 0.0025\n",
      "Epoch 61/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1936 - val_loss: 2.0921 - lr: 0.0025\n",
      "Epoch 62/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1835 - val_loss: 1.9429 - lr: 0.0025\n",
      "Epoch 63/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1923 - val_loss: 2.3606 - lr: 0.0025\n",
      "Epoch 64/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1932 - val_loss: 1.8187 - lr: 0.0025\n",
      "Epoch 65/300\n",
      "236/236 [==============================] - 3s 11ms/step - loss: 0.1826 - val_loss: 1.8397 - lr: 0.0025\n",
      "Epoch 66/300\n",
      "236/236 [==============================] - 3s 11ms/step - loss: 0.1671 - val_loss: 2.1026 - lr: 0.0012\n",
      "Epoch 67/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1679 - val_loss: 2.1850 - lr: 0.0012\n",
      "Epoch 68/300\n",
      "236/236 [==============================] - 3s 11ms/step - loss: 0.1630 - val_loss: 1.9615 - lr: 0.0012\n",
      "Epoch 69/300\n",
      "236/236 [==============================] - 3s 11ms/step - loss: 0.1615 - val_loss: 2.0012 - lr: 0.0012\n",
      "Epoch 70/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1646 - val_loss: 2.1056 - lr: 0.0012\n",
      "Epoch 71/300\n",
      "236/236 [==============================] - 3s 13ms/step - loss: 0.1670 - val_loss: 1.9218 - lr: 0.0012\n",
      "Epoch 72/300\n",
      "236/236 [==============================] - 4s 16ms/step - loss: 0.1683 - val_loss: 2.5274 - lr: 0.0012\n",
      "Epoch 73/300\n",
      "236/236 [==============================] - 3s 13ms/step - loss: 0.1592 - val_loss: 1.9034 - lr: 0.0012\n",
      "Epoch 74/300\n",
      "236/236 [==============================] - 3s 13ms/step - loss: 0.1569 - val_loss: 2.0277 - lr: 0.0012\n",
      "Epoch 75/300\n",
      "236/236 [==============================] - 3s 13ms/step - loss: 0.1609 - val_loss: 1.9155 - lr: 0.0012\n",
      "Epoch 76/300\n",
      "236/236 [==============================] - 3s 14ms/step - loss: 0.1612 - val_loss: 2.4502 - lr: 0.0012\n",
      "Epoch 77/300\n",
      "236/236 [==============================] - 3s 15ms/step - loss: 0.1650 - val_loss: 2.4898 - lr: 0.0012\n",
      "Epoch 78/300\n",
      "236/236 [==============================] - 3s 13ms/step - loss: 0.1635 - val_loss: 1.9877 - lr: 0.0012\n",
      "Epoch 79/300\n",
      "236/236 [==============================] - 3s 15ms/step - loss: 0.1639 - val_loss: 1.7945 - lr: 0.0012\n",
      "Epoch 80/300\n",
      "236/236 [==============================] - 4s 17ms/step - loss: 0.1559 - val_loss: 1.9606 - lr: 0.0012\n",
      "Epoch 81/300\n",
      "236/236 [==============================] - 3s 15ms/step - loss: 0.1567 - val_loss: 1.8889 - lr: 0.0012\n",
      "Epoch 82/300\n",
      "236/236 [==============================] - 3s 14ms/step - loss: 0.1520 - val_loss: 2.2031 - lr: 0.0012\n",
      "Epoch 83/300\n",
      "236/236 [==============================] - 3s 14ms/step - loss: 0.1550 - val_loss: 1.9401 - lr: 0.0012\n",
      "Epoch 84/300\n",
      "236/236 [==============================] - 3s 14ms/step - loss: 0.1522 - val_loss: 2.1815 - lr: 0.0012\n",
      "Epoch 85/300\n",
      "236/236 [==============================] - 3s 14ms/step - loss: 0.1534 - val_loss: 1.9568 - lr: 0.0012\n",
      "Epoch 86/300\n",
      "236/236 [==============================] - 3s 14ms/step - loss: 0.1530 - val_loss: 2.3666 - lr: 0.0012\n",
      "Epoch 87/300\n",
      "236/236 [==============================] - 3s 13ms/step - loss: 0.1505 - val_loss: 2.0697 - lr: 0.0012\n",
      "Epoch 88/300\n",
      "236/236 [==============================] - 3s 13ms/step - loss: 0.1495 - val_loss: 1.8436 - lr: 0.0012\n",
      "Epoch 89/300\n",
      "236/236 [==============================] - 3s 13ms/step - loss: 0.1533 - val_loss: 1.7852 - lr: 0.0012\n",
      "Epoch 90/300\n",
      "236/236 [==============================] - 3s 15ms/step - loss: 0.1519 - val_loss: 1.9493 - lr: 0.0012\n",
      "Epoch 91/300\n",
      "236/236 [==============================] - 3s 14ms/step - loss: 0.1541 - val_loss: 1.9176 - lr: 0.0012\n",
      "Epoch 92/300\n",
      "236/236 [==============================] - 3s 14ms/step - loss: 0.1480 - val_loss: 1.8693 - lr: 0.0012\n",
      "Epoch 93/300\n",
      "236/236 [==============================] - 3s 14ms/step - loss: 0.1482 - val_loss: 1.7001 - lr: 0.0012\n",
      "Epoch 94/300\n",
      "236/236 [==============================] - 3s 13ms/step - loss: 0.1462 - val_loss: 1.9738 - lr: 0.0012\n",
      "Epoch 95/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1467 - val_loss: 1.8853 - lr: 0.0012\n",
      "Epoch 96/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1381 - val_loss: 1.9551 - lr: 6.2500e-04\n",
      "Epoch 97/300\n",
      "236/236 [==============================] - 3s 13ms/step - loss: 0.1370 - val_loss: 1.8931 - lr: 6.2500e-04\n",
      "Epoch 98/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1372 - val_loss: 1.8462 - lr: 6.2500e-04\n",
      "Epoch 99/300\n",
      "236/236 [==============================] - 3s 13ms/step - loss: 0.1370 - val_loss: 2.0523 - lr: 6.2500e-04\n",
      "Epoch 100/300\n",
      "236/236 [==============================] - 3s 13ms/step - loss: 0.1321 - val_loss: 1.9961 - lr: 6.2500e-04\n",
      "Epoch 101/300\n",
      "236/236 [==============================] - 3s 13ms/step - loss: 0.1358 - val_loss: 1.8560 - lr: 6.2500e-04\n",
      "Epoch 102/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1352 - val_loss: 1.9266 - lr: 6.2500e-04\n",
      "Epoch 103/300\n",
      "236/236 [==============================] - 3s 13ms/step - loss: 0.1318 - val_loss: 1.9203 - lr: 6.2500e-04\n",
      "Epoch 104/300\n",
      "236/236 [==============================] - 4s 15ms/step - loss: 0.1358 - val_loss: 1.9249 - lr: 6.2500e-04\n",
      "Epoch 105/300\n",
      "236/236 [==============================] - 3s 13ms/step - loss: 0.1398 - val_loss: 1.8945 - lr: 6.2500e-04\n",
      "Epoch 106/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1338 - val_loss: 1.9287 - lr: 6.2500e-04\n",
      "Epoch 107/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1345 - val_loss: 1.9468 - lr: 6.2500e-04\n",
      "Epoch 108/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1321 - val_loss: 2.0123 - lr: 6.2500e-04\n",
      "Epoch 109/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1323 - val_loss: 1.8691 - lr: 6.2500e-04\n",
      "Epoch 110/300\n",
      "236/236 [==============================] - 3s 13ms/step - loss: 0.1314 - val_loss: 1.9017 - lr: 6.2500e-04\n",
      "Epoch 111/300\n",
      "236/236 [==============================] - 3s 11ms/step - loss: 0.1333 - val_loss: 1.9267 - lr: 6.2500e-04\n",
      "Epoch 112/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1353 - val_loss: 1.9389 - lr: 6.2500e-04\n",
      "Epoch 113/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1305 - val_loss: 2.0744 - lr: 6.2500e-04\n",
      "Epoch 114/300\n",
      "236/236 [==============================] - 3s 13ms/step - loss: 0.1325 - val_loss: 2.0336 - lr: 6.2500e-04\n",
      "Epoch 115/300\n",
      "236/236 [==============================] - 3s 13ms/step - loss: 0.1309 - val_loss: 1.9865 - lr: 6.2500e-04\n",
      "Epoch 116/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1341 - val_loss: 1.9979 - lr: 6.2500e-04\n",
      "Epoch 117/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1307 - val_loss: 1.9697 - lr: 6.2500e-04\n",
      "Epoch 118/300\n",
      "236/236 [==============================] - 3s 13ms/step - loss: 0.1340 - val_loss: 1.9823 - lr: 6.2500e-04\n",
      "Epoch 119/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1318 - val_loss: 2.1243 - lr: 6.2500e-04\n",
      "Epoch 120/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1310 - val_loss: 1.9133 - lr: 6.2500e-04\n",
      "Epoch 121/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1251 - val_loss: 1.8783 - lr: 6.2500e-04\n",
      "Epoch 122/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1252 - val_loss: 2.0167 - lr: 6.2500e-04\n",
      "Epoch 123/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1268 - val_loss: 1.8557 - lr: 6.2500e-04\n",
      "Epoch 124/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1295 - val_loss: 1.7894 - lr: 6.2500e-04\n",
      "Epoch 125/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1233 - val_loss: 1.8408 - lr: 6.2500e-04\n",
      "Epoch 126/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1217 - val_loss: 1.9089 - lr: 3.1250e-04\n",
      "Epoch 127/300\n",
      "236/236 [==============================] - 3s 13ms/step - loss: 0.1227 - val_loss: 1.8762 - lr: 3.1250e-04\n",
      "Epoch 128/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1250 - val_loss: 1.8663 - lr: 3.1250e-04\n",
      "Epoch 129/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1237 - val_loss: 1.9368 - lr: 3.1250e-04\n",
      "Epoch 130/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1159 - val_loss: 1.8564 - lr: 3.1250e-04\n",
      "Epoch 131/300\n",
      "236/236 [==============================] - 3s 13ms/step - loss: 0.1186 - val_loss: 1.8686 - lr: 3.1250e-04\n",
      "Epoch 132/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1226 - val_loss: 1.9195 - lr: 3.1250e-04\n",
      "Epoch 133/300\n",
      "236/236 [==============================] - 3s 11ms/step - loss: 0.1213 - val_loss: 1.8297 - lr: 3.1250e-04\n",
      "Epoch 134/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1232 - val_loss: 1.8322 - lr: 3.1250e-04\n",
      "Epoch 135/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1260 - val_loss: 1.9013 - lr: 3.1250e-04\n",
      "Epoch 136/300\n",
      "236/236 [==============================] - 3s 13ms/step - loss: 0.1253 - val_loss: 1.9042 - lr: 3.1250e-04\n",
      "Epoch 137/300\n",
      "236/236 [==============================] - 3s 13ms/step - loss: 0.1216 - val_loss: 1.8866 - lr: 3.1250e-04\n",
      "Epoch 138/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1222 - val_loss: 1.8595 - lr: 3.1250e-04\n",
      "Epoch 139/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1192 - val_loss: 1.8855 - lr: 3.1250e-04\n",
      "Epoch 140/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1240 - val_loss: 1.9096 - lr: 3.1250e-04\n",
      "Epoch 141/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1214 - val_loss: 1.9049 - lr: 3.1250e-04\n",
      "Epoch 142/300\n",
      "236/236 [==============================] - 3s 13ms/step - loss: 0.1191 - val_loss: 1.9850 - lr: 3.1250e-04\n",
      "Epoch 143/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1173 - val_loss: 1.9959 - lr: 3.1250e-04\n",
      "Epoch 144/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1191 - val_loss: 1.9595 - lr: 3.1250e-04\n",
      "Epoch 145/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1229 - val_loss: 1.9046 - lr: 3.1250e-04\n",
      "Epoch 146/300\n",
      "236/236 [==============================] - 3s 13ms/step - loss: 0.1252 - val_loss: 1.8876 - lr: 3.1250e-04\n",
      "Epoch 147/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1191 - val_loss: 1.8018 - lr: 3.1250e-04\n",
      "Epoch 148/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1212 - val_loss: 1.9028 - lr: 3.1250e-04\n",
      "Epoch 149/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1200 - val_loss: 1.8876 - lr: 3.1250e-04\n",
      "Epoch 150/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1212 - val_loss: 1.8546 - lr: 3.1250e-04\n",
      "Epoch 151/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1152 - val_loss: 1.9731 - lr: 3.1250e-04\n",
      "Epoch 152/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1234 - val_loss: 1.9709 - lr: 3.1250e-04\n",
      "Epoch 153/300\n",
      "236/236 [==============================] - 3s 13ms/step - loss: 0.1207 - val_loss: 1.8714 - lr: 3.1250e-04\n",
      "Epoch 154/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1197 - val_loss: 1.8939 - lr: 3.1250e-04\n",
      "Epoch 155/300\n",
      "236/236 [==============================] - 3s 12ms/step - loss: 0.1150 - val_loss: 1.9176 - lr: 3.1250e-04\n",
      "Epoch 155: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/ph/8yv0q18n4mb1439tnf3rzcf40000gp/T/tmpl0i72jd1.wav':\n",
      "  Duration: 00:00:02.27, bitrate: 705 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, 1 channels, s16, 705 kb/s\n",
      "   2.20 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B f=0/0   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from keras import callbacks\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "from audio.audio import play_training_is_complete\n",
    "\n",
    "SAVED_BEST_MODEL = \"model/best_step_model.h5\"\n",
    "reduce_lr_patience = 30\n",
    "early_stopping_patience = 150\n",
    "callback_list = [\n",
    "    callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=reduce_lr_patience, min_lr=0.0001),\n",
    "    callbacks.EarlyStopping(monitor=\"val_loss\", patience=early_stopping_patience, verbose=1),\n",
    "    callbacks.ModelCheckpoint(SAVED_BEST_MODEL, save_best_only=True, monitor=\"val_loss\")\n",
    "]\n",
    "if log_writer.enabled:\n",
    "    callback_list.append(\n",
    "        callbacks.ModelCheckpoint(log_writer.base_folder + \"/model.h5\", save_best_only=True, monitor=\"val_loss\")\n",
    "    )\n",
    "epochs = 300\n",
    "batch_size = 32\n",
    "validation_split = 15 / 85\n",
    "adam_starting_lr = 0.005\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=adam_starting_lr,\n",
    "    name=\"Adam\",\n",
    ")\n",
    "\n",
    "loss_function = \"mse\"\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss_function,\n",
    "    # metrics=['accuracy']\n",
    ")\n",
    "\n",
    "log_writer.write(\n",
    "    f\"\"\"Epoch: {epochs}\n",
    "Batch size: {batch_size}\n",
    "Validation split: {validation_split}\n",
    "Optimizer: Adam with starting lr {adam_starting_lr}\n",
    "Loss function: {loss_function}\n",
    "Reduce LR patience: {reduce_lr_patience}\n",
    "Early stopping patience: {early_stopping_patience}\n",
    "\"\"\"\n",
    ")\n",
    "log_writer.write(\"Data Configuration\", line_divider=True)\n",
    "log_writer.write(\n",
    "    f\"\"\"Data training shape: ${train_x.shape}\n",
    "Data testing shape: ${test_x.shape}\"\"\"\n",
    ")\n",
    "start_time = time()\n",
    "history = model.fit(\n",
    "    train_x,\n",
    "    train_y_step,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=callback_list,\n",
    "    validation_split=validation_split,\n",
    "    verbose=1,\n",
    "    shuffle=True\n",
    ")\n",
    "end_time = time()\n",
    "training_time = end_time - start_time\n",
    "log_writer.write(\"Result\", line_divider=True)\n",
    "log_writer.write(\"Training time: \" + str(end_time - start_time) + \" seconds.\")\n",
    "log_writer.write(\"Smallest validation loss: \" + str(min(history.history['val_loss'])))\n",
    "model = models.load_model(SAVED_BEST_MODEL)\n",
    "play_training_is_complete()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the result\n",
    "metric = \"loss\"\n",
    "plt.figure()\n",
    "plt.plot(history.history[metric])\n",
    "plt.plot(history.history[\"val_\" + metric])\n",
    "plt.title(\"CNN:\" + metric)\n",
    "plt.ylabel(metric, fontsize=\"large\")\n",
    "plt.xlabel(\"epoch\", fontsize=\"large\")\n",
    "plt.legend([\"train\", \"val\"], loc=\"best\")\n",
    "if log_writer.enabled:\n",
    "    plt.savefig(os.path.join(log_writer.base_folder, \"Validation progress.png\"))\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct:  2\n",
      "Incorrect: index -  1  | base -  2.3244262  | predict -  2  | actual -  3\n",
      "Incorrect: index -  2  | base -  2.1492522  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  5  | base -  2.8574624  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Incorrect: index -  7  | base -  2.5608625  | predict -  3  | actual -  2\n",
      "Incorrect: index -  8  | base -  2.4535542  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Incorrect: index -  10  | base -  2.6161985  | predict -  3  | actual -  4\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  17  | base -  3.0866904  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Incorrect: index -  19  | base -  2.3439126  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  25  | base -  2.4756808  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  35  | base -  2.4030073  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  41  | base -  2.4546525  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  44  | base -  3.105918  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  49  | base -  2.8607724  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Incorrect: index -  51  | base -  1.7360542  | predict -  2  | actual -  0\n",
      "Incorrect: index -  52  | base -  1.3852414  | predict -  1  | actual -  0\n",
      "Incorrect: index -  53  | base -  1.2074934  | predict -  1  | actual -  0\n",
      "Incorrect: index -  54  | base -  2.258728  | predict -  2  | actual -  3\n",
      "Incorrect: index -  55  | base -  2.3004308  | predict -  2  | actual -  1\n",
      "Incorrect: index -  56  | base -  1.4473867  | predict -  1  | actual -  0\n",
      "Incorrect: index -  57  | base -  1.2548534  | predict -  1  | actual -  0\n",
      "Correct:  2\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  62  | base -  2.6197062  | predict -  3  | actual -  4\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  70  | base -  2.450645  | predict -  2  | actual -  4\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  78  | base -  3.5431223  | predict -  4  | actual -  3\n",
      "Correct:  3\n",
      "Incorrect: index -  80  | base -  3.574593  | predict -  4  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  83  | base -  2.7282434  | predict -  3  | actual -  1\n",
      "Incorrect: index -  84  | base -  2.6855972  | predict -  3  | actual -  0\n",
      "Incorrect: index -  85  | base -  2.580834  | predict -  3  | actual -  0\n",
      "Incorrect: index -  86  | base -  2.686198  | predict -  3  | actual -  0\n",
      "Incorrect: index -  87  | base -  1.142356  | predict -  1  | actual -  0\n",
      "Incorrect: index -  88  | base -  0.9447936  | predict -  1  | actual -  0\n",
      "Incorrect: index -  89  | base -  1.2072266  | predict -  1  | actual -  0\n",
      "Incorrect: index -  90  | base -  1.0460904  | predict -  1  | actual -  0\n",
      "Incorrect: index -  91  | base -  1.1126924  | predict -  1  | actual -  0\n",
      "Incorrect: index -  92  | base -  1.2632695  | predict -  1  | actual -  0\n",
      "Correct:  1\n",
      "Incorrect: index -  94  | base -  1.334929  | predict -  1  | actual -  2\n",
      "Incorrect: index -  95  | base -  1.0776361  | predict -  1  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  2\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Incorrect: index -  101  | base -  0.6569439  | predict -  1  | actual -  0\n",
      "Correct:  2\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  105  | base -  3.6365013  | predict -  4  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  112  | base -  2.9371147  | predict -  3  | actual -  4\n",
      "Incorrect: index -  113  | base -  2.4371724  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  120  | base -  3.4117663  | predict -  3  | actual -  4\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  4\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  129  | base -  3.661259  | predict -  4  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  135  | base -  3.0538397  | predict -  3  | actual -  4\n",
      "Correct:  3\n",
      "Incorrect: index -  137  | base -  2.9061954  | predict -  3  | actual -  4\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  142  | base -  2.8630369  | predict -  3  | actual -  0\n",
      "Incorrect: index -  143  | base -  2.6328082  | predict -  3  | actual -  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Incorrect: index -  152  | base -  0.06873572  | predict -  0  | actual -  2\n",
      "Incorrect: index -  153  | base -  1.54127  | predict -  2  | actual -  3\n",
      "Incorrect: index -  154  | base -  1.7980169  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  157  | base -  2.9393315  | predict -  3  | actual -  4\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  167  | base -  3.5783072  | predict -  4  | actual -  3\n",
      "Incorrect: index -  168  | base -  3.889488  | predict -  4  | actual -  3\n",
      "Correct:  3\n",
      "Incorrect: index -  170  | base -  3.1151628  | predict -  3  | actual -  4\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  174  | base -  3.1382527  | predict -  3  | actual -  4\n",
      "Incorrect: index -  175  | base -  0.7183567  | predict -  1  | actual -  0\n",
      "Incorrect: index -  176  | base -  0.71521103  | predict -  1  | actual -  0\n",
      "Incorrect: index -  177  | base -  0.7063618  | predict -  1  | actual -  0\n",
      "Incorrect: index -  178  | base -  0.7023779  | predict -  1  | actual -  0\n",
      "Incorrect: index -  179  | base -  1.3593765  | predict -  1  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  184  | base -  2.7359788  | predict -  3  | actual -  2\n",
      "Incorrect: index -  185  | base -  3.0174892  | predict -  3  | actual -  1\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Incorrect: index -  192  | base -  0.0  | predict -  0  | actual -  1\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  210  | base -  2.6337402  | predict -  3  | actual -  2\n",
      "Correct:  2\n",
      "Correct:  2\n",
      "Incorrect: index -  213  | base -  0.64747334  | predict -  1  | actual -  0\n",
      "Incorrect: index -  214  | base -  0.71017873  | predict -  1  | actual -  0\n",
      "Incorrect: index -  215  | base -  0.7759054  | predict -  1  | actual -  0\n",
      "Incorrect: index -  216  | base -  0.9054152  | predict -  1  | actual -  0\n",
      "Incorrect: index -  217  | base -  1.071972  | predict -  1  | actual -  0\n",
      "Incorrect: index -  218  | base -  1.1974921  | predict -  1  | actual -  0\n",
      "Incorrect: index -  219  | base -  1.2225041  | predict -  1  | actual -  0\n",
      "Incorrect: index -  220  | base -  1.2252457  | predict -  1  | actual -  0\n",
      "Incorrect: index -  221  | base -  0.96683  | predict -  1  | actual -  0\n",
      "Incorrect: index -  222  | base -  0.7893102  | predict -  1  | actual -  0\n",
      "Incorrect: index -  223  | base -  0.8479557  | predict -  1  | actual -  0\n",
      "Correct:  1\n",
      "Incorrect: index -  225  | base -  1.9836556  | predict -  2  | actual -  3\n",
      "Correct:  2\n",
      "Correct:  2\n",
      "Incorrect: index -  228  | base -  1.4959483  | predict -  1  | actual -  3\n",
      "Correct:  2\n",
      "Incorrect: index -  230  | base -  2.1569805  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  2\n",
      "Correct:  2\n",
      "Incorrect: index -  234  | base -  2.5448132  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Incorrect: index -  236  | base -  2.3349853  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  243  | base -  2.224482  | predict -  2  | actual -  0\n",
      "Incorrect: index -  244  | base -  1.3951823  | predict -  1  | actual -  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Incorrect: index -  250  | base -  0.0  | predict -  0  | actual -  2\n",
      "Incorrect: index -  251  | base -  3.4357214  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  259  | base -  2.8229623  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  2\n",
      "Incorrect: index -  265  | base -  0.9781498  | predict -  1  | actual -  0\n",
      "Incorrect: index -  266  | base -  0.73417544  | predict -  1  | actual -  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Incorrect: index -  271  | base -  0.5188217  | predict -  1  | actual -  0\n",
      "Correct:  1\n",
      "Incorrect: index -  273  | base -  0.50077057  | predict -  1  | actual -  2\n",
      "Correct:  2\n",
      "Correct:  3\n",
      "Incorrect: index -  276  | base -  2.2201862  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  281  | base -  2.9369338  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  286  | base -  1.7448018  | predict -  2  | actual -  0\n",
      "Incorrect: index -  287  | base -  0.5623667  | predict -  1  | actual -  0\n",
      "Incorrect: index -  288  | base -  0.5134907  | predict -  1  | actual -  0\n",
      "Incorrect: index -  289  | base -  0.5239016  | predict -  1  | actual -  0\n",
      "Incorrect: index -  290  | base -  0.77598894  | predict -  1  | actual -  0\n",
      "Incorrect: index -  291  | base -  0.7696358  | predict -  1  | actual -  0\n",
      "Incorrect: index -  292  | base -  0.77532876  | predict -  1  | actual -  0\n",
      "Incorrect: index -  293  | base -  1.9174265  | predict -  2  | actual -  3\n",
      "Correct:  2\n",
      "Correct:  2\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  299  | base -  2.4375288  | predict -  2  | actual -  3\n",
      "Incorrect: index -  300  | base -  2.2896137  | predict -  2  | actual -  3\n",
      "Incorrect: index -  301  | base -  2.3416538  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  305  | base -  2.8338633  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  316  | base -  2.4385164  | predict -  2  | actual -  3\n",
      "Correct:  2\n",
      "Incorrect: index -  318  | base -  2.255035  | predict -  2  | actual -  3\n",
      "Incorrect: index -  319  | base -  2.359035  | predict -  2  | actual -  3\n",
      "Correct:  2\n",
      "Incorrect: index -  321  | base -  2.1981335  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Incorrect: index -  323  | base -  2.639641  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  331  | base -  2.5785022  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  334  | base -  2.306927  | predict -  2  | actual -  3\n",
      "Correct:  2\n",
      "Incorrect: index -  336  | base -  2.4337988  | predict -  2  | actual -  3\n",
      "Correct:  2\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Incorrect: index -  344  | base -  1.3504604  | predict -  1  | actual -  2\n",
      "Correct:  3\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  2\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  358  | base -  2.989405  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Incorrect: index -  360  | base -  3.0855384  | predict -  3  | actual -  2\n",
      "Incorrect: index -  361  | base -  2.8189387  | predict -  3  | actual -  1\n",
      "Incorrect: index -  362  | base -  3.0227199  | predict -  3  | actual -  1\n",
      "Incorrect: index -  363  | base -  2.9035108  | predict -  3  | actual -  1\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  367  | base -  2.4302316  | predict -  2  | actual -  3\n",
      "Incorrect: index -  368  | base -  0.0  | predict -  0  | actual -  1\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Incorrect: index -  378  | base -  2.649703  | predict -  3  | actual -  1\n",
      "Incorrect: index -  379  | base -  2.8295681  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  390  | base -  1.8304229  | predict -  2  | actual -  3\n",
      "Incorrect: index -  391  | base -  1.5938687  | predict -  2  | actual -  3\n",
      "Incorrect: index -  392  | base -  0.0  | predict -  0  | actual -  1\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  2\n",
      "Incorrect: index -  407  | base -  2.7843552  | predict -  3  | actual -  2\n",
      "Incorrect: index -  408  | base -  1.9643968  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  416  | base -  1.467413  | predict -  1  | actual -  3\n",
      "Incorrect: index -  417  | base -  2.562686  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  424  | base -  2.8942084  | predict -  3  | actual -  4\n",
      "Incorrect: index -  425  | base -  3.216905  | predict -  3  | actual -  4\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Incorrect: index -  443  | base -  1.3364887  | predict -  1  | actual -  0\n",
      "Correct:  2\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  453  | base -  2.4664726  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Incorrect: index -  455  | base -  3.005365  | predict -  3  | actual -  4\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  459  | base -  2.2179806  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  2\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  498  | base -  3.045409  | predict -  3  | actual -  4\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  4\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  509  | base -  3.0820427  | predict -  3  | actual -  4\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  512  | base -  2.8418283  | predict -  3  | actual -  4\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  516  | base -  2.3419962  | predict -  2  | actual -  3\n",
      "Incorrect: index -  517  | base -  2.2300663  | predict -  2  | actual -  3\n",
      "Incorrect: index -  518  | base -  2.161779  | predict -  2  | actual -  3\n",
      "Incorrect: index -  519  | base -  2.3639846  | predict -  2  | actual -  3\n",
      "Incorrect: index -  520  | base -  2.581871  | predict -  3  | actual -  4\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  528  | base -  2.8997648  | predict -  3  | actual -  4\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  536  | base -  3.054751  | predict -  3  | actual -  2\n",
      "Incorrect: index -  537  | base -  2.9151032  | predict -  3  | actual -  1\n",
      "Incorrect: index -  538  | base -  2.619381  | predict -  3  | actual -  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Incorrect: index -  542  | base -  0.5289167  | predict -  1  | actual -  0\n",
      "Incorrect: index -  543  | base -  0.5244713  | predict -  1  | actual -  0\n",
      "Correct:  0\n",
      "Incorrect: index -  545  | base -  0.5691887  | predict -  1  | actual -  0\n",
      "Incorrect: index -  546  | base -  0.5001863  | predict -  1  | actual -  0\n",
      "Incorrect: index -  547  | base -  0.7070943  | predict -  1  | actual -  0\n",
      "Incorrect: index -  548  | base -  0.9641062  | predict -  1  | actual -  3\n",
      "Incorrect: index -  549  | base -  1.048486  | predict -  1  | actual -  3\n",
      "Incorrect: index -  550  | base -  1.6067134  | predict -  2  | actual -  3\n",
      "Incorrect: index -  551  | base -  2.312187  | predict -  2  | actual -  3\n",
      "Incorrect: index -  552  | base -  2.5355344  | predict -  3  | actual -  4\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  555  | base -  3.235786  | predict -  3  | actual -  4\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  563  | base -  2.662428  | predict -  3  | actual -  0\n",
      "Incorrect: index -  564  | base -  2.9081335  | predict -  3  | actual -  0\n",
      "Incorrect: index -  565  | base -  2.720162  | predict -  3  | actual -  0\n",
      "Incorrect: index -  566  | base -  2.3526893  | predict -  2  | actual -  0\n",
      "Incorrect: index -  567  | base -  1.2985803  | predict -  1  | actual -  0\n",
      "Incorrect: index -  568  | base -  1.7567118  | predict -  2  | actual -  0\n",
      "Incorrect: index -  569  | base -  1.7278582  | predict -  2  | actual -  0\n",
      "Incorrect: index -  570  | base -  1.6603718  | predict -  2  | actual -  0\n",
      "Incorrect: index -  571  | base -  1.112094  | predict -  1  | actual -  0\n",
      "Incorrect: index -  572  | base -  1.1232097  | predict -  1  | actual -  0\n",
      "Incorrect: index -  573  | base -  1.0079203  | predict -  1  | actual -  0\n",
      "Incorrect: index -  574  | base -  0.9499029  | predict -  1  | actual -  0\n",
      "Incorrect: index -  575  | base -  0.8925344  | predict -  1  | actual -  0\n",
      "Incorrect: index -  576  | base -  1.2088996  | predict -  1  | actual -  0\n",
      "Incorrect: index -  577  | base -  1.1053617  | predict -  1  | actual -  0\n",
      "Incorrect: index -  578  | base -  1.8018056  | predict -  2  | actual -  3\n",
      "Incorrect: index -  579  | base -  2.7842865  | predict -  3  | actual -  2\n",
      "Incorrect: index -  580  | base -  2.4716616  | predict -  2  | actual -  3\n",
      "Incorrect: index -  581  | base -  2.8674104  | predict -  3  | actual -  2\n",
      "Incorrect: index -  582  | base -  2.7524114  | predict -  3  | actual -  2\n",
      "Incorrect: index -  583  | base -  2.5015798  | predict -  3  | actual -  2\n",
      "Incorrect: index -  584  | base -  2.4692416  | predict -  2  | actual -  3\n",
      "Incorrect: index -  585  | base -  2.621535  | predict -  3  | actual -  2\n",
      "Incorrect: index -  586  | base -  2.5232782  | predict -  3  | actual -  2\n",
      "Incorrect: index -  587  | base -  2.5705462  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  593  | base -  2.8562436  | predict -  3  | actual -  1\n",
      "Incorrect: index -  594  | base -  3.0904555  | predict -  3  | actual -  0\n",
      "Incorrect: index -  595  | base -  1.0665005  | predict -  1  | actual -  0\n",
      "Incorrect: index -  596  | base -  0.9593408  | predict -  1  | actual -  0\n",
      "Incorrect: index -  597  | base -  0.91263664  | predict -  1  | actual -  0\n",
      "Incorrect: index -  598  | base -  0.8933462  | predict -  1  | actual -  0\n",
      "Incorrect: index -  599  | base -  0.9031079  | predict -  1  | actual -  0\n",
      "Incorrect: index -  600  | base -  0.91496015  | predict -  1  | actual -  0\n",
      "Incorrect: index -  601  | base -  0.8731265  | predict -  1  | actual -  0\n",
      "Incorrect: index -  602  | base -  0.8719013  | predict -  1  | actual -  0\n",
      "Incorrect: index -  603  | base -  0.8518394  | predict -  1  | actual -  0\n",
      "Incorrect: index -  604  | base -  0.8714149  | predict -  1  | actual -  0\n",
      "Incorrect: index -  605  | base -  0.89340913  | predict -  1  | actual -  0\n",
      "Incorrect: index -  606  | base -  0.8563633  | predict -  1  | actual -  3\n",
      "Incorrect: index -  607  | base -  0.9144583  | predict -  1  | actual -  3\n",
      "Incorrect: index -  608  | base -  1.0555685  | predict -  1  | actual -  3\n",
      "Incorrect: index -  609  | base -  2.3013773  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  627  | base -  0.9108938  | predict -  1  | actual -  0\n",
      "Incorrect: index -  628  | base -  0.9872887  | predict -  1  | actual -  0\n",
      "Incorrect: index -  629  | base -  0.83102465  | predict -  1  | actual -  0\n",
      "Correct:  1\n",
      "Incorrect: index -  631  | base -  1.0687267  | predict -  1  | actual -  2\n",
      "Incorrect: index -  632  | base -  0.9172665  | predict -  1  | actual -  2\n",
      "Incorrect: index -  633  | base -  2.435491  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  637  | base -  3.0138922  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Incorrect: index -  639  | base -  2.7174087  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Incorrect: index -  641  | base -  3.019165  | predict -  3  | actual -  2\n",
      "Incorrect: index -  642  | base -  2.8152637  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Incorrect: index -  644  | base -  3.095512  | predict -  3  | actual -  2\n",
      "Incorrect: index -  645  | base -  2.9140084  | predict -  3  | actual -  1\n",
      "Incorrect: index -  646  | base -  2.7273679  | predict -  3  | actual -  0\n",
      "Incorrect: index -  647  | base -  2.7503443  | predict -  3  | actual -  0\n",
      "Incorrect: index -  648  | base -  1.8324571  | predict -  2  | actual -  0\n",
      "Incorrect: index -  649  | base -  1.28236  | predict -  1  | actual -  0\n",
      "Incorrect: index -  650  | base -  0.9002167  | predict -  1  | actual -  0\n",
      "Incorrect: index -  651  | base -  0.92083037  | predict -  1  | actual -  0\n",
      "Incorrect: index -  652  | base -  0.9423313  | predict -  1  | actual -  0\n",
      "Incorrect: index -  653  | base -  0.9467082  | predict -  1  | actual -  0\n",
      "Incorrect: index -  654  | base -  0.9511672  | predict -  1  | actual -  0\n",
      "Incorrect: index -  655  | base -  1.0205432  | predict -  1  | actual -  0\n",
      "Correct:  1\n",
      "Incorrect: index -  657  | base -  0.971303  | predict -  1  | actual -  2\n",
      "Incorrect: index -  658  | base -  1.0401326  | predict -  1  | actual -  2\n",
      "Incorrect: index -  659  | base -  1.0748286  | predict -  1  | actual -  3\n",
      "Incorrect: index -  660  | base -  1.0991954  | predict -  1  | actual -  2\n",
      "Incorrect: index -  661  | base -  1.1181258  | predict -  1  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  671  | base -  2.942319  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Incorrect: index -  673  | base -  2.3105953  | predict -  2  | actual -  3\n",
      "Correct:  2\n",
      "Correct:  2\n",
      "Incorrect: index -  676  | base -  2.9007754  | predict -  3  | actual -  2\n",
      "Incorrect: index -  677  | base -  3.2975593  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Incorrect: index -  679  | base -  3.1835546  | predict -  3  | actual -  2\n",
      "Incorrect: index -  680  | base -  3.1577458  | predict -  3  | actual -  1\n",
      "Incorrect: index -  681  | base -  2.9186625  | predict -  3  | actual -  1\n",
      "Incorrect: index -  682  | base -  2.7666395  | predict -  3  | actual -  0\n",
      "Incorrect: index -  683  | base -  2.4858007  | predict -  2  | actual -  0\n",
      "Incorrect: index -  684  | base -  2.2558784  | predict -  2  | actual -  0\n",
      "Incorrect: index -  685  | base -  1.7309175  | predict -  2  | actual -  0\n",
      "Incorrect: index -  686  | base -  1.4394459  | predict -  1  | actual -  0\n",
      "Incorrect: index -  687  | base -  1.2032313  | predict -  1  | actual -  0\n",
      "Incorrect: index -  688  | base -  0.7865304  | predict -  1  | actual -  0\n",
      "Incorrect: index -  689  | base -  1.0479074  | predict -  1  | actual -  0\n",
      "Incorrect: index -  690  | base -  1.4637908  | predict -  1  | actual -  0\n",
      "Incorrect: index -  691  | base -  1.4715176  | predict -  1  | actual -  0\n",
      "Incorrect: index -  692  | base -  1.4424917  | predict -  1  | actual -  0\n",
      "Incorrect: index -  693  | base -  1.7245637  | predict -  2  | actual -  0\n",
      "Incorrect: index -  694  | base -  1.7352225  | predict -  2  | actual -  0\n",
      "Incorrect: index -  695  | base -  0.82131374  | predict -  1  | actual -  0\n",
      "Incorrect: index -  696  | base -  3.2105088  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  699  | base -  3.60328  | predict -  4  | actual -  3\n",
      "Incorrect: index -  700  | base -  3.5002098  | predict -  4  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  703  | base -  3.307724  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  716  | base -  2.966666  | predict -  3  | actual -  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Incorrect: index -  724  | base -  0.8985547  | predict -  1  | actual -  2\n",
      "Incorrect: index -  725  | base -  0.961751  | predict -  1  | actual -  3\n",
      "Correct:  2\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  738  | base -  2.8043675  | predict -  3  | actual -  0\n",
      "Correct:  0\n",
      "Incorrect: index -  740  | base -  0.5445927  | predict -  1  | actual -  0\n",
      "Incorrect: index -  741  | base -  0.5527073  | predict -  1  | actual -  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  3\n",
      "Incorrect: index -  754  | base -  2.5029552  | predict -  3  | actual -  2\n",
      "Correct:  2\n",
      "Incorrect: index -  756  | base -  2.419808  | predict -  2  | actual -  3\n",
      "Correct:  2\n",
      "Incorrect: index -  758  | base -  2.7779136  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Incorrect: index -  760  | base -  3.0120797  | predict -  3  | actual -  2\n",
      "Incorrect: index -  761  | base -  2.4293628  | predict -  2  | actual -  3\n",
      "Incorrect: index -  762  | base -  2.9088204  | predict -  3  | actual -  0\n",
      "Incorrect: index -  763  | base -  2.7816486  | predict -  3  | actual -  0\n",
      "Incorrect: index -  764  | base -  2.6361172  | predict -  3  | actual -  0\n",
      "Incorrect: index -  765  | base -  0.84624994  | predict -  1  | actual -  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Incorrect: index -  772  | base -  0.17488348  | predict -  0  | actual -  2\n",
      "Incorrect: index -  773  | base -  0.54231906  | predict -  1  | actual -  3\n",
      "Incorrect: index -  774  | base -  1.0473745  | predict -  1  | actual -  3\n",
      "Incorrect: index -  775  | base -  1.1978805  | predict -  1  | actual -  3\n",
      "Incorrect: index -  776  | base -  2.1442883  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  792  | base -  2.8205667  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  797  | base -  2.6297858  | predict -  3  | actual -  0\n",
      "Incorrect: index -  798  | base -  1.4460781  | predict -  1  | actual -  0\n",
      "Incorrect: index -  799  | base -  1.2656188  | predict -  1  | actual -  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Incorrect: index -  808  | base -  0.019995794  | predict -  0  | actual -  2\n",
      "Incorrect: index -  809  | base -  0.6892333  | predict -  1  | actual -  2\n",
      "Incorrect: index -  810  | base -  1.8121312  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Incorrect: index -  812  | base -  2.9415333  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  824  | base -  2.6580424  | predict -  3  | actual -  2\n",
      "Incorrect: index -  825  | base -  2.6147828  | predict -  3  | actual -  1\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Incorrect: index -  839  | base -  0.5605955  | predict -  1  | actual -  2\n",
      "Incorrect: index -  840  | base -  1.5666949  | predict -  2  | actual -  3\n",
      "Incorrect: index -  841  | base -  2.2403064  | predict -  2  | actual -  3\n",
      "Correct:  2\n",
      "Incorrect: index -  843  | base -  2.4440823  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Incorrect: index -  845  | base -  2.4365091  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Incorrect: index -  847  | base -  2.4881606  | predict -  2  | actual -  3\n",
      "Correct:  2\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  859  | base -  2.7028337  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  864  | base -  2.2675426  | predict -  2  | actual -  3\n",
      "Incorrect: index -  865  | base -  2.3913789  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  871  | base -  1.6425544  | predict -  2  | actual -  0\n",
      "Incorrect: index -  872  | base -  0.8657881  | predict -  1  | actual -  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Incorrect: index -  875  | base -  0.93799293  | predict -  1  | actual -  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  2\n",
      "Incorrect: index -  880  | base -  3.578132  | predict -  4  | actual -  3\n",
      "Incorrect: index -  881  | base -  3.493981  | predict -  3  | actual -  4\n",
      "Incorrect: index -  882  | base -  3.971833  | predict -  4  | actual -  3\n",
      "Correct:  4\n",
      "Incorrect: index -  884  | base -  3.8450933  | predict -  4  | actual -  3\n",
      "Incorrect: index -  885  | base -  3.8434875  | predict -  4  | actual -  3\n",
      "Incorrect: index -  886  | base -  3.394432  | predict -  3  | actual -  4\n",
      "Correct:  4\n",
      "Incorrect: index -  888  | base -  3.5851264  | predict -  4  | actual -  3\n",
      "Incorrect: index -  889  | base -  4.058293  | predict -  4  | actual -  3\n",
      "Correct:  4\n",
      "Incorrect: index -  891  | base -  2.9290924  | predict -  3  | actual -  4\n",
      "Correct:  3\n",
      "Incorrect: index -  893  | base -  3.6506255  | predict -  4  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  896  | base -  3.4896555  | predict -  3  | actual -  4\n",
      "Incorrect: index -  897  | base -  3.5193214  | predict -  4  | actual -  3\n",
      "Incorrect: index -  898  | base -  3.5248637  | predict -  4  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  4\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Incorrect: index -  906  | base -  0.7017406  | predict -  1  | actual -  0\n",
      "Incorrect: index -  907  | base -  3.0348806  | predict -  3  | actual -  2\n",
      "Incorrect: index -  908  | base -  3.6500494  | predict -  4  | actual -  3\n",
      "Incorrect: index -  909  | base -  3.7031903  | predict -  4  | actual -  3\n",
      "Incorrect: index -  910  | base -  3.60672  | predict -  4  | actual -  3\n",
      "Incorrect: index -  911  | base -  3.9714937  | predict -  4  | actual -  3\n",
      "Incorrect: index -  912  | base -  4.0826535  | predict -  4  | actual -  3\n",
      "Correct:  4\n",
      "Correct:  3\n",
      "Incorrect: index -  915  | base -  3.3562179  | predict -  3  | actual -  4\n",
      "Correct:  3\n",
      "Incorrect: index -  917  | base -  3.231861  | predict -  3  | actual -  4\n",
      "Correct:  3\n",
      "Incorrect: index -  919  | base -  3.287827  | predict -  3  | actual -  4\n",
      "Incorrect: index -  920  | base -  3.457568  | predict -  3  | actual -  4\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  1\n",
      "Incorrect: index -  925  | base -  0.0  | predict -  0  | actual -  1\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Incorrect: index -  929  | base -  0.5737909  | predict -  1  | actual -  0\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  932  | base -  3.5759912  | predict -  4  | actual -  3\n",
      "Incorrect: index -  933  | base -  3.4259162  | predict -  3  | actual -  4\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  938  | base -  2.470497  | predict -  2  | actual -  3\n",
      "Incorrect: index -  939  | base -  2.9568357  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Incorrect: index -  960  | base -  1.028219  | predict -  1  | actual -  0\n",
      "Incorrect: index -  961  | base -  1.1075848  | predict -  1  | actual -  0\n",
      "Incorrect: index -  962  | base -  3.0971246  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  4\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  971  | base -  3.2295823  | predict -  3  | actual -  4\n",
      "Correct:  3\n",
      "Incorrect: index -  973  | base -  3.4963436  | predict -  3  | actual -  4\n",
      "Incorrect: index -  974  | base -  3.3835573  | predict -  3  | actual -  4\n",
      "Correct:  3\n",
      "Correct:  4\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  979  | base -  2.8290591  | predict -  3  | actual -  4\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  983  | base -  3.471591  | predict -  3  | actual -  4\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  986  | base -  3.3016417  | predict -  3  | actual -  4\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  991  | base -  3.2768772  | predict -  3  | actual -  4\n",
      "Correct:  4\n",
      "Incorrect: index -  993  | base -  3.3976092  | predict -  3  | actual -  4\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  997  | base -  3.3018937  | predict -  3  | actual -  4\n",
      "Correct:  3\n",
      "Incorrect: index -  999  | base -  3.7249074  | predict -  4  | actual -  3\n",
      "Correct:  4\n",
      "Correct:  4\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Incorrect: index -  1011  | base -  0.5551671  | predict -  1  | actual -  0\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  1014  | base -  3.6608882  | predict -  4  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  4\n",
      "Incorrect: index -  1017  | base -  2.9863377  | predict -  3  | actual -  4\n",
      "Correct:  3\n",
      "Incorrect: index -  1019  | base -  3.576086  | predict -  4  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  1022  | base -  3.58654  | predict -  4  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  1025  | base -  2.6691685  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  1045  | base -  2.9668689  | predict -  3  | actual -  4\n",
      "Incorrect: index -  1046  | base -  3.1130393  | predict -  3  | actual -  4\n",
      "Correct:  3\n",
      "Correct:  2\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Incorrect: index -  1059  | base -  0.9386817  | predict -  1  | actual -  0\n",
      "Correct:  3\n",
      "Correct:  1\n",
      "Incorrect: index -  1062  | base -  0.96361053  | predict -  1  | actual -  2\n",
      "Incorrect: index -  1063  | base -  1.3191351  | predict -  1  | actual -  3\n",
      "Incorrect: index -  1064  | base -  1.2409219  | predict -  1  | actual -  3\n",
      "Incorrect: index -  1065  | base -  1.234629  | predict -  1  | actual -  3\n",
      "Incorrect: index -  1066  | base -  2.4001184  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1067  | base -  2.4554453  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  1070  | base -  2.2687912  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1071  | base -  2.185685  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1072  | base -  2.1736956  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1073  | base -  2.423801  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1074  | base -  2.3353372  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1075  | base -  2.3813677  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  1080  | base -  2.4319766  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1081  | base -  2.406272  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Incorrect: index -  1083  | base -  2.0848987  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Incorrect: index -  1085  | base -  2.3718991  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1086  | base -  2.4693823  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  2\n",
      "Incorrect: index -  1091  | base -  1.9711987  | predict -  2  | actual -  3\n",
      "Correct:  2\n",
      "Incorrect: index -  1093  | base -  1.7003876  | predict -  2  | actual -  1\n",
      "Incorrect: index -  1094  | base -  1.8814337  | predict -  2  | actual -  0\n",
      "Incorrect: index -  1095  | base -  1.6529118  | predict -  2  | actual -  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Incorrect: index -  1122  | base -  0.0  | predict -  0  | actual -  1\n",
      "Incorrect: index -  1123  | base -  0.0  | predict -  0  | actual -  3\n",
      "Incorrect: index -  1124  | base -  0.28013605  | predict -  0  | actual -  2\n",
      "Incorrect: index -  1125  | base -  0.7695706  | predict -  1  | actual -  3\n",
      "Incorrect: index -  1126  | base -  2.0762959  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1127  | base -  2.137244  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1128  | base -  2.3123202  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1129  | base -  2.0192199  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1130  | base -  2.3951855  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1131  | base -  2.730279  | predict -  3  | actual -  2\n",
      "Incorrect: index -  1132  | base -  2.345923  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1133  | base -  2.419653  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1134  | base -  3.058223  | predict -  3  | actual -  2\n",
      "Incorrect: index -  1135  | base -  2.644154  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  1148  | base -  2.6192813  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  1152  | base -  2.466107  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1153  | base -  3.1318257  | predict -  3  | actual -  2\n",
      "Incorrect: index -  1154  | base -  2.4797266  | predict -  2  | actual -  1\n",
      "Incorrect: index -  1155  | base -  2.1737971  | predict -  2  | actual -  0\n",
      "Incorrect: index -  1156  | base -  2.0208373  | predict -  2  | actual -  0\n",
      "Incorrect: index -  1157  | base -  1.2322769  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1158  | base -  1.0795131  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1159  | base -  1.0682766  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1160  | base -  1.0617946  | predict -  1  | actual -  2\n",
      "Incorrect: index -  1161  | base -  1.0562055  | predict -  1  | actual -  2\n",
      "Incorrect: index -  1162  | base -  1.094895  | predict -  1  | actual -  3\n",
      "Incorrect: index -  1163  | base -  2.4185505  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  2\n",
      "Incorrect: index -  1168  | base -  2.612813  | predict -  3  | actual -  1\n",
      "Incorrect: index -  1169  | base -  2.5599122  | predict -  3  | actual -  0\n",
      "Incorrect: index -  1170  | base -  2.3204703  | predict -  2  | actual -  0\n",
      "Incorrect: index -  1171  | base -  1.4382757  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1172  | base -  0.9755255  | predict -  1  | actual -  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Incorrect: index -  1180  | base -  0.60143137  | predict -  1  | actual -  0\n",
      "Correct:  0\n",
      "Incorrect: index -  1182  | base -  0.65067136  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1183  | base -  0.5633962  | predict -  1  | actual -  2\n",
      "Incorrect: index -  1184  | base -  0.34286755  | predict -  0  | actual -  3\n",
      "Incorrect: index -  1185  | base -  2.2042217  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  1202  | base -  2.8507206  | predict -  3  | actual -  4\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  1209  | base -  2.9643936  | predict -  3  | actual -  4\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  1214  | base -  3.3220696  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Correct:  2\n",
      "Incorrect: index -  1217  | base -  3.0525484  | predict -  3  | actual -  0\n",
      "Incorrect: index -  1218  | base -  1.907659  | predict -  2  | actual -  0\n",
      "Incorrect: index -  1219  | base -  0.9783962  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1220  | base -  0.9737048  | predict -  1  | actual -  0\n",
      "Correct:  0\n",
      "Incorrect: index -  1222  | base -  0.59819686  | predict -  1  | actual -  2\n",
      "Incorrect: index -  1223  | base -  0.4081073  | predict -  0  | actual -  3\n",
      "Incorrect: index -  1224  | base -  1.0955287  | predict -  1  | actual -  3\n",
      "Incorrect: index -  1225  | base -  1.7678461  | predict -  2  | actual -  3\n",
      "Correct:  2\n",
      "Correct:  2\n",
      "Incorrect: index -  1228  | base -  2.3275266  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1229  | base -  2.3047423  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  2\n",
      "Incorrect: index -  1233  | base -  1.344075  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1234  | base -  1.0280014  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1235  | base -  1.0578059  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1236  | base -  1.0027034  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1237  | base -  1.0703952  | predict -  1  | actual -  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Incorrect: index -  1246  | base -  0.086482376  | predict -  0  | actual -  1\n",
      "Incorrect: index -  1247  | base -  0.14300932  | predict -  0  | actual -  3\n",
      "Correct:  2\n",
      "Incorrect: index -  1249  | base -  2.2356718  | predict -  2  | actual -  3\n",
      "Correct:  2\n",
      "Incorrect: index -  1251  | base -  1.893417  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1252  | base -  1.2951065  | predict -  1  | actual -  4\n",
      "Correct:  2\n",
      "Incorrect: index -  1254  | base -  2.1621318  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Incorrect: index -  1256  | base -  2.140295  | predict -  2  | actual -  3\n",
      "Correct:  2\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  1260  | base -  2.6287835  | predict -  3  | actual -  2\n",
      "Incorrect: index -  1261  | base -  3.0018775  | predict -  3  | actual -  2\n",
      "Incorrect: index -  1262  | base -  2.937319  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Incorrect: index -  1264  | base -  2.2624795  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  1267  | base -  2.9700756  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Incorrect: index -  1269  | base -  2.724186  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  1273  | base -  2.8741577  | predict -  3  | actual -  2\n",
      "Incorrect: index -  1274  | base -  2.9262052  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  1278  | base -  1.6698296  | predict -  2  | actual -  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Incorrect: index -  1294  | base -  0.5918431  | predict -  1  | actual -  0\n",
      "Correct:  1\n",
      "Correct:  2\n",
      "Incorrect: index -  1297  | base -  1.3176557  | predict -  1  | actual -  3\n",
      "Incorrect: index -  1298  | base -  1.6316711  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  1301  | base -  3.010384  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  1311  | base -  3.036071  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  1324  | base -  2.5835662  | predict -  3  | actual -  2\n",
      "Incorrect: index -  1325  | base -  1.3189995  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1326  | base -  0.8355857  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1327  | base -  0.80935466  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1328  | base -  0.584615  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1329  | base -  0.57668066  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1330  | base -  0.5726669  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1331  | base -  0.57626134  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1332  | base -  0.577719  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1333  | base -  0.61959827  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1334  | base -  0.45317653  | predict -  0  | actual -  1\n",
      "Incorrect: index -  1335  | base -  0.50057423  | predict -  1  | actual -  2\n",
      "Incorrect: index -  1336  | base -  1.6243485  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  1341  | base -  2.701242  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  1346  | base -  2.6888044  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  1351  | base -  2.8984146  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  1356  | base -  2.9494395  | predict -  3  | actual -  2\n",
      "Incorrect: index -  1357  | base -  2.0126505  | predict -  2  | actual -  0\n",
      "Incorrect: index -  1358  | base -  1.9395181  | predict -  2  | actual -  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Incorrect: index -  1368  | base -  0.73896825  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1369  | base -  0.7338221  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1370  | base -  0.6234393  | predict -  1  | actual -  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Incorrect: index -  1377  | base -  0.38916397  | predict -  0  | actual -  1\n",
      "Incorrect: index -  1378  | base -  0.84960735  | predict -  1  | actual -  3\n",
      "Correct:  3\n",
      "Incorrect: index -  1380  | base -  2.6272664  | predict -  3  | actual -  2\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  1384  | base -  2.5254374  | predict -  3  | actual -  2\n",
      "Incorrect: index -  1385  | base -  2.8585176  | predict -  3  | actual -  0\n",
      "Incorrect: index -  1386  | base -  1.7547523  | predict -  2  | actual -  0\n",
      "Incorrect: index -  1387  | base -  1.3965825  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1388  | base -  0.77970016  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1389  | base -  0.8760736  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1390  | base -  0.72376513  | predict -  1  | actual -  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Incorrect: index -  1394  | base -  0.5029419  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1395  | base -  0.53748626  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1396  | base -  0.7215563  | predict -  1  | actual -  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Incorrect: index -  1409  | base -  0.8261298  | predict -  1  | actual -  3\n",
      "Incorrect: index -  1410  | base -  1.3016064  | predict -  1  | actual -  3\n",
      "Incorrect: index -  1411  | base -  2.2479668  | predict -  2  | actual -  3\n",
      "Correct:  2\n",
      "Incorrect: index -  1413  | base -  2.185063  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Incorrect: index -  1415  | base -  2.5882852  | predict -  3  | actual -  2\n",
      "Incorrect: index -  1416  | base -  2.0443044  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1417  | base -  2.037599  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1418  | base -  1.894896  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1419  | base -  2.0855396  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1420  | base -  1.8835555  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  2\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  1433  | base -  2.2607985  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1434  | base -  2.1670096  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  1438  | base -  2.816494  | predict -  3  | actual -  2\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Incorrect: index -  1444  | base -  2.2640986  | predict -  2  | actual -  0\n",
      "Incorrect: index -  1445  | base -  2.2309158  | predict -  2  | actual -  0\n",
      "Incorrect: index -  1446  | base -  2.2892647  | predict -  2  | actual -  0\n",
      "Incorrect: index -  1447  | base -  2.3565702  | predict -  2  | actual -  0\n",
      "Incorrect: index -  1448  | base -  2.3605223  | predict -  2  | actual -  0\n",
      "Correct:  3\n",
      "Incorrect: index -  1450  | base -  2.252819  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1451  | base -  2.4163346  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1452  | base -  2.3269515  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1453  | base -  2.0963228  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1454  | base -  2.3236194  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1455  | base -  1.8625692  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1456  | base -  2.173888  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1457  | base -  2.075743  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1458  | base -  2.216871  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1459  | base -  2.0455768  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1460  | base -  2.0815372  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Incorrect: index -  1462  | base -  1.0622903  | predict -  1  | actual -  3\n",
      "Incorrect: index -  1463  | base -  1.1923987  | predict -  1  | actual -  2\n",
      "Incorrect: index -  1464  | base -  1.0125475  | predict -  1  | actual -  2\n",
      "Correct:  1\n",
      "Incorrect: index -  1466  | base -  0.8085643  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1467  | base -  0.653152  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1468  | base -  0.6695317  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1469  | base -  0.6866845  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1470  | base -  0.734905  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1471  | base -  0.7857858  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1472  | base -  0.6877769  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1473  | base -  0.6898068  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1474  | base -  0.78749  | predict -  1  | actual -  0\n",
      "Correct:  2\n",
      "Incorrect: index -  1476  | base -  2.1181803  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1477  | base -  2.2349987  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1478  | base -  2.3803363  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1479  | base -  2.3567805  | predict -  2  | actual -  4\n",
      "Incorrect: index -  1480  | base -  2.3914223  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1481  | base -  2.3226728  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1482  | base -  2.1302724  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1483  | base -  2.134729  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1484  | base -  2.1896012  | predict -  2  | actual -  4\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  1488  | base -  2.0199726  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1489  | base -  2.4412622  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1490  | base -  2.1481237  | predict -  2  | actual -  4\n",
      "Correct:  3\n",
      "Incorrect: index -  1492  | base -  2.3258395  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Incorrect: index -  1494  | base -  2.3947356  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1495  | base -  2.418095  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1496  | base -  2.389747  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1497  | base -  1.6613067  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1498  | base -  1.7097255  | predict -  2  | actual -  3\n",
      "Correct:  2\n",
      "Incorrect: index -  1500  | base -  1.7324046  | predict -  2  | actual -  3\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Incorrect: index -  1507  | base -  1.0453422  | predict -  1  | actual -  0\n",
      "Correct:  2\n",
      "Correct:  2\n",
      "Incorrect: index -  1510  | base -  1.9783965  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1511  | base -  2.1888201  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1512  | base -  2.290056  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1513  | base -  2.149618  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1514  | base -  2.1745477  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1515  | base -  2.4294662  | predict -  2  | actual -  4\n",
      "Incorrect: index -  1516  | base -  1.8706058  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1517  | base -  2.1065857  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1518  | base -  2.2482047  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1519  | base -  2.119898  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1520  | base -  1.020139  | predict -  1  | actual -  3\n",
      "Incorrect: index -  1521  | base -  1.1111945  | predict -  1  | actual -  3\n",
      "Incorrect: index -  1522  | base -  1.3025109  | predict -  1  | actual -  2\n",
      "Correct:  2\n",
      "Incorrect: index -  1524  | base -  1.5247377  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1525  | base -  2.064047  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1526  | base -  2.1960056  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1527  | base -  2.2684982  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1528  | base -  2.1385536  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  1531  | base -  2.2605572  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1532  | base -  2.4113245  | predict -  2  | actual -  4\n",
      "Correct:  3\n",
      "Incorrect: index -  1534  | base -  2.4092467  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1535  | base -  2.4055595  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1536  | base -  2.4765482  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1537  | base -  2.0330195  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1538  | base -  2.2254324  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1539  | base -  2.4219337  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1540  | base -  2.3170683  | predict -  2  | actual -  3\n",
      "Correct:  2\n",
      "Incorrect: index -  1542  | base -  1.8309664  | predict -  2  | actual -  0\n",
      "Incorrect: index -  1543  | base -  1.4043355  | predict -  1  | actual -  0\n",
      "Correct:  1\n",
      "Correct:  1\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Incorrect: index -  1556  | base -  0.6549916  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1557  | base -  0.52766323  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1558  | base -  0.5016445  | predict -  1  | actual -  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Incorrect: index -  1561  | base -  0.52861845  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1562  | base -  2.057847  | predict -  2  | actual -  3\n",
      "Correct:  2\n",
      "Incorrect: index -  1564  | base -  2.1409898  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1565  | base -  2.0234342  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1566  | base -  1.8877815  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1567  | base -  2.0041783  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1568  | base -  2.1383333  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1569  | base -  2.013934  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1570  | base -  2.0091002  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1571  | base -  2.1104488  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1572  | base -  1.9676801  | predict -  2  | actual -  4\n",
      "Incorrect: index -  1573  | base -  1.8859233  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1574  | base -  1.858287  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1575  | base -  1.9932979  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1576  | base -  2.0072737  | predict -  2  | actual -  4\n",
      "Incorrect: index -  1577  | base -  2.3458512  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1578  | base -  2.4443247  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1579  | base -  2.2660425  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1580  | base -  2.3827407  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1581  | base -  2.3531723  | predict -  2  | actual -  4\n",
      "Incorrect: index -  1582  | base -  2.4270413  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1583  | base -  1.9050473  | predict -  2  | actual -  4\n",
      "Incorrect: index -  1584  | base -  0.94190705  | predict -  1  | actual -  3\n",
      "Incorrect: index -  1585  | base -  0.44997343  | predict -  0  | actual -  2\n",
      "Incorrect: index -  1586  | base -  0.31284136  | predict -  0  | actual -  2\n",
      "Incorrect: index -  1587  | base -  0.010663271  | predict -  0  | actual -  1\n",
      "Correct:  0\n",
      "Incorrect: index -  1589  | base -  0.63931656  | predict -  1  | actual -  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Incorrect: index -  1593  | base -  0.67622626  | predict -  1  | actual -  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Correct:  0\n",
      "Incorrect: index -  1600  | base -  2.2710226  | predict -  2  | actual -  0\n",
      "Incorrect: index -  1601  | base -  0.9413862  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1602  | base -  0.9772388  | predict -  1  | actual -  3\n",
      "Incorrect: index -  1603  | base -  1.7269094  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1604  | base -  1.8436121  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1605  | base -  1.6587912  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1606  | base -  2.974115  | predict -  3  | actual -  0\n",
      "Incorrect: index -  1607  | base -  1.3476267  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1608  | base -  0.8052566  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1609  | base -  1.4263512  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1610  | base -  1.4707757  | predict -  1  | actual -  0\n",
      "Incorrect: index -  1611  | base -  1.7179035  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1612  | base -  1.9940892  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1613  | base -  1.8896525  | predict -  2  | actual -  4\n",
      "Incorrect: index -  1614  | base -  1.9693929  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1615  | base -  2.3737698  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1616  | base -  2.1175714  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1617  | base -  2.09253  | predict -  2  | actual -  3\n",
      "Incorrect: index -  1618  | base -  2.4185529  | predict -  2  | actual -  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Incorrect: index -  1622  | base -  2.8890383  | predict -  3  | actual -  4\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  3\n",
      "Correct:  1009 / 1626\n",
      "****************************************************\n"
     ]
    }
   ],
   "source": [
    "def round_pred(pred):\n",
    "    round_list = []\n",
    "    for i in pred:\n",
    "        round_list.append(round(i[0]))\n",
    "    return round_list\n",
    "\n",
    "\n",
    "def print_correct_count(pred, actual, log):\n",
    "    old_pred = pred\n",
    "    pred = round_pred(pred)\n",
    "    correct_count = 0\n",
    "    diff_list = []\n",
    "    for i in range(len(actual)):\n",
    "        diff_list.append(abs(actual[i] - pred[i]))\n",
    "        if actual[i] == pred[i]:\n",
    "            print(\"Correct: \", pred[i])\n",
    "            correct_count += 1\n",
    "        else:\n",
    "            print(\"Incorrect: index - \", i, \" | base - \", old_pred[i][0], \" | predict - \", pred[i], \" | actual - \",\n",
    "                  actual[i])\n",
    "    print(\"Correct: \", correct_count, \"/\", len(actual))\n",
    "    log.write(\"Correct \" + str(correct_count) + \"/\" + str(len(actual)))\n",
    "\n",
    "    log.write(\"Mean difference: \" + str((sum(diff_list) / len(diff_list))))\n",
    "\n",
    "\n",
    "y_pred = model.predict(test_x)\n",
    "print_correct_count(y_pred, test_y_step, log_writer)\n",
    "\n",
    "log_writer.close()\n",
    "print_line_divider()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training Transformer for context detection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      "Model: \"model_23\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_24 (InputLayer)          [(None, 40, 9)]      0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_74 (LayerN  (None, 40, 9)       18          ['input_24[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_37 (Multi  (None, 40, 9)       5001        ['layer_normalization_74[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_125 (Dropout)          (None, 40, 9)        0           ['multi_head_attention_37[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_74 (TFOpL  (None, 40, 9)       0           ['dropout_125[0][0]',            \n",
      " ambda)                                                           'input_24[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_75 (LayerN  (None, 40, 9)       18          ['tf.__operators__.add_74[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_74 (Conv1D)             (None, 40, 4)        40          ['layer_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_126 (Dropout)          (None, 40, 4)        0           ['conv1d_74[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_75 (Conv1D)             (None, 40, 9)        45          ['dropout_126[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_75 (TFOpL  (None, 40, 9)       0           ['conv1d_75[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_74[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_76 (LayerN  (None, 40, 9)       18          ['tf.__operators__.add_75[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_38 (Multi  (None, 40, 9)       5001        ['layer_normalization_76[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_127 (Dropout)          (None, 40, 9)        0           ['multi_head_attention_38[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_76 (TFOpL  (None, 40, 9)       0           ['dropout_127[0][0]',            \n",
      " ambda)                                                           'tf.__operators__.add_75[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_77 (LayerN  (None, 40, 9)       18          ['tf.__operators__.add_76[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_76 (Conv1D)             (None, 40, 4)        40          ['layer_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_128 (Dropout)          (None, 40, 4)        0           ['conv1d_76[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_77 (Conv1D)             (None, 40, 9)        45          ['dropout_128[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_77 (TFOpL  (None, 40, 9)       0           ['conv1d_77[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_76[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_78 (LayerN  (None, 40, 9)       18          ['tf.__operators__.add_77[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_39 (Multi  (None, 40, 9)       5001        ['layer_normalization_78[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_129 (Dropout)          (None, 40, 9)        0           ['multi_head_attention_39[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_78 (TFOpL  (None, 40, 9)       0           ['dropout_129[0][0]',            \n",
      " ambda)                                                           'tf.__operators__.add_77[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_79 (LayerN  (None, 40, 9)       18          ['tf.__operators__.add_78[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_78 (Conv1D)             (None, 40, 4)        40          ['layer_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_130 (Dropout)          (None, 40, 4)        0           ['conv1d_78[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_79 (Conv1D)             (None, 40, 9)        45          ['dropout_130[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_79 (TFOpL  (None, 40, 9)       0           ['conv1d_79[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_78[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_23 (G  (None, 40)          0           ['tf.__operators__.add_79[0][0]']\n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_46 (Dense)               (None, 128)          5248        ['global_average_pooling1d_23[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_131 (Dropout)          (None, 128)          0           ['dense_46[0][0]']               \n",
      "                                                                                                  \n",
      " dense_47 (Dense)               (None, 5)            645         ['dropout_131[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21,259\n",
      "Trainable params: 21,259\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "****************************************************\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from model.transformer import make_transformer_model_v1\n",
    "from models.log_writer import LogWriter\n",
    "from keras import callbacks, models\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "from audio.audio import play_training_is_complete\n",
    "\n",
    "SAVED_BEST_MODEL = \"model/best_context_for_step_model.h5\"\n",
    "\n",
    "log_writer = LogWriter(enabled=True)\n",
    "\n",
    "_, model = make_transformer_model_v1(\n",
    "    input_shape=(40, 9),\n",
    "    head_size=64,\n",
    "    num_heads=2,\n",
    "    ff_dim=4,\n",
    "    num_transformer_blocks=3,\n",
    "    mlp_units=[128],\n",
    "    mlp_dropout=0.4,\n",
    "    dropout=0.25,\n",
    ")\n",
    "# model = models.load_model(\"logs/2022-06-21/id_31/model.h5\")\n",
    "\n",
    "print(\"Model Summary:\")\n",
    "stringlist = []\n",
    "model.summary(print_fn=lambda x: stringlist.append(x))\n",
    "short_model_summary = \"\\n\".join(stringlist)\n",
    "print(short_model_summary)\n",
    "print(print_line_divider())\n",
    "log_writer.write(\"Model\", line_divider=True)\n",
    "log_writer.write(short_model_summary)\n",
    "\n",
    "epochs = 300\n",
    "batch_size = 32\n",
    "validation_split = 15 / 85\n",
    "adam_starting_lr = 0.0025 / 2\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=adam_starting_lr, name=\"Adam\")\n",
    "reduce_lr_patience = 20\n",
    "early_stopping_patience = 100\n",
    "callback_list = [\n",
    "    callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=reduce_lr_patience, min_lr=0.0001),\n",
    "    callbacks.EarlyStopping(monitor=\"val_loss\", patience=early_stopping_patience, verbose=1),\n",
    "    callbacks.ModelCheckpoint(SAVED_BEST_MODEL, save_best_only=True, monitor=\"val_loss\")\n",
    "]\n",
    "loss_function = \"sparse_categorical_crossentropy\"\n",
    "\n",
    "log_writer.write(\"Training configuration\", line_divider=True)\n",
    "log_writer.write(\n",
    "    f\"\"\"Epoch: {epochs}\n",
    "Batch size: {batch_size}\n",
    "Validation split: {validation_split}\n",
    "Optimizer: Adam with starting lr {adam_starting_lr}\n",
    "Loss function: {loss_function}\n",
    "Reduce LR patience: {reduce_lr_patience}\n",
    "Early stopping patience: {early_stopping_patience}\n",
    "\"\"\"\n",
    ")\n",
    "if log_writer.enabled:\n",
    "    callback_list.append(\n",
    "        callbacks.ModelCheckpoint(log_writer.base_folder + \"/model.h5\", save_best_only=True, monitor=\"val_loss\")\n",
    "    )\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss_function,\n",
    "    metrics=[\"sparse_categorical_accuracy\"],\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "236/236 [==============================] - 12s 43ms/step - loss: 0.3852 - sparse_categorical_accuracy: 0.8377 - val_loss: 1.1879 - val_sparse_categorical_accuracy: 0.8702 - lr: 0.0012\n",
      "Epoch 2/300\n",
      "236/236 [==============================] - 7s 28ms/step - loss: 0.0501 - sparse_categorical_accuracy: 0.9854 - val_loss: 8.4580 - val_sparse_categorical_accuracy: 0.5328 - lr: 0.0012\n",
      "Epoch 3/300\n",
      "236/236 [==============================] - 8s 33ms/step - loss: 0.0316 - sparse_categorical_accuracy: 0.9918 - val_loss: 1.6734 - val_sparse_categorical_accuracy: 0.7831 - lr: 0.0012\n",
      "Epoch 4/300\n",
      "236/236 [==============================] - 9s 38ms/step - loss: 0.0103 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.3165 - val_sparse_categorical_accuracy: 0.8702 - lr: 0.0012\n",
      "Epoch 5/300\n",
      "236/236 [==============================] - 10s 43ms/step - loss: 0.0265 - sparse_categorical_accuracy: 0.9924 - val_loss: 1.8757 - val_sparse_categorical_accuracy: 0.7899 - lr: 0.0012\n",
      "Epoch 6/300\n",
      "236/236 [==============================] - 10s 44ms/step - loss: 0.0104 - sparse_categorical_accuracy: 0.9974 - val_loss: 1.5529 - val_sparse_categorical_accuracy: 0.8727 - lr: 0.0012\n",
      "Epoch 7/300\n",
      "236/236 [==============================] - 11s 48ms/step - loss: 0.0134 - sparse_categorical_accuracy: 0.9960 - val_loss: 1.0773 - val_sparse_categorical_accuracy: 0.8585 - lr: 0.0012\n",
      "Epoch 8/300\n",
      "236/236 [==============================] - 10s 41ms/step - loss: 0.0188 - sparse_categorical_accuracy: 0.9946 - val_loss: 5.0461 - val_sparse_categorical_accuracy: 0.6990 - lr: 0.0012\n",
      "Epoch 9/300\n",
      "236/236 [==============================] - 9s 40ms/step - loss: 0.0103 - sparse_categorical_accuracy: 0.9970 - val_loss: 3.7018 - val_sparse_categorical_accuracy: 0.5939 - lr: 0.0012\n",
      "Epoch 10/300\n",
      "236/236 [==============================] - 10s 42ms/step - loss: 0.0107 - sparse_categorical_accuracy: 0.9970 - val_loss: 3.5349 - val_sparse_categorical_accuracy: 0.6836 - lr: 0.0012\n",
      "Epoch 11/300\n",
      "236/236 [==============================] - 11s 46ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9987 - val_loss: 2.7657 - val_sparse_categorical_accuracy: 0.7868 - lr: 0.0012\n",
      "Epoch 12/300\n",
      "186/236 [======================>.......] - ETA: 2s - loss: 0.0027 - sparse_categorical_accuracy: 0.9992"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [104]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time()\n\u001B[0;32m----> 2\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_x\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_y_context\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback_list\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_split\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[1;32m     11\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m     12\u001B[0m end_time \u001B[38;5;241m=\u001B[39m time()\n\u001B[1;32m     13\u001B[0m training_time \u001B[38;5;241m=\u001B[39m end_time \u001B[38;5;241m-\u001B[39m start_time\n",
      "File \u001B[0;32m~/Desktop/FINAL PROJECT/context_transformer/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 64\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/Desktop/FINAL PROJECT/context_transformer/venv/lib/python3.9/site-packages/keras/engine/training.py:1384\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1377\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1378\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m   1379\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   1380\u001B[0m     step_num\u001B[38;5;241m=\u001B[39mstep,\n\u001B[1;32m   1381\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[1;32m   1382\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m   1383\u001B[0m   callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1384\u001B[0m   tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1385\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1386\u001B[0m     context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/Desktop/FINAL PROJECT/context_transformer/venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/Desktop/FINAL PROJECT/context_transformer/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    912\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    914\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 915\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    917\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    918\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/Desktop/FINAL PROJECT/context_transformer/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    944\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    945\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    946\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 947\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_stateless_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[1;32m    948\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    949\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    950\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[1;32m    951\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m~/Desktop/FINAL PROJECT/context_transformer/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2956\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2953\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m   2954\u001B[0m   (graph_function,\n\u001B[1;32m   2955\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[0;32m-> 2956\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2957\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/FINAL PROJECT/context_transformer/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1853\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1849\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1850\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1851\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1852\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1853\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1854\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   1855\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1856\u001B[0m     args,\n\u001B[1;32m   1857\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1858\u001B[0m     executing_eagerly)\n\u001B[1;32m   1859\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/Desktop/FINAL PROJECT/context_transformer/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    497\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    498\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 499\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    503\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    504\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    505\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    506\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m    507\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[1;32m    508\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    511\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[1;32m    512\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[0;32m~/Desktop/FINAL PROJECT/context_transformer/venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "history = model.fit(\n",
    "    train_x,\n",
    "    train_y_context,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=callback_list,\n",
    "    validation_split=validation_split,\n",
    "    verbose=1,\n",
    "    shuffle=True\n",
    ")\n",
    "end_time = time()\n",
    "training_time = end_time - start_time\n",
    "print(\"Total training time in seconds: \" + str(training_time))\n",
    "print(\"Highest validation accuracy: \", max(history.history['val_sparse_categorical_accuracy']))\n",
    "log_writer.write(\"Result\", line_divider=True)\n",
    "log_writer.write(\"Training time: \" + str(end_time - start_time) + \" seconds.\")\n",
    "log_writer.write(\"Highest validation accuracy: \" + str(max(history.history['val_sparse_categorical_accuracy'])))\n",
    "play_training_is_complete()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# PLOTTING\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "metric = \"sparse_categorical_accuracy\"\n",
    "plt.figure()\n",
    "plt.plot(history.history[metric])\n",
    "plt.plot(history.history[\"val_\" + metric])\n",
    "plt.title(\"Transformer:\" + metric)\n",
    "plt.ylabel(metric, fontsize=\"large\")\n",
    "plt.xlabel(\"epoch\", fontsize=\"large\")\n",
    "plt.legend([\"train\", \"val\"], loc=\"best\")\n",
    "if log_writer.enabled:\n",
    "    plt.savefig(os.path.join(log_writer.base_folder, \"Validation progress.png\"))\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 1s 12ms/step - loss: 0.2927 - sparse_categorical_accuracy: 0.9686\n",
      "****************************************************\n",
      "Test accuracy 0.9686346650123596\n",
      "Test loss 0.292726993560791\n",
      "Metrics report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.91      0.95       565\n",
      "         1.0       0.94      1.00      0.97       544\n",
      "         2.0       0.97      1.00      0.98       517\n",
      "\n",
      "    accuracy                           0.97      1626\n",
      "   macro avg       0.97      0.97      0.97      1626\n",
      "weighted avg       0.97      0.97      0.97      1626\n",
      "\n",
      "[[516  33  16]\n",
      " [  1 543   0]\n",
      " [  1   0 516]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# EVALUATION\n",
    "model = models.load_model(\"logs/2022-06-21/id_33/model.h5\")\n",
    "\n",
    "log_writer = LogWriter(enabled=False)\n",
    "test_loss, test_acc = model.evaluate(test_x, test_y_context)\n",
    "print_line_divider()\n",
    "print(\"Test accuracy\", test_acc)\n",
    "print(\"Test loss\", test_loss)\n",
    "\n",
    "# Accuracy based on different labels\n",
    "y_pred = model.predict(test_x)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "metrics_report = classification_report(test_y_context, y_pred)\n",
    "print(\"Metrics report: \")\n",
    "print(metrics_report)\n",
    "\n",
    "con_mat = tf.math.confusion_matrix(labels=test_y_context, predictions=y_pred).numpy()\n",
    "print(con_mat)\n",
    "con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=4)\n",
    "con_mat_df = pd.DataFrame(con_mat_norm, index=location_labels, columns=location_labels)\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(con_mat_df, annot=True, cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "if log_writer.enabled:\n",
    "    plt.savefig(os.path.join(log_writer.base_folder, \"Accuracy.png\"))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "log_writer.write(\"Test evaluation\", line_divider=True)\n",
    "log_writer.write(\"Test accuracy: \" + str(test_acc))\n",
    "log_writer.write(\"Test loss: \" + str(test_loss))\n",
    "log_writer.write(\"Metric report: \")\n",
    "log_writer.write(metrics_report)\n",
    "log_writer.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Final Evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['holdinginhand', 'insidethebag', 'insidethepantpocket']\n"
     ]
    }
   ],
   "source": [
    "print(location_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['holdinginhand', 'insidethebag', 'insidethepantpocket']\n",
      "Evaluating item 1/1626\n",
      "Evaluating item 2/1626\n",
      "Evaluating item 3/1626\n",
      "Evaluating item 4/1626\n",
      "Evaluating item 5/1626\n",
      "Evaluating item 6/1626\n",
      "Evaluating item 7/1626\n",
      "Evaluating item 8/1626\n",
      "Evaluating item 9/1626\n",
      "Evaluating item 10/1626\n",
      "Evaluating item 11/1626\n",
      "Evaluating item 12/1626\n",
      "Evaluating item 13/1626\n",
      "Evaluating item 14/1626\n",
      "Evaluating item 15/1626\n",
      "Evaluating item 16/1626\n",
      "Evaluating item 17/1626\n",
      "Evaluating item 18/1626\n",
      "Evaluating item 19/1626\n",
      "Evaluating item 20/1626\n",
      "Evaluating item 21/1626\n",
      "Evaluating item 22/1626\n",
      "Evaluating item 23/1626\n",
      "Evaluating item 24/1626\n",
      "Evaluating item 25/1626\n",
      "Evaluating item 26/1626\n",
      "Evaluating item 27/1626\n",
      "Evaluating item 28/1626\n",
      "Evaluating item 29/1626\n",
      "Evaluating item 30/1626\n",
      "Evaluating item 31/1626\n",
      "Evaluating item 32/1626\n",
      "Evaluating item 33/1626\n",
      "Evaluating item 34/1626\n",
      "Evaluating item 35/1626\n",
      "Evaluating item 36/1626\n",
      "Evaluating item 37/1626\n",
      "Evaluating item 38/1626\n",
      "Evaluating item 39/1626\n",
      "Evaluating item 40/1626\n",
      "Evaluating item 41/1626\n",
      "Evaluating item 42/1626\n",
      "Evaluating item 43/1626\n",
      "Evaluating item 44/1626\n",
      "Evaluating item 45/1626\n",
      "Evaluating item 46/1626\n",
      "Evaluating item 47/1626\n",
      "Evaluating item 48/1626\n",
      "Evaluating item 49/1626\n",
      "Evaluating item 50/1626\n",
      "Evaluating item 51/1626\n",
      "Evaluating item 52/1626\n",
      "Evaluating item 53/1626\n",
      "Evaluating item 54/1626\n",
      "Evaluating item 55/1626\n",
      "Evaluating item 56/1626\n",
      "Evaluating item 57/1626\n",
      "Evaluating item 58/1626\n",
      "Evaluating item 59/1626\n",
      "Evaluating item 60/1626\n",
      "Evaluating item 61/1626\n",
      "Evaluating item 62/1626\n",
      "Evaluating item 63/1626\n",
      "Evaluating item 64/1626\n",
      "Evaluating item 65/1626\n",
      "Evaluating item 66/1626\n",
      "Evaluating item 67/1626\n",
      "Evaluating item 68/1626\n",
      "Evaluating item 69/1626\n",
      "Evaluating item 70/1626\n",
      "Evaluating item 71/1626\n",
      "Evaluating item 72/1626\n",
      "Evaluating item 73/1626\n",
      "Evaluating item 74/1626\n",
      "Evaluating item 75/1626\n",
      "Evaluating item 76/1626\n",
      "Evaluating item 77/1626\n",
      "Evaluating item 78/1626\n",
      "Evaluating item 79/1626\n",
      "Evaluating item 80/1626\n",
      "Evaluating item 81/1626\n",
      "Evaluating item 82/1626\n",
      "Evaluating item 83/1626\n",
      "Evaluating item 84/1626\n",
      "Evaluating item 85/1626\n",
      "Evaluating item 86/1626\n",
      "Evaluating item 87/1626\n",
      "Evaluating item 88/1626\n",
      "Evaluating item 89/1626\n",
      "Evaluating item 90/1626\n",
      "Evaluating item 91/1626\n",
      "Evaluating item 92/1626\n",
      "Evaluating item 93/1626\n",
      "Evaluating item 94/1626\n",
      "Evaluating item 95/1626\n",
      "Evaluating item 96/1626\n",
      "Evaluating item 97/1626\n",
      "Evaluating item 98/1626\n",
      "Evaluating item 99/1626\n",
      "Evaluating item 100/1626\n",
      "Evaluating item 101/1626\n",
      "Evaluating item 102/1626\n",
      "Evaluating item 103/1626\n",
      "Evaluating item 104/1626\n",
      "Evaluating item 105/1626\n",
      "Evaluating item 106/1626\n",
      "Evaluating item 107/1626\n",
      "Evaluating item 108/1626\n",
      "Evaluating item 109/1626\n",
      "Evaluating item 110/1626\n",
      "Evaluating item 111/1626\n",
      "Evaluating item 112/1626\n",
      "Evaluating item 113/1626\n",
      "Evaluating item 114/1626\n",
      "Evaluating item 115/1626\n",
      "Evaluating item 116/1626\n",
      "Evaluating item 117/1626\n",
      "Evaluating item 118/1626\n",
      "Evaluating item 119/1626\n",
      "Evaluating item 120/1626\n",
      "Evaluating item 121/1626\n",
      "Evaluating item 122/1626\n",
      "Evaluating item 123/1626\n",
      "Evaluating item 124/1626\n",
      "Evaluating item 125/1626\n",
      "Evaluating item 126/1626\n",
      "Evaluating item 127/1626\n",
      "Evaluating item 128/1626\n",
      "Evaluating item 129/1626\n",
      "Evaluating item 130/1626\n",
      "Evaluating item 131/1626\n",
      "Evaluating item 132/1626\n",
      "Evaluating item 133/1626\n",
      "Evaluating item 134/1626\n",
      "Evaluating item 135/1626\n",
      "Evaluating item 136/1626\n",
      "Evaluating item 137/1626\n",
      "Evaluating item 138/1626\n",
      "Evaluating item 139/1626\n",
      "Evaluating item 140/1626\n",
      "Evaluating item 141/1626\n",
      "Evaluating item 142/1626\n",
      "Evaluating item 143/1626\n",
      "Evaluating item 144/1626\n",
      "Evaluating item 145/1626\n",
      "Evaluating item 146/1626\n",
      "Evaluating item 147/1626\n",
      "Evaluating item 148/1626\n",
      "Evaluating item 149/1626\n",
      "Evaluating item 150/1626\n",
      "Evaluating item 151/1626\n",
      "Evaluating item 152/1626\n",
      "Evaluating item 153/1626\n",
      "Evaluating item 154/1626\n",
      "Evaluating item 155/1626\n",
      "Evaluating item 156/1626\n",
      "Evaluating item 157/1626\n",
      "Evaluating item 158/1626\n",
      "Evaluating item 159/1626\n",
      "Evaluating item 160/1626\n",
      "Evaluating item 161/1626\n",
      "Evaluating item 162/1626\n",
      "Evaluating item 163/1626\n",
      "Evaluating item 164/1626\n",
      "Evaluating item 165/1626\n",
      "Evaluating item 166/1626\n",
      "Evaluating item 167/1626\n",
      "Evaluating item 168/1626\n",
      "Evaluating item 169/1626\n",
      "Evaluating item 170/1626\n",
      "Evaluating item 171/1626\n",
      "Evaluating item 172/1626\n",
      "Evaluating item 173/1626\n",
      "Evaluating item 174/1626\n",
      "Evaluating item 175/1626\n",
      "Evaluating item 176/1626\n",
      "Evaluating item 177/1626\n",
      "Evaluating item 178/1626\n",
      "Evaluating item 179/1626\n",
      "Evaluating item 180/1626\n",
      "Evaluating item 181/1626\n",
      "Evaluating item 182/1626\n",
      "Evaluating item 183/1626\n",
      "Evaluating item 184/1626\n",
      "Evaluating item 185/1626\n",
      "Evaluating item 186/1626\n",
      "Evaluating item 187/1626\n",
      "Evaluating item 188/1626\n",
      "Evaluating item 189/1626\n",
      "Evaluating item 190/1626\n",
      "Evaluating item 191/1626\n",
      "Evaluating item 192/1626\n",
      "Evaluating item 193/1626\n",
      "Evaluating item 194/1626\n",
      "Evaluating item 195/1626\n",
      "Evaluating item 196/1626\n",
      "Evaluating item 197/1626\n",
      "Evaluating item 198/1626\n",
      "Evaluating item 199/1626\n",
      "Evaluating item 200/1626\n",
      "Evaluating item 201/1626\n",
      "Evaluating item 202/1626\n",
      "Evaluating item 203/1626\n",
      "Evaluating item 204/1626\n",
      "Evaluating item 205/1626\n",
      "Evaluating item 206/1626\n",
      "Evaluating item 207/1626\n",
      "Evaluating item 208/1626\n",
      "Evaluating item 209/1626\n",
      "Evaluating item 210/1626\n",
      "Evaluating item 211/1626\n",
      "Evaluating item 212/1626\n",
      "Evaluating item 213/1626\n",
      "Evaluating item 214/1626\n",
      "Evaluating item 215/1626\n",
      "Evaluating item 216/1626\n",
      "Evaluating item 217/1626\n",
      "Evaluating item 218/1626\n",
      "Evaluating item 219/1626\n",
      "Evaluating item 220/1626\n",
      "Evaluating item 221/1626\n",
      "Evaluating item 222/1626\n",
      "Evaluating item 223/1626\n",
      "Evaluating item 224/1626\n",
      "Evaluating item 225/1626\n",
      "Evaluating item 226/1626\n",
      "Evaluating item 227/1626\n",
      "Evaluating item 228/1626\n",
      "Evaluating item 229/1626\n",
      "Evaluating item 230/1626\n",
      "Evaluating item 231/1626\n",
      "Evaluating item 232/1626\n",
      "Evaluating item 233/1626\n",
      "Evaluating item 234/1626\n",
      "Evaluating item 235/1626\n",
      "Evaluating item 236/1626\n",
      "Evaluating item 237/1626\n",
      "Evaluating item 238/1626\n",
      "Evaluating item 239/1626\n",
      "Evaluating item 240/1626\n",
      "Evaluating item 241/1626\n",
      "Evaluating item 242/1626\n",
      "Evaluating item 243/1626\n",
      "Evaluating item 244/1626\n",
      "Evaluating item 245/1626\n",
      "Evaluating item 246/1626\n",
      "Evaluating item 247/1626\n",
      "Evaluating item 248/1626\n",
      "Evaluating item 249/1626\n",
      "Evaluating item 250/1626\n",
      "Evaluating item 251/1626\n",
      "Evaluating item 252/1626\n",
      "Evaluating item 253/1626\n",
      "Evaluating item 254/1626\n",
      "Evaluating item 255/1626\n",
      "Evaluating item 256/1626\n",
      "Evaluating item 257/1626\n",
      "Evaluating item 258/1626\n",
      "Evaluating item 259/1626\n",
      "Evaluating item 260/1626\n",
      "Evaluating item 261/1626\n",
      "Evaluating item 262/1626\n",
      "Evaluating item 263/1626\n",
      "Evaluating item 264/1626\n",
      "Evaluating item 265/1626\n",
      "Evaluating item 266/1626\n",
      "Evaluating item 267/1626\n",
      "Evaluating item 268/1626\n",
      "Evaluating item 269/1626\n",
      "Evaluating item 270/1626\n",
      "Evaluating item 271/1626\n",
      "Evaluating item 272/1626\n",
      "Evaluating item 273/1626\n",
      "Evaluating item 274/1626\n",
      "Evaluating item 275/1626\n",
      "Evaluating item 276/1626\n",
      "Evaluating item 277/1626\n",
      "Evaluating item 278/1626\n",
      "Evaluating item 279/1626\n",
      "Evaluating item 280/1626\n",
      "Evaluating item 281/1626\n",
      "Evaluating item 282/1626\n",
      "Evaluating item 283/1626\n",
      "Evaluating item 284/1626\n",
      "Evaluating item 285/1626\n",
      "Evaluating item 286/1626\n",
      "Evaluating item 287/1626\n",
      "Evaluating item 288/1626\n",
      "Evaluating item 289/1626\n",
      "Evaluating item 290/1626\n",
      "Evaluating item 291/1626\n",
      "Evaluating item 292/1626\n",
      "Evaluating item 293/1626\n",
      "Evaluating item 294/1626\n",
      "Evaluating item 295/1626\n",
      "Evaluating item 296/1626\n",
      "Evaluating item 297/1626\n",
      "Evaluating item 298/1626\n",
      "Evaluating item 299/1626\n",
      "Evaluating item 300/1626\n",
      "Evaluating item 301/1626\n",
      "Evaluating item 302/1626\n",
      "Evaluating item 303/1626\n",
      "Evaluating item 304/1626\n",
      "Evaluating item 305/1626\n",
      "Evaluating item 306/1626\n",
      "Evaluating item 307/1626\n",
      "Evaluating item 308/1626\n",
      "Evaluating item 309/1626\n",
      "Evaluating item 310/1626\n",
      "Evaluating item 311/1626\n",
      "Evaluating item 312/1626\n",
      "Evaluating item 313/1626\n",
      "Evaluating item 314/1626\n",
      "Evaluating item 315/1626\n",
      "Evaluating item 316/1626\n",
      "Evaluating item 317/1626\n",
      "Evaluating item 318/1626\n",
      "Evaluating item 319/1626\n",
      "Evaluating item 320/1626\n",
      "Evaluating item 321/1626\n",
      "Evaluating item 322/1626\n",
      "Evaluating item 323/1626\n",
      "Evaluating item 324/1626\n",
      "Evaluating item 325/1626\n",
      "Evaluating item 326/1626\n",
      "Evaluating item 327/1626\n",
      "Evaluating item 328/1626\n",
      "Evaluating item 329/1626\n",
      "Evaluating item 330/1626\n",
      "Evaluating item 331/1626\n",
      "Evaluating item 332/1626\n",
      "Evaluating item 333/1626\n",
      "Evaluating item 334/1626\n",
      "Evaluating item 335/1626\n",
      "Evaluating item 336/1626\n",
      "Evaluating item 337/1626\n",
      "Evaluating item 338/1626\n",
      "Evaluating item 339/1626\n",
      "Evaluating item 340/1626\n",
      "Evaluating item 341/1626\n",
      "Evaluating item 342/1626\n",
      "Evaluating item 343/1626\n",
      "Evaluating item 344/1626\n",
      "Evaluating item 345/1626\n",
      "Evaluating item 346/1626\n",
      "Evaluating item 347/1626\n",
      "Evaluating item 348/1626\n",
      "Evaluating item 349/1626\n",
      "Evaluating item 350/1626\n",
      "Evaluating item 351/1626\n",
      "Evaluating item 352/1626\n",
      "Evaluating item 353/1626\n",
      "Evaluating item 354/1626\n",
      "Evaluating item 355/1626\n",
      "Evaluating item 356/1626\n",
      "Evaluating item 357/1626\n",
      "Evaluating item 358/1626\n",
      "Evaluating item 359/1626\n",
      "Evaluating item 360/1626\n",
      "Evaluating item 361/1626\n",
      "Evaluating item 362/1626\n",
      "Evaluating item 363/1626\n",
      "Evaluating item 364/1626\n",
      "Evaluating item 365/1626\n",
      "Evaluating item 366/1626\n",
      "Evaluating item 367/1626\n",
      "Evaluating item 368/1626\n",
      "Evaluating item 369/1626\n",
      "Evaluating item 370/1626\n",
      "Evaluating item 371/1626\n",
      "Evaluating item 372/1626\n",
      "Evaluating item 373/1626\n",
      "Evaluating item 374/1626\n",
      "Evaluating item 375/1626\n",
      "Evaluating item 376/1626\n",
      "Evaluating item 377/1626\n",
      "Evaluating item 378/1626\n",
      "Evaluating item 379/1626\n",
      "Evaluating item 380/1626\n",
      "Evaluating item 381/1626\n",
      "Evaluating item 382/1626\n",
      "Evaluating item 383/1626\n",
      "Evaluating item 384/1626\n",
      "Evaluating item 385/1626\n",
      "Evaluating item 386/1626\n",
      "Evaluating item 387/1626\n",
      "Evaluating item 388/1626\n",
      "Evaluating item 389/1626\n",
      "Evaluating item 390/1626\n",
      "Evaluating item 391/1626\n",
      "Evaluating item 392/1626\n",
      "Evaluating item 393/1626\n",
      "Evaluating item 394/1626\n",
      "Evaluating item 395/1626\n",
      "Evaluating item 396/1626\n",
      "Evaluating item 397/1626\n",
      "Evaluating item 398/1626\n",
      "Evaluating item 399/1626\n",
      "Evaluating item 400/1626\n",
      "Evaluating item 401/1626\n",
      "Evaluating item 402/1626\n",
      "Evaluating item 403/1626\n",
      "Evaluating item 404/1626\n",
      "Evaluating item 405/1626\n",
      "Evaluating item 406/1626\n",
      "Evaluating item 407/1626\n",
      "Evaluating item 408/1626\n",
      "Evaluating item 409/1626\n",
      "Evaluating item 410/1626\n",
      "Evaluating item 411/1626\n",
      "Evaluating item 412/1626\n",
      "Evaluating item 413/1626\n",
      "Evaluating item 414/1626\n",
      "Evaluating item 415/1626\n",
      "Evaluating item 416/1626\n",
      "Evaluating item 417/1626\n",
      "Evaluating item 418/1626\n",
      "Evaluating item 419/1626\n",
      "Evaluating item 420/1626\n",
      "Evaluating item 421/1626\n",
      "Evaluating item 422/1626\n",
      "Evaluating item 423/1626\n",
      "Evaluating item 424/1626\n",
      "Evaluating item 425/1626\n",
      "Evaluating item 426/1626\n",
      "Evaluating item 427/1626\n",
      "Evaluating item 428/1626\n",
      "Evaluating item 429/1626\n",
      "Evaluating item 430/1626\n",
      "Evaluating item 431/1626\n",
      "Evaluating item 432/1626\n",
      "Evaluating item 433/1626\n",
      "Evaluating item 434/1626\n",
      "Evaluating item 435/1626\n",
      "Evaluating item 436/1626\n",
      "Evaluating item 437/1626\n",
      "Evaluating item 438/1626\n",
      "Evaluating item 439/1626\n",
      "Evaluating item 440/1626\n",
      "Evaluating item 441/1626\n",
      "Evaluating item 442/1626\n",
      "Evaluating item 443/1626\n",
      "Evaluating item 444/1626\n",
      "Evaluating item 445/1626\n",
      "Evaluating item 446/1626\n",
      "Evaluating item 447/1626\n",
      "Evaluating item 448/1626\n",
      "Evaluating item 449/1626\n",
      "Evaluating item 450/1626\n",
      "Evaluating item 451/1626\n",
      "Evaluating item 452/1626\n",
      "Evaluating item 453/1626\n",
      "Evaluating item 454/1626\n",
      "Evaluating item 455/1626\n",
      "Evaluating item 456/1626\n",
      "Evaluating item 457/1626\n",
      "Evaluating item 458/1626\n",
      "Evaluating item 459/1626\n",
      "Evaluating item 460/1626\n",
      "Evaluating item 461/1626\n",
      "Evaluating item 462/1626\n",
      "Evaluating item 463/1626\n",
      "Evaluating item 464/1626\n",
      "Evaluating item 465/1626\n",
      "Evaluating item 466/1626\n",
      "Evaluating item 467/1626\n",
      "Evaluating item 468/1626\n",
      "Evaluating item 469/1626\n",
      "Evaluating item 470/1626\n",
      "Evaluating item 471/1626\n",
      "Evaluating item 472/1626\n",
      "Evaluating item 473/1626\n",
      "Evaluating item 474/1626\n",
      "Evaluating item 475/1626\n",
      "Evaluating item 476/1626\n",
      "Evaluating item 477/1626\n",
      "Evaluating item 478/1626\n",
      "Evaluating item 479/1626\n",
      "Evaluating item 480/1626\n",
      "Evaluating item 481/1626\n",
      "Evaluating item 482/1626\n",
      "Evaluating item 483/1626\n",
      "Evaluating item 484/1626\n",
      "Evaluating item 485/1626\n",
      "Evaluating item 486/1626\n",
      "Evaluating item 487/1626\n",
      "Evaluating item 488/1626\n",
      "Evaluating item 489/1626\n",
      "Evaluating item 490/1626\n",
      "Evaluating item 491/1626\n",
      "Evaluating item 492/1626\n",
      "Evaluating item 493/1626\n",
      "Evaluating item 494/1626\n",
      "Evaluating item 495/1626\n",
      "Evaluating item 496/1626\n",
      "Evaluating item 497/1626\n",
      "Evaluating item 498/1626\n",
      "Evaluating item 499/1626\n",
      "Evaluating item 500/1626\n",
      "Evaluating item 501/1626\n",
      "Evaluating item 502/1626\n",
      "Evaluating item 503/1626\n",
      "Evaluating item 504/1626\n",
      "Evaluating item 505/1626\n",
      "Evaluating item 506/1626\n",
      "Evaluating item 507/1626\n",
      "Evaluating item 508/1626\n",
      "Evaluating item 509/1626\n",
      "Evaluating item 510/1626\n",
      "Evaluating item 511/1626\n",
      "Evaluating item 512/1626\n",
      "Evaluating item 513/1626\n",
      "Evaluating item 514/1626\n",
      "Evaluating item 515/1626\n",
      "Evaluating item 516/1626\n",
      "Evaluating item 517/1626\n",
      "Evaluating item 518/1626\n",
      "Evaluating item 519/1626\n",
      "Evaluating item 520/1626\n",
      "Evaluating item 521/1626\n",
      "Evaluating item 522/1626\n",
      "Evaluating item 523/1626\n",
      "Evaluating item 524/1626\n",
      "Evaluating item 525/1626\n",
      "Evaluating item 526/1626\n",
      "Evaluating item 527/1626\n",
      "Evaluating item 528/1626\n",
      "Evaluating item 529/1626\n",
      "Evaluating item 530/1626\n",
      "Evaluating item 531/1626\n",
      "Evaluating item 532/1626\n",
      "Evaluating item 533/1626\n",
      "Evaluating item 534/1626\n",
      "Evaluating item 535/1626\n",
      "Evaluating item 536/1626\n",
      "Evaluating item 537/1626\n",
      "Evaluating item 538/1626\n",
      "Evaluating item 539/1626\n",
      "Evaluating item 540/1626\n",
      "Evaluating item 541/1626\n",
      "Evaluating item 542/1626\n",
      "Evaluating item 543/1626\n",
      "Evaluating item 544/1626\n",
      "Evaluating item 545/1626\n",
      "Evaluating item 546/1626\n",
      "Evaluating item 547/1626\n",
      "Evaluating item 548/1626\n",
      "Evaluating item 549/1626\n",
      "Evaluating item 550/1626\n",
      "Evaluating item 551/1626\n",
      "Evaluating item 552/1626\n",
      "Evaluating item 553/1626\n",
      "Evaluating item 554/1626\n",
      "Evaluating item 555/1626\n",
      "Evaluating item 556/1626\n",
      "Evaluating item 557/1626\n",
      "Evaluating item 558/1626\n",
      "Evaluating item 559/1626\n",
      "Evaluating item 560/1626\n",
      "Evaluating item 561/1626\n",
      "Evaluating item 562/1626\n",
      "Evaluating item 563/1626\n",
      "Evaluating item 564/1626\n",
      "Evaluating item 565/1626\n",
      "Evaluating item 566/1626\n",
      "Evaluating item 567/1626\n",
      "Evaluating item 568/1626\n",
      "Evaluating item 569/1626\n",
      "Evaluating item 570/1626\n",
      "Evaluating item 571/1626\n",
      "Evaluating item 572/1626\n",
      "Evaluating item 573/1626\n",
      "Evaluating item 574/1626\n",
      "Evaluating item 575/1626\n",
      "Evaluating item 576/1626\n",
      "Evaluating item 577/1626\n",
      "Evaluating item 578/1626\n",
      "Evaluating item 579/1626\n",
      "Evaluating item 580/1626\n",
      "Evaluating item 581/1626\n",
      "Evaluating item 582/1626\n",
      "Evaluating item 583/1626\n",
      "Evaluating item 584/1626\n",
      "Evaluating item 585/1626\n",
      "Evaluating item 586/1626\n",
      "Evaluating item 587/1626\n",
      "Evaluating item 588/1626\n",
      "Evaluating item 589/1626\n",
      "Evaluating item 590/1626\n",
      "Evaluating item 591/1626\n",
      "Evaluating item 592/1626\n",
      "Evaluating item 593/1626\n",
      "Evaluating item 594/1626\n",
      "Evaluating item 595/1626\n",
      "Evaluating item 596/1626\n",
      "Evaluating item 597/1626\n",
      "Evaluating item 598/1626\n",
      "Evaluating item 599/1626\n",
      "Evaluating item 600/1626\n",
      "Evaluating item 601/1626\n",
      "Evaluating item 602/1626\n",
      "Evaluating item 603/1626\n",
      "Evaluating item 604/1626\n",
      "Evaluating item 605/1626\n",
      "Evaluating item 606/1626\n",
      "Evaluating item 607/1626\n",
      "Evaluating item 608/1626\n",
      "Evaluating item 609/1626\n",
      "Evaluating item 610/1626\n",
      "Evaluating item 611/1626\n",
      "Evaluating item 612/1626\n",
      "Evaluating item 613/1626\n",
      "Evaluating item 614/1626\n",
      "Evaluating item 615/1626\n",
      "Evaluating item 616/1626\n",
      "Evaluating item 617/1626\n",
      "Evaluating item 618/1626\n",
      "Evaluating item 619/1626\n",
      "Evaluating item 620/1626\n",
      "Evaluating item 621/1626\n",
      "Evaluating item 622/1626\n",
      "Evaluating item 623/1626\n",
      "Evaluating item 624/1626\n",
      "Evaluating item 625/1626\n",
      "Evaluating item 626/1626\n",
      "Evaluating item 627/1626\n",
      "Evaluating item 628/1626\n",
      "Evaluating item 629/1626\n",
      "Evaluating item 630/1626\n",
      "Evaluating item 631/1626\n",
      "Evaluating item 632/1626\n",
      "Evaluating item 633/1626\n",
      "Evaluating item 634/1626\n",
      "Evaluating item 635/1626\n",
      "Evaluating item 636/1626\n",
      "Evaluating item 637/1626\n",
      "Evaluating item 638/1626\n",
      "Evaluating item 639/1626\n",
      "Evaluating item 640/1626\n",
      "Evaluating item 641/1626\n",
      "Evaluating item 642/1626\n",
      "Evaluating item 643/1626\n",
      "Evaluating item 644/1626\n",
      "Evaluating item 645/1626\n",
      "Evaluating item 646/1626\n",
      "Evaluating item 647/1626\n",
      "Evaluating item 648/1626\n",
      "Evaluating item 649/1626\n",
      "Evaluating item 650/1626\n",
      "Evaluating item 651/1626\n",
      "Evaluating item 652/1626\n",
      "Evaluating item 653/1626\n",
      "Evaluating item 654/1626\n",
      "Evaluating item 655/1626\n",
      "Evaluating item 656/1626\n",
      "Evaluating item 657/1626\n",
      "Evaluating item 658/1626\n",
      "Evaluating item 659/1626\n",
      "Evaluating item 660/1626\n",
      "Evaluating item 661/1626\n",
      "Evaluating item 662/1626\n",
      "Evaluating item 663/1626\n",
      "Evaluating item 664/1626\n",
      "Evaluating item 665/1626\n",
      "Evaluating item 666/1626\n",
      "Evaluating item 667/1626\n",
      "Evaluating item 668/1626\n",
      "Evaluating item 669/1626\n",
      "Evaluating item 670/1626\n",
      "Evaluating item 671/1626\n",
      "Evaluating item 672/1626\n",
      "Evaluating item 673/1626\n",
      "Evaluating item 674/1626\n",
      "Evaluating item 675/1626\n",
      "Evaluating item 676/1626\n",
      "Evaluating item 677/1626\n",
      "Evaluating item 678/1626\n",
      "Evaluating item 679/1626\n",
      "Evaluating item 680/1626\n",
      "Evaluating item 681/1626\n",
      "Evaluating item 682/1626\n",
      "Evaluating item 683/1626\n",
      "Evaluating item 684/1626\n",
      "Evaluating item 685/1626\n",
      "Evaluating item 686/1626\n",
      "Evaluating item 687/1626\n",
      "Evaluating item 688/1626\n",
      "Evaluating item 689/1626\n",
      "Evaluating item 690/1626\n",
      "Evaluating item 691/1626\n",
      "Evaluating item 692/1626\n",
      "Evaluating item 693/1626\n",
      "Evaluating item 694/1626\n",
      "Evaluating item 695/1626\n",
      "Evaluating item 696/1626\n",
      "Evaluating item 697/1626\n",
      "Evaluating item 698/1626\n",
      "Evaluating item 699/1626\n",
      "Evaluating item 700/1626\n",
      "Evaluating item 701/1626\n",
      "Evaluating item 702/1626\n",
      "Evaluating item 703/1626\n",
      "Evaluating item 704/1626\n",
      "Evaluating item 705/1626\n",
      "Evaluating item 706/1626\n",
      "Evaluating item 707/1626\n",
      "Evaluating item 708/1626\n",
      "Evaluating item 709/1626\n",
      "Evaluating item 710/1626\n",
      "Evaluating item 711/1626\n",
      "Evaluating item 712/1626\n",
      "Evaluating item 713/1626\n",
      "Evaluating item 714/1626\n",
      "Evaluating item 715/1626\n",
      "Evaluating item 716/1626\n",
      "Evaluating item 717/1626\n",
      "Evaluating item 718/1626\n",
      "Evaluating item 719/1626\n",
      "Evaluating item 720/1626\n",
      "Evaluating item 721/1626\n",
      "Evaluating item 722/1626\n",
      "Evaluating item 723/1626\n",
      "Evaluating item 724/1626\n",
      "Evaluating item 725/1626\n",
      "Evaluating item 726/1626\n",
      "Evaluating item 727/1626\n",
      "Evaluating item 728/1626\n",
      "Evaluating item 729/1626\n",
      "Evaluating item 730/1626\n",
      "Evaluating item 731/1626\n",
      "Evaluating item 732/1626\n",
      "Evaluating item 733/1626\n",
      "Evaluating item 734/1626\n",
      "Evaluating item 735/1626\n",
      "Evaluating item 736/1626\n",
      "Evaluating item 737/1626\n",
      "Evaluating item 738/1626\n",
      "Evaluating item 739/1626\n",
      "Evaluating item 740/1626\n",
      "Evaluating item 741/1626\n",
      "Evaluating item 742/1626\n",
      "Evaluating item 743/1626\n",
      "Evaluating item 744/1626\n",
      "Evaluating item 745/1626\n",
      "Evaluating item 746/1626\n",
      "Evaluating item 747/1626\n",
      "Evaluating item 748/1626\n",
      "Evaluating item 749/1626\n",
      "Evaluating item 750/1626\n",
      "Evaluating item 751/1626\n",
      "Evaluating item 752/1626\n",
      "Evaluating item 753/1626\n",
      "Evaluating item 754/1626\n",
      "Evaluating item 755/1626\n",
      "Evaluating item 756/1626\n",
      "Evaluating item 757/1626\n",
      "Evaluating item 758/1626\n",
      "Evaluating item 759/1626\n",
      "Evaluating item 760/1626\n",
      "Evaluating item 761/1626\n",
      "Evaluating item 762/1626\n",
      "Evaluating item 763/1626\n",
      "Evaluating item 764/1626\n",
      "Evaluating item 765/1626\n",
      "Evaluating item 766/1626\n",
      "Evaluating item 767/1626\n",
      "Evaluating item 768/1626\n",
      "Evaluating item 769/1626\n",
      "Evaluating item 770/1626\n",
      "Evaluating item 771/1626\n",
      "Evaluating item 772/1626\n",
      "Evaluating item 773/1626\n",
      "Evaluating item 774/1626\n",
      "Evaluating item 775/1626\n",
      "Evaluating item 776/1626\n",
      "Evaluating item 777/1626\n",
      "Evaluating item 778/1626\n",
      "Evaluating item 779/1626\n",
      "Evaluating item 780/1626\n",
      "Evaluating item 781/1626\n",
      "Evaluating item 782/1626\n",
      "Evaluating item 783/1626\n",
      "Evaluating item 784/1626\n",
      "Evaluating item 785/1626\n",
      "Evaluating item 786/1626\n",
      "Evaluating item 787/1626\n",
      "Evaluating item 788/1626\n",
      "Evaluating item 789/1626\n",
      "Evaluating item 790/1626\n",
      "Evaluating item 791/1626\n",
      "Evaluating item 792/1626\n",
      "Evaluating item 793/1626\n",
      "Evaluating item 794/1626\n",
      "Evaluating item 795/1626\n",
      "Evaluating item 796/1626\n",
      "Evaluating item 797/1626\n",
      "Evaluating item 798/1626\n",
      "Evaluating item 799/1626\n",
      "Evaluating item 800/1626\n",
      "Evaluating item 801/1626\n",
      "Evaluating item 802/1626\n",
      "Evaluating item 803/1626\n",
      "Evaluating item 804/1626\n",
      "Evaluating item 805/1626\n",
      "Evaluating item 806/1626\n",
      "Evaluating item 807/1626\n",
      "Evaluating item 808/1626\n",
      "Evaluating item 809/1626\n",
      "Evaluating item 810/1626\n",
      "Evaluating item 811/1626\n",
      "Evaluating item 812/1626\n",
      "Evaluating item 813/1626\n",
      "Evaluating item 814/1626\n",
      "Evaluating item 815/1626\n",
      "Evaluating item 816/1626\n",
      "Evaluating item 817/1626\n",
      "Evaluating item 818/1626\n",
      "Evaluating item 819/1626\n",
      "Evaluating item 820/1626\n",
      "Evaluating item 821/1626\n",
      "Evaluating item 822/1626\n",
      "Evaluating item 823/1626\n",
      "Evaluating item 824/1626\n",
      "Evaluating item 825/1626\n",
      "Evaluating item 826/1626\n",
      "Evaluating item 827/1626\n",
      "Evaluating item 828/1626\n",
      "Evaluating item 829/1626\n",
      "Evaluating item 830/1626\n",
      "Evaluating item 831/1626\n",
      "Evaluating item 832/1626\n",
      "Evaluating item 833/1626\n",
      "Evaluating item 834/1626\n",
      "Evaluating item 835/1626\n",
      "Evaluating item 836/1626\n",
      "Evaluating item 837/1626\n",
      "Evaluating item 838/1626\n",
      "Evaluating item 839/1626\n",
      "Evaluating item 840/1626\n",
      "Evaluating item 841/1626\n",
      "Evaluating item 842/1626\n",
      "Evaluating item 843/1626\n",
      "Evaluating item 844/1626\n",
      "Evaluating item 845/1626\n",
      "Evaluating item 846/1626\n",
      "Evaluating item 847/1626\n",
      "Evaluating item 848/1626\n",
      "Evaluating item 849/1626\n",
      "Evaluating item 850/1626\n",
      "Evaluating item 851/1626\n",
      "Evaluating item 852/1626\n",
      "Evaluating item 853/1626\n",
      "Evaluating item 854/1626\n",
      "Evaluating item 855/1626\n",
      "Evaluating item 856/1626\n",
      "Evaluating item 857/1626\n",
      "Evaluating item 858/1626\n",
      "Evaluating item 859/1626\n",
      "Evaluating item 860/1626\n",
      "Evaluating item 861/1626\n",
      "Evaluating item 862/1626\n",
      "Evaluating item 863/1626\n",
      "Evaluating item 864/1626\n",
      "Evaluating item 865/1626\n",
      "Evaluating item 866/1626\n",
      "Evaluating item 867/1626\n",
      "Evaluating item 868/1626\n",
      "Evaluating item 869/1626\n",
      "Evaluating item 870/1626\n",
      "Evaluating item 871/1626\n",
      "Evaluating item 872/1626\n",
      "Evaluating item 873/1626\n",
      "Evaluating item 874/1626\n",
      "Evaluating item 875/1626\n",
      "Evaluating item 876/1626\n",
      "Evaluating item 877/1626\n",
      "Evaluating item 878/1626\n",
      "Evaluating item 879/1626\n",
      "Evaluating item 880/1626\n",
      "Evaluating item 881/1626\n",
      "Evaluating item 882/1626\n",
      "Evaluating item 883/1626\n",
      "Evaluating item 884/1626\n",
      "Evaluating item 885/1626\n",
      "Evaluating item 886/1626\n",
      "Evaluating item 887/1626\n",
      "Evaluating item 888/1626\n",
      "Evaluating item 889/1626\n",
      "Evaluating item 890/1626\n",
      "Evaluating item 891/1626\n",
      "Evaluating item 892/1626\n",
      "Evaluating item 893/1626\n",
      "Evaluating item 894/1626\n",
      "Evaluating item 895/1626\n",
      "Evaluating item 896/1626\n",
      "Evaluating item 897/1626\n",
      "Evaluating item 898/1626\n",
      "Evaluating item 899/1626\n",
      "Evaluating item 900/1626\n",
      "Evaluating item 901/1626\n",
      "Evaluating item 902/1626\n",
      "Evaluating item 903/1626\n",
      "Evaluating item 904/1626\n",
      "Evaluating item 905/1626\n",
      "Evaluating item 906/1626\n",
      "Evaluating item 907/1626\n",
      "Evaluating item 908/1626\n",
      "Evaluating item 909/1626\n",
      "Evaluating item 910/1626\n",
      "Evaluating item 911/1626\n",
      "Evaluating item 912/1626\n",
      "Evaluating item 913/1626\n",
      "Evaluating item 914/1626\n",
      "Evaluating item 915/1626\n",
      "Evaluating item 916/1626\n",
      "Evaluating item 917/1626\n",
      "Evaluating item 918/1626\n",
      "Evaluating item 919/1626\n",
      "Evaluating item 920/1626\n",
      "Evaluating item 921/1626\n",
      "Evaluating item 922/1626\n",
      "Evaluating item 923/1626\n",
      "Evaluating item 924/1626\n",
      "Evaluating item 925/1626\n",
      "Evaluating item 926/1626\n",
      "Evaluating item 927/1626\n",
      "Evaluating item 928/1626\n",
      "Evaluating item 929/1626\n",
      "Evaluating item 930/1626\n",
      "Evaluating item 931/1626\n",
      "Evaluating item 932/1626\n",
      "Evaluating item 933/1626\n",
      "Evaluating item 934/1626\n",
      "Evaluating item 935/1626\n",
      "Evaluating item 936/1626\n",
      "Evaluating item 937/1626\n",
      "Evaluating item 938/1626\n",
      "Evaluating item 939/1626\n",
      "Evaluating item 940/1626\n",
      "Evaluating item 941/1626\n",
      "Evaluating item 942/1626\n",
      "Evaluating item 943/1626\n",
      "Evaluating item 944/1626\n",
      "Evaluating item 945/1626\n",
      "Evaluating item 946/1626\n",
      "Evaluating item 947/1626\n",
      "Evaluating item 948/1626\n",
      "Evaluating item 949/1626\n",
      "Evaluating item 950/1626\n",
      "Evaluating item 951/1626\n",
      "Evaluating item 952/1626\n",
      "Evaluating item 953/1626\n",
      "Evaluating item 954/1626\n",
      "Evaluating item 955/1626\n",
      "Evaluating item 956/1626\n",
      "Evaluating item 957/1626\n",
      "Evaluating item 958/1626\n",
      "Evaluating item 959/1626\n",
      "Evaluating item 960/1626\n",
      "Evaluating item 961/1626\n",
      "Evaluating item 962/1626\n",
      "Evaluating item 963/1626\n",
      "Evaluating item 964/1626\n",
      "Evaluating item 965/1626\n",
      "Evaluating item 966/1626\n",
      "Evaluating item 967/1626\n",
      "Evaluating item 968/1626\n",
      "Evaluating item 969/1626\n",
      "Evaluating item 970/1626\n",
      "Evaluating item 971/1626\n",
      "Evaluating item 972/1626\n",
      "Evaluating item 973/1626\n",
      "Evaluating item 974/1626\n",
      "Evaluating item 975/1626\n",
      "Evaluating item 976/1626\n",
      "Evaluating item 977/1626\n",
      "Evaluating item 978/1626\n",
      "Evaluating item 979/1626\n",
      "Evaluating item 980/1626\n",
      "Evaluating item 981/1626\n",
      "Evaluating item 982/1626\n",
      "Evaluating item 983/1626\n",
      "Evaluating item 984/1626\n",
      "Evaluating item 985/1626\n",
      "Evaluating item 986/1626\n",
      "Evaluating item 987/1626\n",
      "Evaluating item 988/1626\n",
      "Evaluating item 989/1626\n",
      "Evaluating item 990/1626\n",
      "Evaluating item 991/1626\n",
      "Evaluating item 992/1626\n",
      "Evaluating item 993/1626\n",
      "Evaluating item 994/1626\n",
      "Evaluating item 995/1626\n",
      "Evaluating item 996/1626\n",
      "Evaluating item 997/1626\n",
      "Evaluating item 998/1626\n",
      "Evaluating item 999/1626\n",
      "Evaluating item 1000/1626\n",
      "Evaluating item 1001/1626\n",
      "Evaluating item 1002/1626\n",
      "Evaluating item 1003/1626\n",
      "Evaluating item 1004/1626\n",
      "Evaluating item 1005/1626\n",
      "Evaluating item 1006/1626\n",
      "Evaluating item 1007/1626\n",
      "Evaluating item 1008/1626\n",
      "Evaluating item 1009/1626\n",
      "Evaluating item 1010/1626\n",
      "Evaluating item 1011/1626\n",
      "Evaluating item 1012/1626\n",
      "Evaluating item 1013/1626\n",
      "Evaluating item 1014/1626\n",
      "Evaluating item 1015/1626\n",
      "Evaluating item 1016/1626\n",
      "Evaluating item 1017/1626\n",
      "Evaluating item 1018/1626\n",
      "Evaluating item 1019/1626\n",
      "Evaluating item 1020/1626\n",
      "Evaluating item 1021/1626\n",
      "Evaluating item 1022/1626\n",
      "Evaluating item 1023/1626\n",
      "Evaluating item 1024/1626\n",
      "Evaluating item 1025/1626\n",
      "Evaluating item 1026/1626\n",
      "Evaluating item 1027/1626\n",
      "Evaluating item 1028/1626\n",
      "Evaluating item 1029/1626\n",
      "Evaluating item 1030/1626\n",
      "Evaluating item 1031/1626\n",
      "Evaluating item 1032/1626\n",
      "Evaluating item 1033/1626\n",
      "Evaluating item 1034/1626\n",
      "Evaluating item 1035/1626\n",
      "Evaluating item 1036/1626\n",
      "Evaluating item 1037/1626\n",
      "Evaluating item 1038/1626\n",
      "Evaluating item 1039/1626\n",
      "Evaluating item 1040/1626\n",
      "Evaluating item 1041/1626\n",
      "Evaluating item 1042/1626\n",
      "Evaluating item 1043/1626\n",
      "Evaluating item 1044/1626\n",
      "Evaluating item 1045/1626\n",
      "Evaluating item 1046/1626\n",
      "Evaluating item 1047/1626\n",
      "Evaluating item 1048/1626\n",
      "Evaluating item 1049/1626\n",
      "Evaluating item 1050/1626\n",
      "Evaluating item 1051/1626\n",
      "Evaluating item 1052/1626\n",
      "Evaluating item 1053/1626\n",
      "Evaluating item 1054/1626\n",
      "Evaluating item 1055/1626\n",
      "Evaluating item 1056/1626\n",
      "Evaluating item 1057/1626\n",
      "Evaluating item 1058/1626\n",
      "Evaluating item 1059/1626\n",
      "Evaluating item 1060/1626\n",
      "Evaluating item 1061/1626\n",
      "Evaluating item 1062/1626\n",
      "Evaluating item 1063/1626\n",
      "Evaluating item 1064/1626\n",
      "Evaluating item 1065/1626\n",
      "Evaluating item 1066/1626\n",
      "Evaluating item 1067/1626\n",
      "Evaluating item 1068/1626\n",
      "Evaluating item 1069/1626\n",
      "Evaluating item 1070/1626\n",
      "Evaluating item 1071/1626\n",
      "Evaluating item 1072/1626\n",
      "Evaluating item 1073/1626\n",
      "Evaluating item 1074/1626\n",
      "Evaluating item 1075/1626\n",
      "Evaluating item 1076/1626\n",
      "Evaluating item 1077/1626\n",
      "Evaluating item 1078/1626\n",
      "Evaluating item 1079/1626\n",
      "Evaluating item 1080/1626\n",
      "Evaluating item 1081/1626\n",
      "Evaluating item 1082/1626\n",
      "Evaluating item 1083/1626\n",
      "Evaluating item 1084/1626\n",
      "Evaluating item 1085/1626\n",
      "Evaluating item 1086/1626\n",
      "Evaluating item 1087/1626\n",
      "Evaluating item 1088/1626\n",
      "Evaluating item 1089/1626\n",
      "Evaluating item 1090/1626\n",
      "Evaluating item 1091/1626\n",
      "Evaluating item 1092/1626\n",
      "Evaluating item 1093/1626\n",
      "Evaluating item 1094/1626\n",
      "Evaluating item 1095/1626\n",
      "Evaluating item 1096/1626\n",
      "Evaluating item 1097/1626\n",
      "Evaluating item 1098/1626\n",
      "Evaluating item 1099/1626\n",
      "Evaluating item 1100/1626\n",
      "Evaluating item 1101/1626\n",
      "Evaluating item 1102/1626\n",
      "Evaluating item 1103/1626\n",
      "Evaluating item 1104/1626\n",
      "Evaluating item 1105/1626\n",
      "Evaluating item 1106/1626\n",
      "Evaluating item 1107/1626\n",
      "Evaluating item 1108/1626\n",
      "Evaluating item 1109/1626\n",
      "Evaluating item 1110/1626\n",
      "Evaluating item 1111/1626\n",
      "Evaluating item 1112/1626\n",
      "Evaluating item 1113/1626\n",
      "Evaluating item 1114/1626\n",
      "Evaluating item 1115/1626\n",
      "Evaluating item 1116/1626\n",
      "Evaluating item 1117/1626\n",
      "Evaluating item 1118/1626\n",
      "Evaluating item 1119/1626\n",
      "Evaluating item 1120/1626\n",
      "Evaluating item 1121/1626\n",
      "Evaluating item 1122/1626\n",
      "Evaluating item 1123/1626\n",
      "Evaluating item 1124/1626\n",
      "Evaluating item 1125/1626\n",
      "Evaluating item 1126/1626\n",
      "Evaluating item 1127/1626\n",
      "Evaluating item 1128/1626\n",
      "Evaluating item 1129/1626\n",
      "Evaluating item 1130/1626\n",
      "Evaluating item 1131/1626\n",
      "Evaluating item 1132/1626\n",
      "Evaluating item 1133/1626\n",
      "Evaluating item 1134/1626\n",
      "Evaluating item 1135/1626\n",
      "Evaluating item 1136/1626\n",
      "Evaluating item 1137/1626\n",
      "Evaluating item 1138/1626\n",
      "Evaluating item 1139/1626\n",
      "Evaluating item 1140/1626\n",
      "Evaluating item 1141/1626\n",
      "Evaluating item 1142/1626\n",
      "Evaluating item 1143/1626\n",
      "Evaluating item 1144/1626\n",
      "Evaluating item 1145/1626\n",
      "Evaluating item 1146/1626\n",
      "Evaluating item 1147/1626\n",
      "Evaluating item 1148/1626\n",
      "Evaluating item 1149/1626\n",
      "Evaluating item 1150/1626\n",
      "Evaluating item 1151/1626\n",
      "Evaluating item 1152/1626\n",
      "Evaluating item 1153/1626\n",
      "Evaluating item 1154/1626\n",
      "Evaluating item 1155/1626\n",
      "Evaluating item 1156/1626\n",
      "Evaluating item 1157/1626\n",
      "Evaluating item 1158/1626\n",
      "Evaluating item 1159/1626\n",
      "Evaluating item 1160/1626\n",
      "Evaluating item 1161/1626\n",
      "Evaluating item 1162/1626\n",
      "Evaluating item 1163/1626\n",
      "Evaluating item 1164/1626\n",
      "Evaluating item 1165/1626\n",
      "Evaluating item 1166/1626\n",
      "Evaluating item 1167/1626\n",
      "Evaluating item 1168/1626\n",
      "Evaluating item 1169/1626\n",
      "Evaluating item 1170/1626\n",
      "Evaluating item 1171/1626\n",
      "Evaluating item 1172/1626\n",
      "Evaluating item 1173/1626\n",
      "Evaluating item 1174/1626\n",
      "Evaluating item 1175/1626\n",
      "Evaluating item 1176/1626\n",
      "Evaluating item 1177/1626\n",
      "Evaluating item 1178/1626\n",
      "Evaluating item 1179/1626\n",
      "Evaluating item 1180/1626\n",
      "Evaluating item 1181/1626\n",
      "Evaluating item 1182/1626\n",
      "Evaluating item 1183/1626\n",
      "Evaluating item 1184/1626\n",
      "Evaluating item 1185/1626\n",
      "Evaluating item 1186/1626\n",
      "Evaluating item 1187/1626\n",
      "Evaluating item 1188/1626\n",
      "Evaluating item 1189/1626\n",
      "Evaluating item 1190/1626\n",
      "Evaluating item 1191/1626\n",
      "Evaluating item 1192/1626\n",
      "Evaluating item 1193/1626\n",
      "Evaluating item 1194/1626\n",
      "Evaluating item 1195/1626\n",
      "Evaluating item 1196/1626\n",
      "Evaluating item 1197/1626\n",
      "Evaluating item 1198/1626\n",
      "Evaluating item 1199/1626\n",
      "Evaluating item 1200/1626\n",
      "Evaluating item 1201/1626\n",
      "Evaluating item 1202/1626\n",
      "Evaluating item 1203/1626\n",
      "Evaluating item 1204/1626\n",
      "Evaluating item 1205/1626\n",
      "Evaluating item 1206/1626\n",
      "Evaluating item 1207/1626\n",
      "Evaluating item 1208/1626\n",
      "Evaluating item 1209/1626\n",
      "Evaluating item 1210/1626\n",
      "Evaluating item 1211/1626\n",
      "Evaluating item 1212/1626\n",
      "Evaluating item 1213/1626\n",
      "Evaluating item 1214/1626\n",
      "Evaluating item 1215/1626\n",
      "Evaluating item 1216/1626\n",
      "Evaluating item 1217/1626\n",
      "Evaluating item 1218/1626\n",
      "Evaluating item 1219/1626\n",
      "Evaluating item 1220/1626\n",
      "Evaluating item 1221/1626\n",
      "Evaluating item 1222/1626\n",
      "Evaluating item 1223/1626\n",
      "Evaluating item 1224/1626\n",
      "Evaluating item 1225/1626\n",
      "Evaluating item 1226/1626\n",
      "Evaluating item 1227/1626\n",
      "Evaluating item 1228/1626\n",
      "Evaluating item 1229/1626\n",
      "Evaluating item 1230/1626\n",
      "Evaluating item 1231/1626\n",
      "Evaluating item 1232/1626\n",
      "Evaluating item 1233/1626\n",
      "Evaluating item 1234/1626\n",
      "Evaluating item 1235/1626\n",
      "Evaluating item 1236/1626\n",
      "Evaluating item 1237/1626\n",
      "Evaluating item 1238/1626\n",
      "Evaluating item 1239/1626\n",
      "Evaluating item 1240/1626\n",
      "Evaluating item 1241/1626\n",
      "Evaluating item 1242/1626\n",
      "Evaluating item 1243/1626\n",
      "Evaluating item 1244/1626\n",
      "Evaluating item 1245/1626\n",
      "Evaluating item 1246/1626\n",
      "Evaluating item 1247/1626\n",
      "Evaluating item 1248/1626\n",
      "Evaluating item 1249/1626\n",
      "Evaluating item 1250/1626\n",
      "Evaluating item 1251/1626\n",
      "Evaluating item 1252/1626\n",
      "Evaluating item 1253/1626\n",
      "Evaluating item 1254/1626\n",
      "Evaluating item 1255/1626\n",
      "Evaluating item 1256/1626\n",
      "Evaluating item 1257/1626\n",
      "Evaluating item 1258/1626\n",
      "Evaluating item 1259/1626\n",
      "Evaluating item 1260/1626\n",
      "Evaluating item 1261/1626\n",
      "Evaluating item 1262/1626\n",
      "Evaluating item 1263/1626\n",
      "Evaluating item 1264/1626\n",
      "Evaluating item 1265/1626\n",
      "Evaluating item 1266/1626\n",
      "Evaluating item 1267/1626\n",
      "Evaluating item 1268/1626\n",
      "Evaluating item 1269/1626\n",
      "Evaluating item 1270/1626\n",
      "Evaluating item 1271/1626\n",
      "Evaluating item 1272/1626\n",
      "Evaluating item 1273/1626\n",
      "Evaluating item 1274/1626\n",
      "Evaluating item 1275/1626\n",
      "Evaluating item 1276/1626\n",
      "Evaluating item 1277/1626\n",
      "Evaluating item 1278/1626\n",
      "Evaluating item 1279/1626\n",
      "Evaluating item 1280/1626\n",
      "Evaluating item 1281/1626\n",
      "Evaluating item 1282/1626\n",
      "Evaluating item 1283/1626\n",
      "Evaluating item 1284/1626\n",
      "Evaluating item 1285/1626\n",
      "Evaluating item 1286/1626\n",
      "Evaluating item 1287/1626\n",
      "Evaluating item 1288/1626\n",
      "Evaluating item 1289/1626\n",
      "Evaluating item 1290/1626\n",
      "Evaluating item 1291/1626\n",
      "Evaluating item 1292/1626\n",
      "Evaluating item 1293/1626\n",
      "Evaluating item 1294/1626\n",
      "Evaluating item 1295/1626\n",
      "Evaluating item 1296/1626\n",
      "Evaluating item 1297/1626\n",
      "Evaluating item 1298/1626\n",
      "Evaluating item 1299/1626\n",
      "Evaluating item 1300/1626\n",
      "Evaluating item 1301/1626\n",
      "Evaluating item 1302/1626\n",
      "Evaluating item 1303/1626\n",
      "Evaluating item 1304/1626\n",
      "Evaluating item 1305/1626\n",
      "Evaluating item 1306/1626\n",
      "Evaluating item 1307/1626\n",
      "Evaluating item 1308/1626\n",
      "Evaluating item 1309/1626\n",
      "Evaluating item 1310/1626\n",
      "Evaluating item 1311/1626\n",
      "Evaluating item 1312/1626\n",
      "Evaluating item 1313/1626\n",
      "Evaluating item 1314/1626\n",
      "Evaluating item 1315/1626\n",
      "Evaluating item 1316/1626\n",
      "Evaluating item 1317/1626\n",
      "Evaluating item 1318/1626\n",
      "Evaluating item 1319/1626\n",
      "Evaluating item 1320/1626\n",
      "Evaluating item 1321/1626\n",
      "Evaluating item 1322/1626\n",
      "Evaluating item 1323/1626\n",
      "Evaluating item 1324/1626\n",
      "Evaluating item 1325/1626\n",
      "Evaluating item 1326/1626\n",
      "Evaluating item 1327/1626\n",
      "Evaluating item 1328/1626\n",
      "Evaluating item 1329/1626\n",
      "Evaluating item 1330/1626\n",
      "Evaluating item 1331/1626\n",
      "Evaluating item 1332/1626\n",
      "Evaluating item 1333/1626\n",
      "Evaluating item 1334/1626\n",
      "Evaluating item 1335/1626\n",
      "Evaluating item 1336/1626\n",
      "Evaluating item 1337/1626\n",
      "Evaluating item 1338/1626\n",
      "Evaluating item 1339/1626\n",
      "Evaluating item 1340/1626\n",
      "Evaluating item 1341/1626\n",
      "Evaluating item 1342/1626\n",
      "Evaluating item 1343/1626\n",
      "Evaluating item 1344/1626\n",
      "Evaluating item 1345/1626\n",
      "Evaluating item 1346/1626\n",
      "Evaluating item 1347/1626\n",
      "Evaluating item 1348/1626\n",
      "Evaluating item 1349/1626\n",
      "Evaluating item 1350/1626\n",
      "Evaluating item 1351/1626\n",
      "Evaluating item 1352/1626\n",
      "Evaluating item 1353/1626\n",
      "Evaluating item 1354/1626\n",
      "Evaluating item 1355/1626\n",
      "Evaluating item 1356/1626\n",
      "Evaluating item 1357/1626\n",
      "Evaluating item 1358/1626\n",
      "Evaluating item 1359/1626\n",
      "Evaluating item 1360/1626\n",
      "Evaluating item 1361/1626\n",
      "Evaluating item 1362/1626\n",
      "Evaluating item 1363/1626\n",
      "Evaluating item 1364/1626\n",
      "Evaluating item 1365/1626\n",
      "Evaluating item 1366/1626\n",
      "Evaluating item 1367/1626\n",
      "Evaluating item 1368/1626\n",
      "Evaluating item 1369/1626\n",
      "Evaluating item 1370/1626\n",
      "Evaluating item 1371/1626\n",
      "Evaluating item 1372/1626\n",
      "Evaluating item 1373/1626\n",
      "Evaluating item 1374/1626\n",
      "Evaluating item 1375/1626\n",
      "Evaluating item 1376/1626\n",
      "Evaluating item 1377/1626\n",
      "Evaluating item 1378/1626\n",
      "Evaluating item 1379/1626\n",
      "Evaluating item 1380/1626\n",
      "Evaluating item 1381/1626\n",
      "Evaluating item 1382/1626\n",
      "Evaluating item 1383/1626\n",
      "Evaluating item 1384/1626\n",
      "Evaluating item 1385/1626\n",
      "Evaluating item 1386/1626\n",
      "Evaluating item 1387/1626\n",
      "Evaluating item 1388/1626\n",
      "Evaluating item 1389/1626\n",
      "Evaluating item 1390/1626\n",
      "Evaluating item 1391/1626\n",
      "Evaluating item 1392/1626\n",
      "Evaluating item 1393/1626\n",
      "Evaluating item 1394/1626\n",
      "Evaluating item 1395/1626\n",
      "Evaluating item 1396/1626\n",
      "Evaluating item 1397/1626\n",
      "Evaluating item 1398/1626\n",
      "Evaluating item 1399/1626\n",
      "Evaluating item 1400/1626\n",
      "Evaluating item 1401/1626\n",
      "Evaluating item 1402/1626\n",
      "Evaluating item 1403/1626\n",
      "Evaluating item 1404/1626\n",
      "Evaluating item 1405/1626\n",
      "Evaluating item 1406/1626\n",
      "Evaluating item 1407/1626\n",
      "Evaluating item 1408/1626\n",
      "Evaluating item 1409/1626\n",
      "Evaluating item 1410/1626\n",
      "Evaluating item 1411/1626\n",
      "Evaluating item 1412/1626\n",
      "Evaluating item 1413/1626\n",
      "Evaluating item 1414/1626\n",
      "Evaluating item 1415/1626\n",
      "Evaluating item 1416/1626\n",
      "Evaluating item 1417/1626\n",
      "Evaluating item 1418/1626\n",
      "Evaluating item 1419/1626\n",
      "Evaluating item 1420/1626\n",
      "Evaluating item 1421/1626\n",
      "Evaluating item 1422/1626\n",
      "Evaluating item 1423/1626\n",
      "Evaluating item 1424/1626\n",
      "Evaluating item 1425/1626\n",
      "Evaluating item 1426/1626\n",
      "Evaluating item 1427/1626\n",
      "Evaluating item 1428/1626\n",
      "Evaluating item 1429/1626\n",
      "Evaluating item 1430/1626\n",
      "Evaluating item 1431/1626\n",
      "Evaluating item 1432/1626\n",
      "Evaluating item 1433/1626\n",
      "Evaluating item 1434/1626\n",
      "Evaluating item 1435/1626\n",
      "Evaluating item 1436/1626\n",
      "Evaluating item 1437/1626\n",
      "Evaluating item 1438/1626\n",
      "Evaluating item 1439/1626\n",
      "Evaluating item 1440/1626\n",
      "Evaluating item 1441/1626\n",
      "Evaluating item 1442/1626\n",
      "Evaluating item 1443/1626\n",
      "Evaluating item 1444/1626\n",
      "Evaluating item 1445/1626\n",
      "Evaluating item 1446/1626\n",
      "Evaluating item 1447/1626\n",
      "Evaluating item 1448/1626\n",
      "Evaluating item 1449/1626\n",
      "Evaluating item 1450/1626\n",
      "Evaluating item 1451/1626\n",
      "Evaluating item 1452/1626\n",
      "Evaluating item 1453/1626\n",
      "Evaluating item 1454/1626\n",
      "Evaluating item 1455/1626\n",
      "Evaluating item 1456/1626\n",
      "Evaluating item 1457/1626\n",
      "Evaluating item 1458/1626\n",
      "Evaluating item 1459/1626\n",
      "Evaluating item 1460/1626\n",
      "Evaluating item 1461/1626\n",
      "Evaluating item 1462/1626\n",
      "Evaluating item 1463/1626\n",
      "Evaluating item 1464/1626\n",
      "Evaluating item 1465/1626\n",
      "Evaluating item 1466/1626\n",
      "Evaluating item 1467/1626\n",
      "Evaluating item 1468/1626\n",
      "Evaluating item 1469/1626\n",
      "Evaluating item 1470/1626\n",
      "Evaluating item 1471/1626\n",
      "Evaluating item 1472/1626\n",
      "Evaluating item 1473/1626\n",
      "Evaluating item 1474/1626\n",
      "Evaluating item 1475/1626\n",
      "Evaluating item 1476/1626\n",
      "Evaluating item 1477/1626\n",
      "Evaluating item 1478/1626\n",
      "Evaluating item 1479/1626\n",
      "Evaluating item 1480/1626\n",
      "Evaluating item 1481/1626\n",
      "Evaluating item 1482/1626\n",
      "Evaluating item 1483/1626\n",
      "Evaluating item 1484/1626\n",
      "Evaluating item 1485/1626\n",
      "Evaluating item 1486/1626\n",
      "Evaluating item 1487/1626\n",
      "Evaluating item 1488/1626\n",
      "Evaluating item 1489/1626\n",
      "Evaluating item 1490/1626\n",
      "Evaluating item 1491/1626\n",
      "Evaluating item 1492/1626\n",
      "Evaluating item 1493/1626\n",
      "Evaluating item 1494/1626\n",
      "Evaluating item 1495/1626\n",
      "Evaluating item 1496/1626\n",
      "Evaluating item 1497/1626\n",
      "Evaluating item 1498/1626\n",
      "Evaluating item 1499/1626\n",
      "Evaluating item 1500/1626\n",
      "Evaluating item 1501/1626\n",
      "Evaluating item 1502/1626\n",
      "Evaluating item 1503/1626\n",
      "Evaluating item 1504/1626\n",
      "Evaluating item 1505/1626\n",
      "Evaluating item 1506/1626\n",
      "Evaluating item 1507/1626\n",
      "Evaluating item 1508/1626\n",
      "Evaluating item 1509/1626\n",
      "Evaluating item 1510/1626\n",
      "Evaluating item 1511/1626\n",
      "Evaluating item 1512/1626\n",
      "Evaluating item 1513/1626\n",
      "Evaluating item 1514/1626\n",
      "Evaluating item 1515/1626\n",
      "Evaluating item 1516/1626\n",
      "Evaluating item 1517/1626\n",
      "Evaluating item 1518/1626\n",
      "Evaluating item 1519/1626\n",
      "Evaluating item 1520/1626\n",
      "Evaluating item 1521/1626\n",
      "Evaluating item 1522/1626\n",
      "Evaluating item 1523/1626\n",
      "Evaluating item 1524/1626\n",
      "Evaluating item 1525/1626\n",
      "Evaluating item 1526/1626\n",
      "Evaluating item 1527/1626\n",
      "Evaluating item 1528/1626\n",
      "Evaluating item 1529/1626\n",
      "Evaluating item 1530/1626\n",
      "Evaluating item 1531/1626\n",
      "Evaluating item 1532/1626\n",
      "Evaluating item 1533/1626\n",
      "Evaluating item 1534/1626\n",
      "Evaluating item 1535/1626\n",
      "Evaluating item 1536/1626\n",
      "Evaluating item 1537/1626\n",
      "Evaluating item 1538/1626\n",
      "Evaluating item 1539/1626\n",
      "Evaluating item 1540/1626\n",
      "Evaluating item 1541/1626\n",
      "Evaluating item 1542/1626\n",
      "Evaluating item 1543/1626\n",
      "Evaluating item 1544/1626\n",
      "Evaluating item 1545/1626\n",
      "Evaluating item 1546/1626\n",
      "Evaluating item 1547/1626\n",
      "Evaluating item 1548/1626\n",
      "Evaluating item 1549/1626\n",
      "Evaluating item 1550/1626\n",
      "Evaluating item 1551/1626\n",
      "Evaluating item 1552/1626\n",
      "Evaluating item 1553/1626\n",
      "Evaluating item 1554/1626\n",
      "Evaluating item 1555/1626\n",
      "Evaluating item 1556/1626\n",
      "Evaluating item 1557/1626\n",
      "Evaluating item 1558/1626\n",
      "Evaluating item 1559/1626\n",
      "Evaluating item 1560/1626\n",
      "Evaluating item 1561/1626\n",
      "Evaluating item 1562/1626\n",
      "Evaluating item 1563/1626\n",
      "Evaluating item 1564/1626\n",
      "Evaluating item 1565/1626\n",
      "Evaluating item 1566/1626\n",
      "Evaluating item 1567/1626\n",
      "Evaluating item 1568/1626\n",
      "Evaluating item 1569/1626\n",
      "Evaluating item 1570/1626\n",
      "Evaluating item 1571/1626\n",
      "Evaluating item 1572/1626\n",
      "Evaluating item 1573/1626\n",
      "Evaluating item 1574/1626\n",
      "Evaluating item 1575/1626\n",
      "Evaluating item 1576/1626\n",
      "Evaluating item 1577/1626\n",
      "Evaluating item 1578/1626\n",
      "Evaluating item 1579/1626\n",
      "Evaluating item 1580/1626\n",
      "Evaluating item 1581/1626\n",
      "Evaluating item 1582/1626\n",
      "Evaluating item 1583/1626\n",
      "Evaluating item 1584/1626\n",
      "Evaluating item 1585/1626\n",
      "Evaluating item 1586/1626\n",
      "Evaluating item 1587/1626\n",
      "Evaluating item 1588/1626\n",
      "Evaluating item 1589/1626\n",
      "Evaluating item 1590/1626\n",
      "Evaluating item 1591/1626\n",
      "Evaluating item 1592/1626\n",
      "Evaluating item 1593/1626\n",
      "Evaluating item 1594/1626\n",
      "Evaluating item 1595/1626\n",
      "Evaluating item 1596/1626\n",
      "Evaluating item 1597/1626\n",
      "Evaluating item 1598/1626\n",
      "Evaluating item 1599/1626\n",
      "Evaluating item 1600/1626\n",
      "Evaluating item 1601/1626\n",
      "Evaluating item 1602/1626\n",
      "Evaluating item 1603/1626\n",
      "Evaluating item 1604/1626\n",
      "Evaluating item 1605/1626\n",
      "Evaluating item 1606/1626\n",
      "Evaluating item 1607/1626\n",
      "Evaluating item 1608/1626\n",
      "Evaluating item 1609/1626\n",
      "Evaluating item 1610/1626\n",
      "Evaluating item 1611/1626\n",
      "Evaluating item 1612/1626\n",
      "Evaluating item 1613/1626\n",
      "Evaluating item 1614/1626\n",
      "Evaluating item 1615/1626\n",
      "Evaluating item 1616/1626\n",
      "Evaluating item 1617/1626\n",
      "Evaluating item 1618/1626\n",
      "Evaluating item 1619/1626\n",
      "Evaluating item 1620/1626\n",
      "Evaluating item 1621/1626\n",
      "Evaluating item 1622/1626\n",
      "Evaluating item 1623/1626\n",
      "Evaluating item 1624/1626\n",
      "Evaluating item 1625/1626\n",
      "Evaluating item 1626/1626\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "\n",
    "print(location_labels)\n",
    "\n",
    "\n",
    "def evaluate(context_model, bag_model, pant_model, hand_model):\n",
    "    context_prediction = context_model.predict(test_x)\n",
    "    context_prediction = np.argmax(context_prediction, axis=1)\n",
    "\n",
    "    result = []\n",
    "    for i in range(len(test_x)):\n",
    "        print(\"Evaluating item \" + str(i + 1) + \"/\" + str(len(test_x)))\n",
    "        predicted_context_index = context_prediction[i]\n",
    "        if location_labels[predicted_context_index] == 'holdinginhand':\n",
    "            step_prediction = hand_model.predict(test_x[i:i + 1])[0][0]\n",
    "        elif location_labels[predicted_context_index] == 'insidethebag':\n",
    "            step_prediction = bag_model.predict(test_x[i:i + 1])[0][0]\n",
    "        elif location_labels[predicted_context_index] == 'insidethepantpocket':\n",
    "            step_prediction = pant_model.predict(test_x[i:i + 1])[0][0]\n",
    "        else:\n",
    "            raise Exception(\"Invalid index\")\n",
    "        result.append(step_prediction)\n",
    "    return np.array(context_prediction), np.array(result)\n",
    "\n",
    "\n",
    "context_predictions, step_predictions = evaluate(\n",
    "    context_model=models.load_model(\"logs/2022-06-21/id_33/model.h5\"),\n",
    "    bag_model=models.load_model(\"logs/2022-06-21/id_8/model.h5\"),\n",
    "    pant_model=models.load_model(\"logs/2022-06-21/id_3/model.h5\"),\n",
    "    hand_model=models.load_model(\"logs/2022-06-21/id_15/model.h5\")\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [],
   "source": [
    "class PredictionProfile:\n",
    "\n",
    "    def __init__(self, context_correct, step_count_correct, context):\n",
    "        self.context_correct = context_correct\n",
    "        self.step_count_correct = step_count_correct\n",
    "        self.context = context"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct:  1235 / 1626\n",
      "0.41808024858929865\n"
     ]
    }
   ],
   "source": [
    "correct_count = 0\n",
    "diff_list = []\n",
    "rounded_step_predictions = [round(i) for i in step_predictions]\n",
    "prediction_profile_list = []\n",
    "\n",
    "for i in range(len(test_y_step)):\n",
    "    is_step_count_correct = test_y_step[i] == rounded_step_predictions[i]\n",
    "    prediction_profile_list.append(PredictionProfile(\n",
    "        context_correct=context_predictions[i] == test_y_context[i],\n",
    "        context=test_y_context[i],\n",
    "        step_count_correct=is_step_count_correct\n",
    "    ))\n",
    "    diff_list.append(abs(test_y_step[i] - step_predictions[i]))\n",
    "    if is_step_count_correct:\n",
    "        correct_count += 1\n",
    "    # else:\n",
    "    #     print(\"Incorrect: index - \", i, \" | base - \", test_y_step[i], \" | actual - \", step_predictions[i])\n",
    "print(\"Correct: \", correct_count, \"/\", len(step_predictions))\n",
    "print(sum(diff_list) / len(diff_list))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hand list length:  565\n",
      "Bag list length:  544\n",
      "Pant list:  517\n"
     ]
    }
   ],
   "source": [
    "holding_in_hand_list = [profile for profile in prediction_profile_list if profile.context == 0]\n",
    "bag_list = [profile for profile in prediction_profile_list if profile.context == 1]\n",
    "pant_list = [profile for profile in prediction_profile_list if profile.context == 2]\n",
    "\n",
    "print(\"Hand list length: \", str(len(holding_in_hand_list)))\n",
    "print(\"Bag list length: \", str(len(bag_list)))\n",
    "print(\"Pant list: \", str(len(pant_list)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************\n",
      "Showing result for list Holding in hand\n",
      "388 128 35 14\n",
      "Success rate  0.7486725663716814\n",
      "**************************\n",
      "Showing result for list Inside the bag\n",
      "405 138 0 1\n",
      "Success rate  0.7444852941176471\n",
      "**************************\n",
      "Showing result for list Inside the pant\n",
      "407 109 0 1\n",
      "Success rate  0.7872340425531915\n"
     ]
    }
   ],
   "source": [
    "def print_list_result(list_name, list):\n",
    "    print(\"**************************\\nShowing result for list \" + list_name)\n",
    "    y_context_y_step = 0\n",
    "    y_context_n_step = 0\n",
    "    n_context_y_step = 0\n",
    "    n_context_n_step = 0\n",
    "\n",
    "    for profile in list:\n",
    "        if profile.context_correct and profile.step_count_correct:\n",
    "            y_context_y_step += 1\n",
    "        elif profile.context_correct and not profile.step_count_correct:\n",
    "            y_context_n_step += 1\n",
    "        elif not profile.context_correct and profile.step_count_correct:\n",
    "            n_context_y_step += 1\n",
    "        else:\n",
    "            n_context_n_step += 1\n",
    "    print(y_context_y_step, y_context_n_step,n_context_y_step,n_context_n_step)\n",
    "    print(\"Success rate \", (y_context_y_step + n_context_y_step) / (y_context_y_step + y_context_n_step + n_context_y_step + n_context_n_step))\n",
    "\n",
    "print_list_result(\"Holding in hand\", holding_in_hand_list)\n",
    "print_list_result(\"Inside the bag\", bag_list)\n",
    "print_list_result(\"Inside the pant\", pant_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}